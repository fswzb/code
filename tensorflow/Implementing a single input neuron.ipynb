{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing a single input neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "interactive_sesssion=tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_value = tf.constant(0.5,name=\"input_value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight = tf.Variable(1.0,name=\"weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expected_output = tf.constant(0.0,name=\"expected_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = tf.multiply(input_value, weight,\"model\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss_function = (model - expected_output)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optim = tf.train.GradientDescentOptimizer(learning_rate=0.025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_step=optim.minimize(loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for value in [input_value,weight,expected_output,model,loss_function]:     \n",
    "    tf.summary.scalar(value.op.name,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summaries = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "summary_writer = tf.summary.FileWriter('log_simple_stats',interactive_sesssion.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_op=tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "interactive_sesssion.run(init_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scatter_output_x=[]\n",
    "scatter_output_y=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is 0.243789. weight is 0.987500\n",
      "loss is 0.237732. weight is 0.975156\n",
      "loss is 0.231826. weight is 0.962967\n",
      "loss is 0.226067. weight is 0.950930\n",
      "loss is 0.220450. weight is 0.939043\n",
      "loss is 0.214974. weight is 0.927305\n",
      "loss is 0.209633. weight is 0.915714\n",
      "loss is 0.204425. weight is 0.904267\n",
      "loss is 0.199346. weight is 0.892964\n",
      "loss is 0.194394. weight is 0.881802\n",
      "loss is 0.189564. weight is 0.870779\n",
      "loss is 0.184855. weight is 0.859895\n",
      "loss is 0.180262. weight is 0.849146\n",
      "loss is 0.175784. weight is 0.838532\n",
      "loss is 0.171417. weight is 0.828050\n",
      "loss is 0.167158. weight is 0.817699\n",
      "loss is 0.163005. weight is 0.807478\n",
      "loss is 0.158956. weight is 0.797385\n",
      "loss is 0.155006. weight is 0.787417\n",
      "loss is 0.151156. weight is 0.777575\n",
      "loss is 0.147400. weight is 0.767855\n",
      "loss is 0.143738. weight is 0.758257\n",
      "loss is 0.140167. weight is 0.748779\n",
      "loss is 0.136685. weight is 0.739419\n",
      "loss is 0.133289. weight is 0.730176\n",
      "loss is 0.129978. weight is 0.721049\n",
      "loss is 0.126749. weight is 0.712036\n",
      "loss is 0.123600. weight is 0.703135\n",
      "loss is 0.120529. weight is 0.694346\n",
      "loss is 0.117535. weight is 0.685667\n",
      "loss is 0.114615. weight is 0.677096\n",
      "loss is 0.111767. weight is 0.668632\n",
      "loss is 0.108991. weight is 0.660274\n",
      "loss is 0.106283. weight is 0.652021\n",
      "loss is 0.103642. weight is 0.643871\n",
      "loss is 0.101067. weight is 0.635822\n",
      "loss is 0.098557. weight is 0.627874\n",
      "loss is 0.096108. weight is 0.620026\n",
      "loss is 0.093720. weight is 0.612276\n",
      "loss is 0.091392. weight is 0.604622\n",
      "loss is 0.089122. weight is 0.597064\n",
      "loss is 0.086907. weight is 0.589601\n",
      "loss is 0.084748. weight is 0.582231\n",
      "loss is 0.082643. weight is 0.574953\n",
      "loss is 0.080590. weight is 0.567766\n",
      "loss is 0.078588. weight is 0.560669\n",
      "loss is 0.076635. weight is 0.553661\n",
      "loss is 0.074731. weight is 0.546740\n",
      "loss is 0.072875. weight is 0.539906\n",
      "loss is 0.071064. weight is 0.533157\n",
      "loss is 0.069299. weight is 0.526493\n",
      "loss is 0.067577. weight is 0.519911\n",
      "loss is 0.065898. weight is 0.513413\n",
      "loss is 0.064261. weight is 0.506995\n",
      "loss is 0.062664. weight is 0.500657\n",
      "loss is 0.061108. weight is 0.494399\n",
      "loss is 0.059590. weight is 0.488219\n",
      "loss is 0.058109. weight is 0.482117\n",
      "loss is 0.056665. weight is 0.476090\n",
      "loss is 0.055258. weight is 0.470139\n",
      "loss is 0.053885. weight is 0.464262\n",
      "loss is 0.052546. weight is 0.458459\n",
      "loss is 0.051241. weight is 0.452728\n",
      "loss is 0.049968. weight is 0.447069\n",
      "loss is 0.048726. weight is 0.441481\n",
      "loss is 0.047516. weight is 0.435962\n",
      "loss is 0.046335. weight is 0.430513\n",
      "loss is 0.045184. weight is 0.425131\n",
      "loss is 0.044062. weight is 0.419817\n",
      "loss is 0.042967. weight is 0.414569\n",
      "loss is 0.041899. weight is 0.409387\n",
      "loss is 0.040859. weight is 0.404270\n",
      "loss is 0.039843. weight is 0.399217\n",
      "loss is 0.038854. weight is 0.394226\n",
      "loss is 0.037888. weight is 0.389299\n",
      "loss is 0.036947. weight is 0.384432\n",
      "loss is 0.036029. weight is 0.379627\n",
      "loss is 0.035134. weight is 0.374882\n",
      "loss is 0.034261. weight is 0.370196\n",
      "loss is 0.033410. weight is 0.365568\n",
      "loss is 0.032580. weight is 0.360999\n",
      "loss is 0.031771. weight is 0.356486\n",
      "loss is 0.030981. weight is 0.352030\n",
      "loss is 0.030212. weight is 0.347630\n",
      "loss is 0.029461. weight is 0.343284\n",
      "loss is 0.028729. weight is 0.338993\n",
      "loss is 0.028015. weight is 0.334756\n",
      "loss is 0.027319. weight is 0.330571\n",
      "loss is 0.026641. weight is 0.326439\n",
      "loss is 0.025979. weight is 0.322359\n",
      "loss is 0.025333. weight is 0.318329\n",
      "loss is 0.024704. weight is 0.314350\n",
      "loss is 0.024090. weight is 0.310421\n",
      "loss is 0.023492. weight is 0.306540\n",
      "loss is 0.022908. weight is 0.302709\n",
      "loss is 0.022339. weight is 0.298925\n",
      "loss is 0.021784. weight is 0.295188\n",
      "loss is 0.021243. weight is 0.291498\n",
      "loss is 0.020715. weight is 0.287855\n",
      "loss is 0.020200. weight is 0.284257\n",
      "loss is 0.019699. weight is 0.280703\n",
      "loss is 0.019209. weight is 0.277194\n",
      "loss is 0.018732. weight is 0.273730\n",
      "loss is 0.018267. weight is 0.270308\n",
      "loss is 0.017813. weight is 0.266929\n",
      "loss is 0.017370. weight is 0.263593\n",
      "loss is 0.016939. weight is 0.260298\n",
      "loss is 0.016518. weight is 0.257044\n",
      "loss is 0.016108. weight is 0.253831\n",
      "loss is 0.015707. weight is 0.250658\n",
      "loss is 0.015317. weight is 0.247525\n",
      "loss is 0.014937. weight is 0.244431\n",
      "loss is 0.014566. weight is 0.241375\n",
      "loss is 0.014204. weight is 0.238358\n",
      "loss is 0.013851. weight is 0.235379\n",
      "loss is 0.013507. weight is 0.232436\n",
      "loss is 0.013171. weight is 0.229531\n",
      "loss is 0.012844. weight is 0.226662\n",
      "loss is 0.012525. weight is 0.223829\n",
      "loss is 0.012214. weight is 0.221031\n",
      "loss is 0.011910. weight is 0.218268\n",
      "loss is 0.011614. weight is 0.215539\n",
      "loss is 0.011326. weight is 0.212845\n",
      "loss is 0.011044. weight is 0.210185\n",
      "loss is 0.010770. weight is 0.207557\n",
      "loss is 0.010502. weight is 0.204963\n",
      "loss is 0.010242. weight is 0.202401\n",
      "loss is 0.009987. weight is 0.199871\n",
      "loss is 0.009739. weight is 0.197372\n",
      "loss is 0.009497. weight is 0.194905\n",
      "loss is 0.009261. weight is 0.192469\n",
      "loss is 0.009031. weight is 0.190063\n",
      "loss is 0.008807. weight is 0.187687\n",
      "loss is 0.008588. weight is 0.185341\n",
      "loss is 0.008374. weight is 0.183024\n",
      "loss is 0.008166. weight is 0.180737\n",
      "loss is 0.007964. weight is 0.178477\n",
      "loss is 0.007766. weight is 0.176246\n",
      "loss is 0.007573. weight is 0.174043\n",
      "loss is 0.007385. weight is 0.171868\n",
      "loss is 0.007201. weight is 0.169720\n",
      "loss is 0.007022. weight is 0.167598\n",
      "loss is 0.006848. weight is 0.165503\n",
      "loss is 0.006678. weight is 0.163434\n",
      "loss is 0.006512. weight is 0.161391\n",
      "loss is 0.006350. weight is 0.159374\n",
      "loss is 0.006192. weight is 0.157382\n",
      "loss is 0.006038. weight is 0.155414\n",
      "loss is 0.005888. weight is 0.153472\n",
      "loss is 0.005742. weight is 0.151553\n",
      "loss is 0.005599. weight is 0.149659\n",
      "loss is 0.005460. weight is 0.147788\n",
      "loss is 0.005325. weight is 0.145941\n",
      "loss is 0.005192. weight is 0.144117\n",
      "loss is 0.005063. weight is 0.142315\n",
      "loss is 0.004938. weight is 0.140536\n",
      "loss is 0.004815. weight is 0.138780\n",
      "loss is 0.004695. weight is 0.137045\n",
      "loss is 0.004579. weight is 0.135332\n",
      "loss is 0.004465. weight is 0.133640\n",
      "loss is 0.004354. weight is 0.131970\n",
      "loss is 0.004246. weight is 0.130320\n",
      "loss is 0.004140. weight is 0.128691\n",
      "loss is 0.004037. weight is 0.127082\n",
      "loss is 0.003937. weight is 0.125494\n",
      "loss is 0.003839. weight is 0.123925\n",
      "loss is 0.003744. weight is 0.122376\n",
      "loss is 0.003651. weight is 0.120846\n",
      "loss is 0.003560. weight is 0.119336\n",
      "loss is 0.003472. weight is 0.117844\n",
      "loss is 0.003386. weight is 0.116371\n",
      "loss is 0.003301. weight is 0.114916\n",
      "loss is 0.003219. weight is 0.113480\n",
      "loss is 0.003139. weight is 0.112061\n",
      "loss is 0.003061. weight is 0.110661\n",
      "loss is 0.002985. weight is 0.109277\n",
      "loss is 0.002911. weight is 0.107911\n",
      "loss is 0.002839. weight is 0.106563\n",
      "loss is 0.002768. weight is 0.105231\n",
      "loss is 0.002700. weight is 0.103915\n",
      "loss is 0.002633. weight is 0.102616\n",
      "loss is 0.002567. weight is 0.101333\n",
      "loss is 0.002503. weight is 0.100067\n",
      "loss is 0.002441. weight is 0.098816\n",
      "loss is 0.002381. weight is 0.097581\n",
      "loss is 0.002321. weight is 0.096361\n",
      "loss is 0.002264. weight is 0.095157\n",
      "loss is 0.002207. weight is 0.093967\n",
      "loss is 0.002153. weight is 0.092792\n",
      "loss is 0.002099. weight is 0.091633\n",
      "loss is 0.002047. weight is 0.090487\n",
      "loss is 0.001996. weight is 0.089356\n",
      "loss is 0.001947. weight is 0.088239\n",
      "loss is 0.001898. weight is 0.087136\n",
      "loss is 0.001851. weight is 0.086047\n",
      "loss is 0.001805. weight is 0.084971\n",
      "loss is 0.001760. weight is 0.083909\n",
      "loss is 0.001716. weight is 0.082860\n",
      "loss is 0.001674. weight is 0.081825\n",
      "loss is 0.001632. weight is 0.080802\n",
      "loss is 0.001592. weight is 0.079792\n",
      "loss is 0.001552. weight is 0.078794\n",
      "loss is 0.001514. weight is 0.077809\n",
      "loss is 0.001476. weight is 0.076837\n",
      "loss is 0.001439. weight is 0.075876\n",
      "loss is 0.001404. weight is 0.074928\n",
      "loss is 0.001369. weight is 0.073991\n",
      "loss is 0.001335. weight is 0.073066\n",
      "loss is 0.001302. weight is 0.072153\n",
      "loss is 0.001269. weight is 0.071251\n",
      "loss is 0.001238. weight is 0.070361\n",
      "loss is 0.001207. weight is 0.069481\n",
      "loss is 0.001177. weight is 0.068613\n",
      "loss is 0.001148. weight is 0.067755\n",
      "loss is 0.001119. weight is 0.066908\n",
      "loss is 0.001091. weight is 0.066072\n",
      "loss is 0.001064. weight is 0.065246\n",
      "loss is 0.001038. weight is 0.064430\n",
      "loss is 0.001012. weight is 0.063625\n",
      "loss is 0.000987. weight is 0.062829\n",
      "loss is 0.000962. weight is 0.062044\n",
      "loss is 0.000938. weight is 0.061268\n",
      "loss is 0.000915. weight is 0.060503\n",
      "loss is 0.000892. weight is 0.059746\n",
      "loss is 0.000870. weight is 0.059000\n",
      "loss is 0.000849. weight is 0.058262\n",
      "loss is 0.000828. weight is 0.057534\n",
      "loss is 0.000807. weight is 0.056815\n",
      "loss is 0.000787. weight is 0.056104\n",
      "loss is 0.000767. weight is 0.055403\n",
      "loss is 0.000748. weight is 0.054711\n",
      "loss is 0.000730. weight is 0.054027\n",
      "loss is 0.000712. weight is 0.053351\n",
      "loss is 0.000694. weight is 0.052684\n",
      "loss is 0.000677. weight is 0.052026\n",
      "loss is 0.000660. weight is 0.051376\n",
      "loss is 0.000643. weight is 0.050733\n",
      "loss is 0.000627. weight is 0.050099\n",
      "loss is 0.000612. weight is 0.049473\n",
      "loss is 0.000597. weight is 0.048855\n",
      "loss is 0.000582. weight is 0.048244\n",
      "loss is 0.000567. weight is 0.047641\n",
      "loss is 0.000553. weight is 0.047045\n",
      "loss is 0.000540. weight is 0.046457\n",
      "loss is 0.000526. weight is 0.045877\n",
      "loss is 0.000513. weight is 0.045303\n",
      "loss is 0.000500. weight is 0.044737\n",
      "loss is 0.000488. weight is 0.044178\n",
      "loss is 0.000476. weight is 0.043625\n",
      "loss is 0.000464. weight is 0.043080\n",
      "loss is 0.000452. weight is 0.042542\n",
      "loss is 0.000441. weight is 0.042010\n",
      "loss is 0.000430. weight is 0.041485\n",
      "loss is 0.000420. weight is 0.040966\n",
      "loss is 0.000409. weight is 0.040454\n",
      "loss is 0.000399. weight is 0.039948\n",
      "loss is 0.000389. weight is 0.039449\n",
      "loss is 0.000379. weight is 0.038956\n",
      "loss is 0.000370. weight is 0.038469\n",
      "loss is 0.000361. weight is 0.037988\n",
      "loss is 0.000352. weight is 0.037513\n",
      "loss is 0.000343. weight is 0.037044\n",
      "loss is 0.000335. weight is 0.036581\n",
      "loss is 0.000326. weight is 0.036124\n",
      "loss is 0.000318. weight is 0.035672\n",
      "loss is 0.000310. weight is 0.035227\n",
      "loss is 0.000303. weight is 0.034786\n",
      "loss is 0.000295. weight is 0.034351\n",
      "loss is 0.000288. weight is 0.033922\n",
      "loss is 0.000281. weight is 0.033498\n",
      "loss is 0.000274. weight is 0.033079\n",
      "loss is 0.000267. weight is 0.032666\n",
      "loss is 0.000260. weight is 0.032257\n",
      "loss is 0.000254. weight is 0.031854\n",
      "loss is 0.000247. weight is 0.031456\n",
      "loss is 0.000241. weight is 0.031063\n",
      "loss is 0.000235. weight is 0.030675\n",
      "loss is 0.000229. weight is 0.030291\n",
      "loss is 0.000224. weight is 0.029912\n",
      "loss is 0.000218. weight is 0.029539\n",
      "loss is 0.000213. weight is 0.029169\n",
      "loss is 0.000207. weight is 0.028805\n",
      "loss is 0.000202. weight is 0.028445\n",
      "loss is 0.000197. weight is 0.028089\n",
      "loss is 0.000192. weight is 0.027738\n",
      "loss is 0.000188. weight is 0.027391\n",
      "loss is 0.000183. weight is 0.027049\n",
      "loss is 0.000178. weight is 0.026711\n",
      "loss is 0.000174. weight is 0.026377\n",
      "loss is 0.000170. weight is 0.026047\n",
      "loss is 0.000165. weight is 0.025722\n",
      "loss is 0.000161. weight is 0.025400\n",
      "loss is 0.000157. weight is 0.025083\n",
      "loss is 0.000153. weight is 0.024769\n",
      "loss is 0.000150. weight is 0.024459\n",
      "loss is 0.000146. weight is 0.024154\n",
      "loss is 0.000142. weight is 0.023852\n",
      "loss is 0.000139. weight is 0.023554\n",
      "loss is 0.000135. weight is 0.023259\n",
      "loss is 0.000132. weight is 0.022968\n",
      "loss is 0.000129. weight is 0.022681\n",
      "loss is 0.000125. weight is 0.022398\n",
      "loss is 0.000122. weight is 0.022118\n",
      "loss is 0.000119. weight is 0.021841\n",
      "loss is 0.000116. weight is 0.021568\n",
      "loss is 0.000113. weight is 0.021299\n",
      "loss is 0.000111. weight is 0.021033\n",
      "loss is 0.000108. weight is 0.020770\n",
      "loss is 0.000105. weight is 0.020510\n",
      "loss is 0.000103. weight is 0.020254\n",
      "loss is 0.000100. weight is 0.020000\n",
      "loss is 0.000098. weight is 0.019750\n",
      "loss is 0.000095. weight is 0.019504\n",
      "loss is 0.000093. weight is 0.019260\n",
      "loss is 0.000090. weight is 0.019019\n",
      "loss is 0.000088. weight is 0.018781\n",
      "loss is 0.000086. weight is 0.018547\n",
      "loss is 0.000084. weight is 0.018315\n",
      "loss is 0.000082. weight is 0.018086\n",
      "loss is 0.000080. weight is 0.017860\n",
      "loss is 0.000078. weight is 0.017636\n",
      "loss is 0.000076. weight is 0.017416\n",
      "loss is 0.000074. weight is 0.017198\n",
      "loss is 0.000072. weight is 0.016983\n",
      "loss is 0.000070. weight is 0.016771\n",
      "loss is 0.000069. weight is 0.016561\n",
      "loss is 0.000067. weight is 0.016354\n",
      "loss is 0.000065. weight is 0.016150\n",
      "loss is 0.000064. weight is 0.015948\n",
      "loss is 0.000062. weight is 0.015749\n",
      "loss is 0.000060. weight is 0.015552\n",
      "loss is 0.000059. weight is 0.015357\n",
      "loss is 0.000057. weight is 0.015165\n",
      "loss is 0.000056. weight is 0.014976\n",
      "loss is 0.000055. weight is 0.014789\n",
      "loss is 0.000053. weight is 0.014604\n",
      "loss is 0.000052. weight is 0.014421\n",
      "loss is 0.000051. weight is 0.014241\n",
      "loss is 0.000049. weight is 0.014063\n",
      "loss is 0.000048. weight is 0.013887\n",
      "loss is 0.000047. weight is 0.013714\n",
      "loss is 0.000046. weight is 0.013542\n",
      "loss is 0.000045. weight is 0.013373\n",
      "loss is 0.000044. weight is 0.013206\n",
      "loss is 0.000043. weight is 0.013041\n",
      "loss is 0.000041. weight is 0.012878\n",
      "loss is 0.000040. weight is 0.012717\n",
      "loss is 0.000039. weight is 0.012558\n",
      "loss is 0.000038. weight is 0.012401\n",
      "loss is 0.000037. weight is 0.012246\n",
      "loss is 0.000037. weight is 0.012093\n",
      "loss is 0.000036. weight is 0.011942\n",
      "loss is 0.000035. weight is 0.011792\n",
      "loss is 0.000034. weight is 0.011645\n",
      "loss is 0.000033. weight is 0.011499\n",
      "loss is 0.000032. weight is 0.011356\n",
      "loss is 0.000031. weight is 0.011214\n",
      "loss is 0.000031. weight is 0.011073\n",
      "loss is 0.000030. weight is 0.010935\n",
      "loss is 0.000029. weight is 0.010798\n",
      "loss is 0.000028. weight is 0.010663\n",
      "loss is 0.000028. weight is 0.010530\n",
      "loss is 0.000027. weight is 0.010398\n",
      "loss is 0.000026. weight is 0.010268\n",
      "loss is 0.000026. weight is 0.010140\n",
      "loss is 0.000025. weight is 0.010013\n",
      "loss is 0.000024. weight is 0.009888\n",
      "loss is 0.000024. weight is 0.009765\n",
      "loss is 0.000023. weight is 0.009643\n",
      "loss is 0.000023. weight is 0.009522\n",
      "loss is 0.000022. weight is 0.009403\n",
      "loss is 0.000022. weight is 0.009285\n",
      "loss is 0.000021. weight is 0.009169\n",
      "loss is 0.000020. weight is 0.009055\n",
      "loss is 0.000020. weight is 0.008942\n",
      "loss is 0.000019. weight is 0.008830\n",
      "loss is 0.000019. weight is 0.008719\n",
      "loss is 0.000019. weight is 0.008610\n",
      "loss is 0.000018. weight is 0.008503\n",
      "loss is 0.000018. weight is 0.008397\n",
      "loss is 0.000017. weight is 0.008292\n",
      "loss is 0.000017. weight is 0.008188\n",
      "loss is 0.000016. weight is 0.008086\n",
      "loss is 0.000016. weight is 0.007985\n",
      "loss is 0.000016. weight is 0.007885\n",
      "loss is 0.000015. weight is 0.007786\n",
      "loss is 0.000015. weight is 0.007689\n",
      "loss is 0.000014. weight is 0.007593\n",
      "loss is 0.000014. weight is 0.007498\n",
      "loss is 0.000014. weight is 0.007404\n",
      "loss is 0.000013. weight is 0.007312\n",
      "loss is 0.000013. weight is 0.007220\n",
      "loss is 0.000013. weight is 0.007130\n",
      "loss is 0.000012. weight is 0.007041\n",
      "loss is 0.000012. weight is 0.006953\n",
      "loss is 0.000012. weight is 0.006866\n",
      "loss is 0.000011. weight is 0.006780\n",
      "loss is 0.000011. weight is 0.006695\n",
      "loss is 0.000011. weight is 0.006612\n",
      "loss is 0.000011. weight is 0.006529\n",
      "loss is 0.000010. weight is 0.006447\n",
      "loss is 0.000010. weight is 0.006367\n",
      "loss is 0.000010. weight is 0.006287\n",
      "loss is 0.000010. weight is 0.006209\n",
      "loss is 0.000009. weight is 0.006131\n",
      "loss is 0.000009. weight is 0.006054\n",
      "loss is 0.000009. weight is 0.005979\n",
      "loss is 0.000009. weight is 0.005904\n",
      "loss is 0.000008. weight is 0.005830\n",
      "loss is 0.000008. weight is 0.005757\n",
      "loss is 0.000008. weight is 0.005685\n",
      "loss is 0.000008. weight is 0.005614\n",
      "loss is 0.000008. weight is 0.005544\n",
      "loss is 0.000007. weight is 0.005475\n",
      "loss is 0.000007. weight is 0.005406\n",
      "loss is 0.000007. weight is 0.005339\n",
      "loss is 0.000007. weight is 0.005272\n",
      "loss is 0.000007. weight is 0.005206\n",
      "loss is 0.000007. weight is 0.005141\n",
      "loss is 0.000006. weight is 0.005077\n",
      "loss is 0.000006. weight is 0.005013\n",
      "loss is 0.000006. weight is 0.004951\n",
      "loss is 0.000006. weight is 0.004889\n",
      "loss is 0.000006. weight is 0.004828\n",
      "loss is 0.000006. weight is 0.004767\n",
      "loss is 0.000006. weight is 0.004708\n",
      "loss is 0.000005. weight is 0.004649\n",
      "loss is 0.000005. weight is 0.004591\n",
      "loss is 0.000005. weight is 0.004533\n",
      "loss is 0.000005. weight is 0.004477\n",
      "loss is 0.000005. weight is 0.004421\n",
      "loss is 0.000005. weight is 0.004365\n",
      "loss is 0.000005. weight is 0.004311\n",
      "loss is 0.000005. weight is 0.004257\n",
      "loss is 0.000004. weight is 0.004204\n",
      "loss is 0.000004. weight is 0.004151\n",
      "loss is 0.000004. weight is 0.004099\n",
      "loss is 0.000004. weight is 0.004048\n",
      "loss is 0.000004. weight is 0.003998\n",
      "loss is 0.000004. weight is 0.003948\n",
      "loss is 0.000004. weight is 0.003898\n",
      "loss is 0.000004. weight is 0.003849\n",
      "loss is 0.000004. weight is 0.003801\n",
      "loss is 0.000004. weight is 0.003754\n",
      "loss is 0.000003. weight is 0.003707\n",
      "loss is 0.000003. weight is 0.003661\n",
      "loss is 0.000003. weight is 0.003615\n",
      "loss is 0.000003. weight is 0.003570\n",
      "loss is 0.000003. weight is 0.003525\n",
      "loss is 0.000003. weight is 0.003481\n",
      "loss is 0.000003. weight is 0.003437\n",
      "loss is 0.000003. weight is 0.003394\n",
      "loss is 0.000003. weight is 0.003352\n",
      "loss is 0.000003. weight is 0.003310\n",
      "loss is 0.000003. weight is 0.003269\n",
      "loss is 0.000003. weight is 0.003228\n",
      "loss is 0.000003. weight is 0.003188\n",
      "loss is 0.000002. weight is 0.003148\n",
      "loss is 0.000002. weight is 0.003108\n",
      "loss is 0.000002. weight is 0.003070\n",
      "loss is 0.000002. weight is 0.003031\n",
      "loss is 0.000002. weight is 0.002993\n",
      "loss is 0.000002. weight is 0.002956\n",
      "loss is 0.000002. weight is 0.002919\n",
      "loss is 0.000002. weight is 0.002882\n",
      "loss is 0.000002. weight is 0.002846\n",
      "loss is 0.000002. weight is 0.002811\n",
      "loss is 0.000002. weight is 0.002776\n",
      "loss is 0.000002. weight is 0.002741\n",
      "loss is 0.000002. weight is 0.002707\n",
      "loss is 0.000002. weight is 0.002673\n",
      "loss is 0.000002. weight is 0.002639\n",
      "loss is 0.000002. weight is 0.002606\n",
      "loss is 0.000002. weight is 0.002574\n",
      "loss is 0.000002. weight is 0.002542\n",
      "loss is 0.000002. weight is 0.002510\n",
      "loss is 0.000002. weight is 0.002479\n",
      "loss is 0.000001. weight is 0.002448\n",
      "loss is 0.000001. weight is 0.002417\n",
      "loss is 0.000001. weight is 0.002387\n",
      "loss is 0.000001. weight is 0.002357\n",
      "loss is 0.000001. weight is 0.002327\n",
      "loss is 0.000001. weight is 0.002298\n",
      "loss is 0.000001. weight is 0.002270\n",
      "loss is 0.000001. weight is 0.002241\n",
      "loss is 0.000001. weight is 0.002213\n",
      "loss is 0.000001. weight is 0.002186\n",
      "loss is 0.000001. weight is 0.002158\n",
      "loss is 0.000001. weight is 0.002131\n",
      "loss is 0.000001. weight is 0.002105\n",
      "loss is 0.000001. weight is 0.002078\n",
      "loss is 0.000001. weight is 0.002052\n",
      "loss is 0.000001. weight is 0.002027\n",
      "loss is 0.000001. weight is 0.002001\n",
      "loss is 0.000001. weight is 0.001976\n",
      "loss is 0.000001. weight is 0.001952\n",
      "loss is 0.000001. weight is 0.001927\n",
      "loss is 0.000001. weight is 0.001903\n",
      "loss is 0.000001. weight is 0.001879\n",
      "loss is 0.000001. weight is 0.001856\n"
     ]
    }
   ],
   "source": [
    "for i in range(500):\n",
    "    interactive_sesssion.run(train_step)\n",
    "    loss=interactive_sesssion.run(loss_function)\n",
    "    w=interactive_sesssion.run(weight)\n",
    "    print(\"loss is %f. weight is %f\"%(loss,w))\n",
    "    scatter_output_x.append(i)\n",
    "    scatter_output_y.append(w)\n",
    "    summary_writer.add_summary(interactive_sesssion.run(summaries),i) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fb62075b5c0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb6207b8390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(scatter_output_x,scatter_output_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "running '$tensorboard --logdir= log_simple_stats' will triger tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
