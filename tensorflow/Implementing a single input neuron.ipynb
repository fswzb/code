{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing a single input neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "interactive_sesssion=tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_value = tf.constant(0.5,name=\"input_value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight = tf.Variable(1.0,name=\"weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expected_output = tf.constant(0.0,name=\"expected_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = tf.multiply(input_value, weight,\"model\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss_function = (model - expected_output)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optim = tf.train.GradientDescentOptimizer(learning_rate=0.025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_step=optim.minimize(loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_op=tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "interactive_sesssion.run(init_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scatter_output_x=[]\n",
    "scatter_output_y=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is 0.243789. weight is 0.987500\n",
      "loss is 0.237732. weight is 0.975156\n",
      "loss is 0.231826. weight is 0.962967\n",
      "loss is 0.226067. weight is 0.950930\n",
      "loss is 0.220450. weight is 0.939043\n",
      "loss is 0.214974. weight is 0.927305\n",
      "loss is 0.209633. weight is 0.915714\n",
      "loss is 0.204425. weight is 0.904267\n",
      "loss is 0.199346. weight is 0.892964\n",
      "loss is 0.194394. weight is 0.881802\n",
      "loss is 0.189564. weight is 0.870779\n",
      "loss is 0.184855. weight is 0.859895\n",
      "loss is 0.180262. weight is 0.849146\n",
      "loss is 0.175784. weight is 0.838532\n",
      "loss is 0.171417. weight is 0.828050\n",
      "loss is 0.167158. weight is 0.817699\n",
      "loss is 0.163005. weight is 0.807478\n",
      "loss is 0.158956. weight is 0.797385\n",
      "loss is 0.155006. weight is 0.787417\n",
      "loss is 0.151156. weight is 0.777575\n",
      "loss is 0.147400. weight is 0.767855\n",
      "loss is 0.143738. weight is 0.758257\n",
      "loss is 0.140167. weight is 0.748779\n",
      "loss is 0.136685. weight is 0.739419\n",
      "loss is 0.133289. weight is 0.730176\n",
      "loss is 0.129978. weight is 0.721049\n",
      "loss is 0.126749. weight is 0.712036\n",
      "loss is 0.123600. weight is 0.703135\n",
      "loss is 0.120529. weight is 0.694346\n",
      "loss is 0.117535. weight is 0.685667\n",
      "loss is 0.114615. weight is 0.677096\n",
      "loss is 0.111767. weight is 0.668632\n",
      "loss is 0.108991. weight is 0.660274\n",
      "loss is 0.106283. weight is 0.652021\n",
      "loss is 0.103642. weight is 0.643871\n",
      "loss is 0.101067. weight is 0.635822\n",
      "loss is 0.098557. weight is 0.627874\n",
      "loss is 0.096108. weight is 0.620026\n",
      "loss is 0.093720. weight is 0.612276\n",
      "loss is 0.091392. weight is 0.604622\n",
      "loss is 0.089122. weight is 0.597064\n",
      "loss is 0.086907. weight is 0.589601\n",
      "loss is 0.084748. weight is 0.582231\n",
      "loss is 0.082643. weight is 0.574953\n",
      "loss is 0.080590. weight is 0.567766\n",
      "loss is 0.078588. weight is 0.560669\n",
      "loss is 0.076635. weight is 0.553661\n",
      "loss is 0.074731. weight is 0.546740\n",
      "loss is 0.072875. weight is 0.539906\n",
      "loss is 0.071064. weight is 0.533157\n",
      "loss is 0.069299. weight is 0.526493\n",
      "loss is 0.067577. weight is 0.519911\n",
      "loss is 0.065898. weight is 0.513413\n",
      "loss is 0.064261. weight is 0.506995\n",
      "loss is 0.062664. weight is 0.500657\n",
      "loss is 0.061108. weight is 0.494399\n",
      "loss is 0.059590. weight is 0.488219\n",
      "loss is 0.058109. weight is 0.482117\n",
      "loss is 0.056665. weight is 0.476090\n",
      "loss is 0.055258. weight is 0.470139\n",
      "loss is 0.053885. weight is 0.464262\n",
      "loss is 0.052546. weight is 0.458459\n",
      "loss is 0.051241. weight is 0.452728\n",
      "loss is 0.049968. weight is 0.447069\n",
      "loss is 0.048726. weight is 0.441481\n",
      "loss is 0.047516. weight is 0.435962\n",
      "loss is 0.046335. weight is 0.430513\n",
      "loss is 0.045184. weight is 0.425131\n",
      "loss is 0.044062. weight is 0.419817\n",
      "loss is 0.042967. weight is 0.414569\n",
      "loss is 0.041899. weight is 0.409387\n",
      "loss is 0.040859. weight is 0.404270\n",
      "loss is 0.039843. weight is 0.399217\n",
      "loss is 0.038854. weight is 0.394226\n",
      "loss is 0.037888. weight is 0.389299\n",
      "loss is 0.036947. weight is 0.384432\n",
      "loss is 0.036029. weight is 0.379627\n",
      "loss is 0.035134. weight is 0.374882\n",
      "loss is 0.034261. weight is 0.370196\n",
      "loss is 0.033410. weight is 0.365568\n",
      "loss is 0.032580. weight is 0.360999\n",
      "loss is 0.031771. weight is 0.356486\n",
      "loss is 0.030981. weight is 0.352030\n",
      "loss is 0.030212. weight is 0.347630\n",
      "loss is 0.029461. weight is 0.343284\n",
      "loss is 0.028729. weight is 0.338993\n",
      "loss is 0.028015. weight is 0.334756\n",
      "loss is 0.027319. weight is 0.330571\n",
      "loss is 0.026641. weight is 0.326439\n",
      "loss is 0.025979. weight is 0.322359\n",
      "loss is 0.025333. weight is 0.318329\n",
      "loss is 0.024704. weight is 0.314350\n",
      "loss is 0.024090. weight is 0.310421\n",
      "loss is 0.023492. weight is 0.306540\n",
      "loss is 0.022908. weight is 0.302709\n",
      "loss is 0.022339. weight is 0.298925\n",
      "loss is 0.021784. weight is 0.295188\n",
      "loss is 0.021243. weight is 0.291498\n",
      "loss is 0.020715. weight is 0.287855\n",
      "loss is 0.020200. weight is 0.284257\n",
      "loss is 0.019699. weight is 0.280703\n",
      "loss is 0.019209. weight is 0.277194\n",
      "loss is 0.018732. weight is 0.273730\n",
      "loss is 0.018267. weight is 0.270308\n",
      "loss is 0.017813. weight is 0.266929\n",
      "loss is 0.017370. weight is 0.263593\n",
      "loss is 0.016939. weight is 0.260298\n",
      "loss is 0.016518. weight is 0.257044\n",
      "loss is 0.016108. weight is 0.253831\n",
      "loss is 0.015707. weight is 0.250658\n",
      "loss is 0.015317. weight is 0.247525\n",
      "loss is 0.014937. weight is 0.244431\n",
      "loss is 0.014566. weight is 0.241375\n",
      "loss is 0.014204. weight is 0.238358\n",
      "loss is 0.013851. weight is 0.235379\n",
      "loss is 0.013507. weight is 0.232436\n",
      "loss is 0.013171. weight is 0.229531\n",
      "loss is 0.012844. weight is 0.226662\n",
      "loss is 0.012525. weight is 0.223829\n",
      "loss is 0.012214. weight is 0.221031\n",
      "loss is 0.011910. weight is 0.218268\n",
      "loss is 0.011614. weight is 0.215539\n",
      "loss is 0.011326. weight is 0.212845\n",
      "loss is 0.011044. weight is 0.210185\n",
      "loss is 0.010770. weight is 0.207557\n",
      "loss is 0.010502. weight is 0.204963\n",
      "loss is 0.010242. weight is 0.202401\n",
      "loss is 0.009987. weight is 0.199871\n",
      "loss is 0.009739. weight is 0.197372\n",
      "loss is 0.009497. weight is 0.194905\n",
      "loss is 0.009261. weight is 0.192469\n",
      "loss is 0.009031. weight is 0.190063\n",
      "loss is 0.008807. weight is 0.187687\n",
      "loss is 0.008588. weight is 0.185341\n",
      "loss is 0.008374. weight is 0.183024\n",
      "loss is 0.008166. weight is 0.180737\n",
      "loss is 0.007964. weight is 0.178477\n",
      "loss is 0.007766. weight is 0.176246\n",
      "loss is 0.007573. weight is 0.174043\n",
      "loss is 0.007385. weight is 0.171868\n",
      "loss is 0.007201. weight is 0.169720\n",
      "loss is 0.007022. weight is 0.167598\n",
      "loss is 0.006848. weight is 0.165503\n",
      "loss is 0.006678. weight is 0.163434\n",
      "loss is 0.006512. weight is 0.161391\n",
      "loss is 0.006350. weight is 0.159374\n",
      "loss is 0.006192. weight is 0.157382\n",
      "loss is 0.006038. weight is 0.155414\n",
      "loss is 0.005888. weight is 0.153472\n",
      "loss is 0.005742. weight is 0.151553\n",
      "loss is 0.005599. weight is 0.149659\n",
      "loss is 0.005460. weight is 0.147788\n",
      "loss is 0.005325. weight is 0.145941\n",
      "loss is 0.005192. weight is 0.144117\n",
      "loss is 0.005063. weight is 0.142315\n",
      "loss is 0.004938. weight is 0.140536\n",
      "loss is 0.004815. weight is 0.138780\n",
      "loss is 0.004695. weight is 0.137045\n",
      "loss is 0.004579. weight is 0.135332\n",
      "loss is 0.004465. weight is 0.133640\n",
      "loss is 0.004354. weight is 0.131970\n",
      "loss is 0.004246. weight is 0.130320\n",
      "loss is 0.004140. weight is 0.128691\n",
      "loss is 0.004037. weight is 0.127082\n",
      "loss is 0.003937. weight is 0.125494\n",
      "loss is 0.003839. weight is 0.123925\n",
      "loss is 0.003744. weight is 0.122376\n",
      "loss is 0.003651. weight is 0.120846\n",
      "loss is 0.003560. weight is 0.119336\n",
      "loss is 0.003472. weight is 0.117844\n",
      "loss is 0.003386. weight is 0.116371\n",
      "loss is 0.003301. weight is 0.114916\n",
      "loss is 0.003219. weight is 0.113480\n",
      "loss is 0.003139. weight is 0.112061\n",
      "loss is 0.003061. weight is 0.110661\n",
      "loss is 0.002985. weight is 0.109277\n",
      "loss is 0.002911. weight is 0.107911\n",
      "loss is 0.002839. weight is 0.106563\n",
      "loss is 0.002768. weight is 0.105231\n",
      "loss is 0.002700. weight is 0.103915\n",
      "loss is 0.002633. weight is 0.102616\n",
      "loss is 0.002567. weight is 0.101333\n",
      "loss is 0.002503. weight is 0.100067\n",
      "loss is 0.002441. weight is 0.098816\n",
      "loss is 0.002381. weight is 0.097581\n",
      "loss is 0.002321. weight is 0.096361\n",
      "loss is 0.002264. weight is 0.095157\n",
      "loss is 0.002207. weight is 0.093967\n",
      "loss is 0.002153. weight is 0.092792\n",
      "loss is 0.002099. weight is 0.091633\n",
      "loss is 0.002047. weight is 0.090487\n",
      "loss is 0.001996. weight is 0.089356\n",
      "loss is 0.001947. weight is 0.088239\n",
      "loss is 0.001898. weight is 0.087136\n",
      "loss is 0.001851. weight is 0.086047\n",
      "loss is 0.001805. weight is 0.084971\n",
      "loss is 0.001760. weight is 0.083909\n",
      "loss is 0.001716. weight is 0.082860\n",
      "loss is 0.001674. weight is 0.081825\n",
      "loss is 0.001632. weight is 0.080802\n",
      "loss is 0.001592. weight is 0.079792\n",
      "loss is 0.001552. weight is 0.078794\n",
      "loss is 0.001514. weight is 0.077809\n",
      "loss is 0.001476. weight is 0.076837\n",
      "loss is 0.001439. weight is 0.075876\n",
      "loss is 0.001404. weight is 0.074928\n",
      "loss is 0.001369. weight is 0.073991\n",
      "loss is 0.001335. weight is 0.073066\n",
      "loss is 0.001302. weight is 0.072153\n",
      "loss is 0.001269. weight is 0.071251\n",
      "loss is 0.001238. weight is 0.070361\n",
      "loss is 0.001207. weight is 0.069481\n",
      "loss is 0.001177. weight is 0.068613\n",
      "loss is 0.001148. weight is 0.067755\n",
      "loss is 0.001119. weight is 0.066908\n",
      "loss is 0.001091. weight is 0.066072\n",
      "loss is 0.001064. weight is 0.065246\n",
      "loss is 0.001038. weight is 0.064430\n",
      "loss is 0.001012. weight is 0.063625\n",
      "loss is 0.000987. weight is 0.062829\n",
      "loss is 0.000962. weight is 0.062044\n",
      "loss is 0.000938. weight is 0.061268\n",
      "loss is 0.000915. weight is 0.060503\n",
      "loss is 0.000892. weight is 0.059746\n",
      "loss is 0.000870. weight is 0.059000\n",
      "loss is 0.000849. weight is 0.058262\n",
      "loss is 0.000828. weight is 0.057534\n",
      "loss is 0.000807. weight is 0.056815\n",
      "loss is 0.000787. weight is 0.056104\n",
      "loss is 0.000767. weight is 0.055403\n",
      "loss is 0.000748. weight is 0.054711\n",
      "loss is 0.000730. weight is 0.054027\n",
      "loss is 0.000712. weight is 0.053351\n",
      "loss is 0.000694. weight is 0.052684\n",
      "loss is 0.000677. weight is 0.052026\n",
      "loss is 0.000660. weight is 0.051376\n",
      "loss is 0.000643. weight is 0.050733\n",
      "loss is 0.000627. weight is 0.050099\n",
      "loss is 0.000612. weight is 0.049473\n",
      "loss is 0.000597. weight is 0.048855\n",
      "loss is 0.000582. weight is 0.048244\n",
      "loss is 0.000567. weight is 0.047641\n",
      "loss is 0.000553. weight is 0.047045\n",
      "loss is 0.000540. weight is 0.046457\n",
      "loss is 0.000526. weight is 0.045877\n",
      "loss is 0.000513. weight is 0.045303\n",
      "loss is 0.000500. weight is 0.044737\n",
      "loss is 0.000488. weight is 0.044178\n",
      "loss is 0.000476. weight is 0.043625\n",
      "loss is 0.000464. weight is 0.043080\n",
      "loss is 0.000452. weight is 0.042542\n",
      "loss is 0.000441. weight is 0.042010\n",
      "loss is 0.000430. weight is 0.041485\n",
      "loss is 0.000420. weight is 0.040966\n",
      "loss is 0.000409. weight is 0.040454\n",
      "loss is 0.000399. weight is 0.039948\n",
      "loss is 0.000389. weight is 0.039449\n",
      "loss is 0.000379. weight is 0.038956\n",
      "loss is 0.000370. weight is 0.038469\n",
      "loss is 0.000361. weight is 0.037988\n",
      "loss is 0.000352. weight is 0.037513\n",
      "loss is 0.000343. weight is 0.037044\n",
      "loss is 0.000335. weight is 0.036581\n",
      "loss is 0.000326. weight is 0.036124\n",
      "loss is 0.000318. weight is 0.035672\n",
      "loss is 0.000310. weight is 0.035227\n",
      "loss is 0.000303. weight is 0.034786\n",
      "loss is 0.000295. weight is 0.034351\n",
      "loss is 0.000288. weight is 0.033922\n",
      "loss is 0.000281. weight is 0.033498\n",
      "loss is 0.000274. weight is 0.033079\n",
      "loss is 0.000267. weight is 0.032666\n",
      "loss is 0.000260. weight is 0.032257\n",
      "loss is 0.000254. weight is 0.031854\n",
      "loss is 0.000247. weight is 0.031456\n",
      "loss is 0.000241. weight is 0.031063\n",
      "loss is 0.000235. weight is 0.030675\n",
      "loss is 0.000229. weight is 0.030291\n",
      "loss is 0.000224. weight is 0.029912\n",
      "loss is 0.000218. weight is 0.029539\n",
      "loss is 0.000213. weight is 0.029169\n",
      "loss is 0.000207. weight is 0.028805\n",
      "loss is 0.000202. weight is 0.028445\n",
      "loss is 0.000197. weight is 0.028089\n",
      "loss is 0.000192. weight is 0.027738\n",
      "loss is 0.000188. weight is 0.027391\n",
      "loss is 0.000183. weight is 0.027049\n",
      "loss is 0.000178. weight is 0.026711\n",
      "loss is 0.000174. weight is 0.026377\n",
      "loss is 0.000170. weight is 0.026047\n",
      "loss is 0.000165. weight is 0.025722\n",
      "loss is 0.000161. weight is 0.025400\n",
      "loss is 0.000157. weight is 0.025083\n",
      "loss is 0.000153. weight is 0.024769\n",
      "loss is 0.000150. weight is 0.024459\n",
      "loss is 0.000146. weight is 0.024154\n",
      "loss is 0.000142. weight is 0.023852\n",
      "loss is 0.000139. weight is 0.023554\n",
      "loss is 0.000135. weight is 0.023259\n",
      "loss is 0.000132. weight is 0.022968\n",
      "loss is 0.000129. weight is 0.022681\n",
      "loss is 0.000125. weight is 0.022398\n",
      "loss is 0.000122. weight is 0.022118\n",
      "loss is 0.000119. weight is 0.021841\n",
      "loss is 0.000116. weight is 0.021568\n",
      "loss is 0.000113. weight is 0.021299\n",
      "loss is 0.000111. weight is 0.021033\n",
      "loss is 0.000108. weight is 0.020770\n",
      "loss is 0.000105. weight is 0.020510\n",
      "loss is 0.000103. weight is 0.020254\n",
      "loss is 0.000100. weight is 0.020000\n",
      "loss is 0.000098. weight is 0.019750\n",
      "loss is 0.000095. weight is 0.019504\n",
      "loss is 0.000093. weight is 0.019260\n",
      "loss is 0.000090. weight is 0.019019\n",
      "loss is 0.000088. weight is 0.018781\n",
      "loss is 0.000086. weight is 0.018547\n",
      "loss is 0.000084. weight is 0.018315\n",
      "loss is 0.000082. weight is 0.018086\n",
      "loss is 0.000080. weight is 0.017860\n",
      "loss is 0.000078. weight is 0.017636\n",
      "loss is 0.000076. weight is 0.017416\n",
      "loss is 0.000074. weight is 0.017198\n",
      "loss is 0.000072. weight is 0.016983\n",
      "loss is 0.000070. weight is 0.016771\n",
      "loss is 0.000069. weight is 0.016561\n",
      "loss is 0.000067. weight is 0.016354\n",
      "loss is 0.000065. weight is 0.016150\n",
      "loss is 0.000064. weight is 0.015948\n",
      "loss is 0.000062. weight is 0.015749\n",
      "loss is 0.000060. weight is 0.015552\n",
      "loss is 0.000059. weight is 0.015357\n",
      "loss is 0.000057. weight is 0.015165\n",
      "loss is 0.000056. weight is 0.014976\n",
      "loss is 0.000055. weight is 0.014789\n",
      "loss is 0.000053. weight is 0.014604\n",
      "loss is 0.000052. weight is 0.014421\n",
      "loss is 0.000051. weight is 0.014241\n",
      "loss is 0.000049. weight is 0.014063\n",
      "loss is 0.000048. weight is 0.013887\n",
      "loss is 0.000047. weight is 0.013714\n",
      "loss is 0.000046. weight is 0.013542\n",
      "loss is 0.000045. weight is 0.013373\n",
      "loss is 0.000044. weight is 0.013206\n",
      "loss is 0.000043. weight is 0.013041\n",
      "loss is 0.000041. weight is 0.012878\n",
      "loss is 0.000040. weight is 0.012717\n",
      "loss is 0.000039. weight is 0.012558\n",
      "loss is 0.000038. weight is 0.012401\n",
      "loss is 0.000037. weight is 0.012246\n",
      "loss is 0.000037. weight is 0.012093\n",
      "loss is 0.000036. weight is 0.011942\n",
      "loss is 0.000035. weight is 0.011792\n",
      "loss is 0.000034. weight is 0.011645\n",
      "loss is 0.000033. weight is 0.011499\n",
      "loss is 0.000032. weight is 0.011356\n",
      "loss is 0.000031. weight is 0.011214\n",
      "loss is 0.000031. weight is 0.011073\n",
      "loss is 0.000030. weight is 0.010935\n",
      "loss is 0.000029. weight is 0.010798\n",
      "loss is 0.000028. weight is 0.010663\n",
      "loss is 0.000028. weight is 0.010530\n",
      "loss is 0.000027. weight is 0.010398\n",
      "loss is 0.000026. weight is 0.010268\n",
      "loss is 0.000026. weight is 0.010140\n",
      "loss is 0.000025. weight is 0.010013\n",
      "loss is 0.000024. weight is 0.009888\n",
      "loss is 0.000024. weight is 0.009765\n",
      "loss is 0.000023. weight is 0.009643\n",
      "loss is 0.000023. weight is 0.009522\n",
      "loss is 0.000022. weight is 0.009403\n",
      "loss is 0.000022. weight is 0.009285\n",
      "loss is 0.000021. weight is 0.009169\n",
      "loss is 0.000020. weight is 0.009055\n",
      "loss is 0.000020. weight is 0.008942\n",
      "loss is 0.000019. weight is 0.008830\n",
      "loss is 0.000019. weight is 0.008719\n",
      "loss is 0.000019. weight is 0.008610\n",
      "loss is 0.000018. weight is 0.008503\n",
      "loss is 0.000018. weight is 0.008397\n",
      "loss is 0.000017. weight is 0.008292\n",
      "loss is 0.000017. weight is 0.008188\n",
      "loss is 0.000016. weight is 0.008086\n",
      "loss is 0.000016. weight is 0.007985\n",
      "loss is 0.000016. weight is 0.007885\n",
      "loss is 0.000015. weight is 0.007786\n",
      "loss is 0.000015. weight is 0.007689\n",
      "loss is 0.000014. weight is 0.007593\n",
      "loss is 0.000014. weight is 0.007498\n",
      "loss is 0.000014. weight is 0.007404\n",
      "loss is 0.000013. weight is 0.007312\n",
      "loss is 0.000013. weight is 0.007220\n",
      "loss is 0.000013. weight is 0.007130\n",
      "loss is 0.000012. weight is 0.007041\n",
      "loss is 0.000012. weight is 0.006953\n",
      "loss is 0.000012. weight is 0.006866\n",
      "loss is 0.000011. weight is 0.006780\n",
      "loss is 0.000011. weight is 0.006695\n",
      "loss is 0.000011. weight is 0.006612\n",
      "loss is 0.000011. weight is 0.006529\n",
      "loss is 0.000010. weight is 0.006447\n",
      "loss is 0.000010. weight is 0.006367\n",
      "loss is 0.000010. weight is 0.006287\n",
      "loss is 0.000010. weight is 0.006209\n",
      "loss is 0.000009. weight is 0.006131\n",
      "loss is 0.000009. weight is 0.006054\n",
      "loss is 0.000009. weight is 0.005979\n",
      "loss is 0.000009. weight is 0.005904\n",
      "loss is 0.000008. weight is 0.005830\n",
      "loss is 0.000008. weight is 0.005757\n",
      "loss is 0.000008. weight is 0.005685\n",
      "loss is 0.000008. weight is 0.005614\n",
      "loss is 0.000008. weight is 0.005544\n",
      "loss is 0.000007. weight is 0.005475\n",
      "loss is 0.000007. weight is 0.005406\n",
      "loss is 0.000007. weight is 0.005339\n",
      "loss is 0.000007. weight is 0.005272\n",
      "loss is 0.000007. weight is 0.005206\n",
      "loss is 0.000007. weight is 0.005141\n",
      "loss is 0.000006. weight is 0.005077\n",
      "loss is 0.000006. weight is 0.005013\n",
      "loss is 0.000006. weight is 0.004951\n",
      "loss is 0.000006. weight is 0.004889\n",
      "loss is 0.000006. weight is 0.004828\n",
      "loss is 0.000006. weight is 0.004767\n",
      "loss is 0.000006. weight is 0.004708\n",
      "loss is 0.000005. weight is 0.004649\n",
      "loss is 0.000005. weight is 0.004591\n",
      "loss is 0.000005. weight is 0.004533\n",
      "loss is 0.000005. weight is 0.004477\n",
      "loss is 0.000005. weight is 0.004421\n",
      "loss is 0.000005. weight is 0.004365\n",
      "loss is 0.000005. weight is 0.004311\n",
      "loss is 0.000005. weight is 0.004257\n",
      "loss is 0.000004. weight is 0.004204\n",
      "loss is 0.000004. weight is 0.004151\n",
      "loss is 0.000004. weight is 0.004099\n",
      "loss is 0.000004. weight is 0.004048\n",
      "loss is 0.000004. weight is 0.003998\n",
      "loss is 0.000004. weight is 0.003948\n",
      "loss is 0.000004. weight is 0.003898\n",
      "loss is 0.000004. weight is 0.003849\n",
      "loss is 0.000004. weight is 0.003801\n",
      "loss is 0.000004. weight is 0.003754\n",
      "loss is 0.000003. weight is 0.003707\n",
      "loss is 0.000003. weight is 0.003661\n",
      "loss is 0.000003. weight is 0.003615\n",
      "loss is 0.000003. weight is 0.003570\n",
      "loss is 0.000003. weight is 0.003525\n",
      "loss is 0.000003. weight is 0.003481\n",
      "loss is 0.000003. weight is 0.003437\n",
      "loss is 0.000003. weight is 0.003394\n",
      "loss is 0.000003. weight is 0.003352\n",
      "loss is 0.000003. weight is 0.003310\n",
      "loss is 0.000003. weight is 0.003269\n",
      "loss is 0.000003. weight is 0.003228\n",
      "loss is 0.000003. weight is 0.003188\n",
      "loss is 0.000002. weight is 0.003148\n",
      "loss is 0.000002. weight is 0.003108\n",
      "loss is 0.000002. weight is 0.003070\n",
      "loss is 0.000002. weight is 0.003031\n",
      "loss is 0.000002. weight is 0.002993\n",
      "loss is 0.000002. weight is 0.002956\n",
      "loss is 0.000002. weight is 0.002919\n",
      "loss is 0.000002. weight is 0.002882\n",
      "loss is 0.000002. weight is 0.002846\n",
      "loss is 0.000002. weight is 0.002811\n",
      "loss is 0.000002. weight is 0.002776\n",
      "loss is 0.000002. weight is 0.002741\n",
      "loss is 0.000002. weight is 0.002707\n",
      "loss is 0.000002. weight is 0.002673\n",
      "loss is 0.000002. weight is 0.002639\n",
      "loss is 0.000002. weight is 0.002606\n",
      "loss is 0.000002. weight is 0.002574\n",
      "loss is 0.000002. weight is 0.002542\n",
      "loss is 0.000002. weight is 0.002510\n",
      "loss is 0.000002. weight is 0.002479\n",
      "loss is 0.000001. weight is 0.002448\n",
      "loss is 0.000001. weight is 0.002417\n",
      "loss is 0.000001. weight is 0.002387\n",
      "loss is 0.000001. weight is 0.002357\n",
      "loss is 0.000001. weight is 0.002327\n",
      "loss is 0.000001. weight is 0.002298\n",
      "loss is 0.000001. weight is 0.002270\n",
      "loss is 0.000001. weight is 0.002241\n",
      "loss is 0.000001. weight is 0.002213\n",
      "loss is 0.000001. weight is 0.002186\n",
      "loss is 0.000001. weight is 0.002158\n",
      "loss is 0.000001. weight is 0.002131\n",
      "loss is 0.000001. weight is 0.002105\n",
      "loss is 0.000001. weight is 0.002078\n",
      "loss is 0.000001. weight is 0.002052\n",
      "loss is 0.000001. weight is 0.002027\n",
      "loss is 0.000001. weight is 0.002001\n",
      "loss is 0.000001. weight is 0.001976\n",
      "loss is 0.000001. weight is 0.001952\n",
      "loss is 0.000001. weight is 0.001927\n",
      "loss is 0.000001. weight is 0.001903\n",
      "loss is 0.000001. weight is 0.001879\n",
      "loss is 0.000001. weight is 0.001856\n"
     ]
    }
   ],
   "source": [
    "for i in range(500):\n",
    "    interactive_sesssion.run(train_step)\n",
    "    loss=interactive_sesssion.run(loss_function)\n",
    "    w=interactive_sesssion.run(weight)\n",
    "    print(\"loss is %f. weight is %f\"%(loss,w))\n",
    "    scatter_output_x.append(i)\n",
    "    scatter_output_y.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f79f8264b00>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nl6QaMtwlqYYMd0mqIcNdkmro/wEWpPMDR85zmQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f797f329f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(scatter_output_x,scatter_output_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
