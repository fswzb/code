{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy.random import RandomState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w1=tf.Variable(tf.random_normal([2,3],stddev=1,seed=1))\n",
    "w2=tf.Variable(tf.random_normal([3,1],stddev=1,seed=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "forward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x=tf.placeholder(tf.float32,shape=(None,2),name='x-input')\n",
    "y_=tf.placeholder(tf.float32,shape=(None,1),name='y-input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=tf.matmul(x,w1)\n",
    "y=tf.matmul(a,w2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "back propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy=-tf.reduce_mean(y_ * tf.log(tf.clip_by_value(y,1e-10,1.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_step=tf.train.AdamOptimizer(0.001).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdm=RandomState(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class RandomState in module numpy.random.mtrand:\n",
      "\n",
      "class RandomState(builtins.object)\n",
      " |  RandomState(seed=None)\n",
      " |  \n",
      " |  Container for the Mersenne Twister pseudo-random number generator.\n",
      " |  \n",
      " |  `RandomState` exposes a number of methods for generating random numbers\n",
      " |  drawn from a variety of probability distributions. In addition to the\n",
      " |  distribution-specific arguments, each method takes a keyword argument\n",
      " |  `size` that defaults to ``None``. If `size` is ``None``, then a single\n",
      " |  value is generated and returned. If `size` is an integer, then a 1-D\n",
      " |  array filled with generated values is returned. If `size` is a tuple,\n",
      " |  then an array with that shape is filled and returned.\n",
      " |  \n",
      " |  *Compatibility Guarantee*\n",
      " |  A fixed seed and a fixed series of calls to 'RandomState' methods using\n",
      " |  the same parameters will always produce the same results up to roundoff\n",
      " |  error except when the values were incorrect. Incorrect values will be\n",
      " |  fixed and the NumPy version in which the fix was made will be noted in\n",
      " |  the relevant docstring. Extension of existing parameter ranges and the\n",
      " |  addition of new parameters is allowed as long the previous behavior\n",
      " |  remains unchanged.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  seed : {None, int, array_like}, optional\n",
      " |      Random seed used to initialize the pseudo-random number generator.  Can\n",
      " |      be any integer between 0 and 2**32 - 1 inclusive, an array (or other\n",
      " |      sequence) of such integers, or ``None`` (the default).  If `seed` is\n",
      " |      ``None``, then `RandomState` will try to read data from\n",
      " |      ``/dev/urandom`` (or the Windows analogue) if available or seed from\n",
      " |      the clock otherwise.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The Python stdlib module \"random\" also contains a Mersenne Twister\n",
      " |  pseudo-random number generator with a number of methods that are similar\n",
      " |  to the ones available in `RandomState`. `RandomState`, besides being\n",
      " |  NumPy-aware, has the advantage that it provides a much larger number\n",
      " |  of probability distributions to choose from.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __getstate__(...)\n",
      " |  \n",
      " |  __init__(self, /, *args, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from builtins.type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  __reduce__(...)\n",
      " |      helper for pickle\n",
      " |  \n",
      " |  __setstate__(...)\n",
      " |  \n",
      " |  beta(...)\n",
      " |      beta(a, b, size=None)\n",
      " |      \n",
      " |      Draw samples from a Beta distribution.\n",
      " |      \n",
      " |      The Beta distribution is a special case of the Dirichlet distribution,\n",
      " |      and is related to the Gamma distribution.  It has the probability\n",
      " |      distribution function\n",
      " |      \n",
      " |      .. math:: f(x; a,b) = \\frac{1}{B(\\alpha, \\beta)} x^{\\alpha - 1}\n",
      " |                                                       (1 - x)^{\\beta - 1},\n",
      " |      \n",
      " |      where the normalisation, B, is the beta function,\n",
      " |      \n",
      " |      .. math:: B(\\alpha, \\beta) = \\int_0^1 t^{\\alpha - 1}\n",
      " |                                   (1 - t)^{\\beta - 1} dt.\n",
      " |      \n",
      " |      It is often seen in Bayesian inference and order statistics.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      a : float or array_like of floats\n",
      " |          Alpha, non-negative.\n",
      " |      b : float or array_like of floats\n",
      " |          Beta, non-negative.\n",
      " |      size : int or tuple of ints, optional\n",
      " |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      " |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      " |          a single value is returned if ``a`` and ``b`` are both scalars.\n",
      " |          Otherwise, ``np.broadcast(a, b).size`` samples are drawn.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : ndarray or scalar\n",
      " |          Drawn samples from the parameterized beta distribution.\n",
      " |  \n",
      " |  binomial(...)\n",
      " |      binomial(n, p, size=None)\n",
      " |      \n",
      " |      Draw samples from a binomial distribution.\n",
      " |      \n",
      " |      Samples are drawn from a binomial distribution with specified\n",
      " |      parameters, n trials and p probability of success where\n",
      " |      n an integer >= 0 and p is in the interval [0,1]. (n may be\n",
      " |      input as a float, but it is truncated to an integer in use)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int or array_like of ints\n",
      " |          Parameter of the distribution, >= 0. Floats are also accepted,\n",
      " |          but they will be truncated to integers.\n",
      " |      p : float or array_like of floats\n",
      " |          Parameter of the distribution, >= 0 and <=1.\n",
      " |      size : int or tuple of ints, optional\n",
      " |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      " |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      " |          a single value is returned if ``n`` and ``p`` are both scalars.\n",
      " |          Otherwise, ``np.broadcast(n, p).size`` samples are drawn.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : ndarray or scalar\n",
      " |          Drawn samples from the parameterized binomial distribution, where\n",
      " |          each sample is equal to the number of successes over the n trials.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      scipy.stats.binom : probability density function, distribution or\n",
      " |          cumulative density function, etc.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The probability density for the binomial distribution is\n",
      " |      \n",
      " |      .. math:: P(N) = \\binom{n}{N}p^N(1-p)^{n-N},\n",
      " |      \n",
      " |      where :math:`n` is the number of trials, :math:`p` is the probability\n",
      " |      of success, and :math:`N` is the number of successes.\n",
      " |      \n",
      " |      When estimating the standard error of a proportion in a population by\n",
      " |      using a random sample, the normal distribution works well unless the\n",
      " |      product p*n <=5, where p = population proportion estimate, and n =\n",
      " |      number of samples, in which case the binomial distribution is used\n",
      " |      instead. For example, a sample of 15 people shows 4 who are left\n",
      " |      handed, and 11 who are right handed. Then p = 4/15 = 27%. 0.27*15 = 4,\n",
      " |      so the binomial distribution should be used in this case.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] Dalgaard, Peter, \"Introductory Statistics with R\",\n",
      " |             Springer-Verlag, 2002.\n",
      " |      .. [2] Glantz, Stanton A. \"Primer of Biostatistics.\", McGraw-Hill,\n",
      " |             Fifth Edition, 2002.\n",
      " |      .. [3] Lentner, Marvin, \"Elementary Applied Statistics\", Bogden\n",
      " |             and Quigley, 1972.\n",
      " |      .. [4] Weisstein, Eric W. \"Binomial Distribution.\" From MathWorld--A\n",
      " |             Wolfram Web Resource.\n",
      " |             http://mathworld.wolfram.com/BinomialDistribution.html\n",
      " |      .. [5] Wikipedia, \"Binomial distribution\",\n",
      " |             http://en.wikipedia.org/wiki/Binomial_distribution\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Draw samples from the distribution:\n",
      " |      \n",
      " |      >>> n, p = 10, .5  # number of trials, probability of each trial\n",
      " |      >>> s = np.random.binomial(n, p, 1000)\n",
      " |      # result of flipping a coin 10 times, tested 1000 times.\n",
      " |      \n",
      " |      A real world example. A company drills 9 wild-cat oil exploration\n",
      " |      wells, each with an estimated probability of success of 0.1. All nine\n",
      " |      wells fail. What is the probability of that happening?\n",
      " |      \n",
      " |      Let's do 20,000 trials of the model, and count the number that\n",
      " |      generate zero positive results.\n",
      " |      \n",
      " |      >>> sum(np.random.binomial(9, 0.1, 20000) == 0)/20000.\n",
      " |      # answer = 0.38885, or 38%.\n",
      " |  \n",
      " |  bytes(...)\n",
      " |      bytes(length)\n",
      " |      \n",
      " |      Return random bytes.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      length : int\n",
      " |          Number of random bytes.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : str\n",
      " |          String of length `length`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> np.random.bytes(10)\n",
      " |      ' eh\\x85\\x022SZ\\xbf\\xa4' #random\n",
      " |  \n",
      " |  chisquare(...)\n",
      " |      chisquare(df, size=None)\n",
      " |      \n",
      " |      Draw samples from a chi-square distribution.\n",
      " |      \n",
      " |      When `df` independent random variables, each with standard normal\n",
      " |      distributions (mean 0, variance 1), are squared and summed, the\n",
      " |      resulting distribution is chi-square (see Notes).  This distribution\n",
      " |      is often used in hypothesis testing.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      df : int or array_like of ints\n",
      " |           Number of degrees of freedom.\n",
      " |      size : int or tuple of ints, optional\n",
      " |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      " |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      " |          a single value is returned if ``df`` is a scalar.  Otherwise,\n",
      " |          ``np.array(df).size`` samples are drawn.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : ndarray or scalar\n",
      " |          Drawn samples from the parameterized chi-square distribution.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          When `df` <= 0 or when an inappropriate `size` (e.g. ``size=-1``)\n",
      " |          is given.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The variable obtained by summing the squares of `df` independent,\n",
      " |      standard normally distributed random variables:\n",
      " |      \n",
      " |      .. math:: Q = \\sum_{i=0}^{\\mathtt{df}} X^2_i\n",
      " |      \n",
      " |      is chi-square distributed, denoted\n",
      " |      \n",
      " |      .. math:: Q \\sim \\chi^2_k.\n",
      " |      \n",
      " |      The probability density function of the chi-squared distribution is\n",
      " |      \n",
      " |      .. math:: p(x) = \\frac{(1/2)^{k/2}}{\\Gamma(k/2)}\n",
      " |                       x^{k/2 - 1} e^{-x/2},\n",
      " |      \n",
      " |      where :math:`\\Gamma` is the gamma function,\n",
      " |      \n",
      " |      .. math:: \\Gamma(x) = \\int_0^{-\\infty} t^{x - 1} e^{-t} dt.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] NIST \"Engineering Statistics Handbook\"\n",
      " |             http://www.itl.nist.gov/div898/handbook/eda/section3/eda3666.htm\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> np.random.chisquare(2,4)\n",
      " |      array([ 1.89920014,  9.00867716,  3.13710533,  5.62318272])\n",
      " |  \n",
      " |  choice(...)\n",
      " |      choice(a, size=None, replace=True, p=None)\n",
      " |      \n",
      " |      Generates a random sample from a given 1-D array\n",
      " |      \n",
      " |              .. versionadded:: 1.7.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      -----------\n",
      " |      a : 1-D array-like or int\n",
      " |          If an ndarray, a random sample is generated from its elements.\n",
      " |          If an int, the random sample is generated as if a was np.arange(n)\n",
      " |      size : int or tuple of ints, optional\n",
      " |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      " |          ``m * n * k`` samples are drawn.  Default is None, in which case a\n",
      " |          single value is returned.\n",
      " |      replace : boolean, optional\n",
      " |          Whether the sample is with or without replacement\n",
      " |      p : 1-D array-like, optional\n",
      " |          The probabilities associated with each entry in a.\n",
      " |          If not given the sample assumes a uniform distribution over all\n",
      " |          entries in a.\n",
      " |      \n",
      " |      Returns\n",
      " |      --------\n",
      " |      samples : 1-D ndarray, shape (size,)\n",
      " |          The generated random samples\n",
      " |      \n",
      " |      Raises\n",
      " |      -------\n",
      " |      ValueError\n",
      " |          If a is an int and less than zero, if a or p are not 1-dimensional,\n",
      " |          if a is an array-like of size 0, if p is not a vector of\n",
      " |          probabilities, if a and p have different lengths, or if\n",
      " |          replace=False and the sample size is greater than the population\n",
      " |          size\n",
      " |      \n",
      " |      See Also\n",
      " |      ---------\n",
      " |      randint, shuffle, permutation\n",
      " |      \n",
      " |      Examples\n",
      " |      ---------\n",
      " |      Generate a uniform random sample from np.arange(5) of size 3:\n",
      " |      \n",
      " |      >>> np.random.choice(5, 3)\n",
      " |      array([0, 3, 4])\n",
      " |      >>> #This is equivalent to np.random.randint(0,5,3)\n",
      " |      \n",
      " |      Generate a non-uniform random sample from np.arange(5) of size 3:\n",
      " |      \n",
      " |      >>> np.random.choice(5, 3, p=[0.1, 0, 0.3, 0.6, 0])\n",
      " |      array([3, 3, 0])\n",
      " |      \n",
      " |      Generate a uniform random sample from np.arange(5) of size 3 without\n",
      " |      replacement:\n",
      " |      \n",
      " |      >>> np.random.choice(5, 3, replace=False)\n",
      " |      array([3,1,0])\n",
      " |      >>> #This is equivalent to np.random.permutation(np.arange(5))[:3]\n",
      " |      \n",
      " |      Generate a non-uniform random sample from np.arange(5) of size\n",
      " |      3 without replacement:\n",
      " |      \n",
      " |      >>> np.random.choice(5, 3, replace=False, p=[0.1, 0, 0.3, 0.6, 0])\n",
      " |      array([2, 3, 0])\n",
      " |      \n",
      " |      Any of the above can be repeated with an arbitrary array-like\n",
      " |      instead of just integers. For instance:\n",
      " |      \n",
      " |      >>> aa_milne_arr = ['pooh', 'rabbit', 'piglet', 'Christopher']\n",
      " |      >>> np.random.choice(aa_milne_arr, 5, p=[0.5, 0.1, 0.1, 0.3])\n",
      " |      array(['pooh', 'pooh', 'pooh', 'Christopher', 'piglet'],\n",
      " |            dtype='|S11')\n",
      " |  \n",
      " |  dirichlet(...)\n",
      " |      dirichlet(alpha, size=None)\n",
      " |      \n",
      " |      Draw samples from the Dirichlet distribution.\n",
      " |      \n",
      " |      Draw `size` samples of dimension k from a Dirichlet distribution. A\n",
      " |      Dirichlet-distributed random variable can be seen as a multivariate\n",
      " |      generalization of a Beta distribution. Dirichlet pdf is the conjugate\n",
      " |      prior of a multinomial in Bayesian inference.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      alpha : array\n",
      " |          Parameter of the distribution (k dimension for sample of\n",
      " |          dimension k).\n",
      " |      size : int or tuple of ints, optional\n",
      " |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      " |          ``m * n * k`` samples are drawn.  Default is None, in which case a\n",
      " |          single value is returned.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      samples : ndarray,\n",
      " |          The drawn samples, of shape (size, alpha.ndim).\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      .. math:: X \\approx \\prod_{i=1}^{k}{x^{\\alpha_i-1}_i}\n",
      " |      \n",
      " |      Uses the following property for computation: for each dimension,\n",
      " |      draw a random sample y_i from a standard gamma generator of shape\n",
      " |      `alpha_i`, then\n",
      " |      :math:`X = \\frac{1}{\\sum_{i=1}^k{y_i}} (y_1, \\ldots, y_n)` is\n",
      " |      Dirichlet distributed.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] David McKay, \"Information Theory, Inference and Learning\n",
      " |             Algorithms,\" chapter 23,\n",
      " |             http://www.inference.phy.cam.ac.uk/mackay/\n",
      " |      .. [2] Wikipedia, \"Dirichlet distribution\",\n",
      " |             http://en.wikipedia.org/wiki/Dirichlet_distribution\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Taking an example cited in Wikipedia, this distribution can be used if\n",
      " |      one wanted to cut strings (each of initial length 1.0) into K pieces\n",
      " |      with different lengths, where each piece had, on average, a designated\n",
      " |      average length, but allowing some variation in the relative sizes of\n",
      " |      the pieces.\n",
      " |      \n",
      " |      >>> s = np.random.dirichlet((10, 5, 3), 20).transpose()\n",
      " |      \n",
      " |      >>> plt.barh(range(20), s[0])\n",
      " |      >>> plt.barh(range(20), s[1], left=s[0], color='g')\n",
      " |      >>> plt.barh(range(20), s[2], left=s[0]+s[1], color='r')\n",
      " |      >>> plt.title(\"Lengths of Strings\")\n",
      " |  \n",
      " |  exponential(...)\n",
      " |      exponential(scale=1.0, size=None)\n",
      " |      \n",
      " |      Draw samples from an exponential distribution.\n",
      " |      \n",
      " |      Its probability density function is\n",
      " |      \n",
      " |      .. math:: f(x; \\frac{1}{\\beta}) = \\frac{1}{\\beta} \\exp(-\\frac{x}{\\beta}),\n",
      " |      \n",
      " |      for ``x > 0`` and 0 elsewhere. :math:`\\beta` is the scale parameter,\n",
      " |      which is the inverse of the rate parameter :math:`\\lambda = 1/\\beta`.\n",
      " |      The rate parameter is an alternative, widely used parameterization\n",
      " |      of the exponential distribution [3]_.\n",
      " |      \n",
      " |      The exponential distribution is a continuous analogue of the\n",
      " |      geometric distribution.  It describes many common situations, such as\n",
      " |      the size of raindrops measured over many rainstorms [1]_, or the time\n",
      " |      between page requests to Wikipedia [2]_.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      scale : float or array_like of floats\n",
      " |          The scale parameter, :math:`\\beta = 1/\\lambda`.\n",
      " |      size : int or tuple of ints, optional\n",
      " |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      " |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      " |          a single value is returned if ``scale`` is a scalar.  Otherwise,\n",
      " |          ``np.array(scale).size`` samples are drawn.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : ndarray or scalar\n",
      " |          Drawn samples from the parameterized exponential distribution.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] Peyton Z. Peebles Jr., \"Probability, Random Variables and\n",
      " |             Random Signal Principles\", 4th ed, 2001, p. 57.\n",
      " |      .. [2] Wikipedia, \"Poisson process\",\n",
      " |             http://en.wikipedia.org/wiki/Poisson_process\n",
      " |      .. [3] Wikipedia, \"Exponential distribution\",\n",
      " |             http://en.wikipedia.org/wiki/Exponential_distribution\n",
      " |  \n",
      " |  f(...)\n",
      " |      f(dfnum, dfden, size=None)\n",
      " |      \n",
      " |      Draw samples from an F distribution.\n",
      " |      \n",
      " |      Samples are drawn from an F distribution with specified parameters,\n",
      " |      `dfnum` (degrees of freedom in numerator) and `dfden` (degrees of\n",
      " |      freedom in denominator), where both parameters should be greater than\n",
      " |      zero.\n",
      " |      \n",
      " |      The random variate of the F distribution (also known as the\n",
      " |      Fisher distribution) is a continuous probability distribution\n",
      " |      that arises in ANOVA tests, and is the ratio of two chi-square\n",
      " |      variates.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dfnum : int or array_like of ints\n",
      " |          Degrees of freedom in numerator. Should be greater than zero.\n",
      " |      dfden : int or array_like of ints\n",
      " |          Degrees of freedom in denominator. Should be greater than zero.\n",
      " |      size : int or tuple of ints, optional\n",
      " |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      " |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      " |          a single value is returned if ``dfnum`` and ``dfden`` are both scalars.\n",
      " |          Otherwise, ``np.broadcast(dfnum, dfden).size`` samples are drawn.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : ndarray or scalar\n",
      " |          Drawn samples from the parameterized Fisher distribution.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      scipy.stats.f : probability density function, distribution or\n",
      " |          cumulative density function, etc.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The F statistic is used to compare in-group variances to between-group\n",
      " |      variances. Calculating the distribution depends on the sampling, and\n",
      " |      so it is a function of the respective degrees of freedom in the\n",
      " |      problem.  The variable `dfnum` is the number of samples minus one, the\n",
      " |      between-groups degrees of freedom, while `dfden` is the within-groups\n",
      " |      degrees of freedom, the sum of the number of samples in each group\n",
      " |      minus the number of groups.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] Glantz, Stanton A. \"Primer of Biostatistics.\", McGraw-Hill,\n",
      " |             Fifth Edition, 2002.\n",
      " |      .. [2] Wikipedia, \"F-distribution\",\n",
      " |             http://en.wikipedia.org/wiki/F-distribution\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      An example from Glantz[1], pp 47-40:\n",
      " |      \n",
      " |      Two groups, children of diabetics (25 people) and children from people\n",
      " |      without diabetes (25 controls). Fasting blood glucose was measured,\n",
      " |      case group had a mean value of 86.1, controls had a mean value of\n",
      " |      82.2. Standard deviations were 2.09 and 2.49 respectively. Are these\n",
      " |      data consistent with the null hypothesis that the parents diabetic\n",
      " |      status does not affect their children's blood glucose levels?\n",
      " |      Calculating the F statistic from the data gives a value of 36.01.\n",
      " |      \n",
      " |      Draw samples from the distribution:\n",
      " |      \n",
      " |      >>> dfnum = 1. # between group degrees of freedom\n",
      " |      >>> dfden = 48. # within groups degrees of freedom\n",
      " |      >>> s = np.random.f(dfnum, dfden, 1000)\n",
      " |      \n",
      " |      The lower bound for the top 1% of the samples is :\n",
      " |      \n",
      " |      >>> sort(s)[-10]\n",
      " |      7.61988120985\n",
      " |      \n",
      " |      So there is about a 1% chance that the F statistic will exceed 7.62,\n",
      " |      the measured value is 36, so the null hypothesis is rejected at the 1%\n",
      " |      level.\n",
      " |  \n",
      " |  gamma(...)\n",
      " |      gamma(shape, scale=1.0, size=None)\n",
      " |      \n",
      " |      Draw samples from a Gamma distribution.\n",
      " |      \n",
      " |      Samples are drawn from a Gamma distribution with specified parameters,\n",
      " |      `shape` (sometimes designated \"k\") and `scale` (sometimes designated\n",
      " |      \"theta\"), where both parameters are > 0.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      shape : float or array_like of floats\n",
      " |          The shape of the gamma distribution. Should be greater than zero.\n",
      " |      scale : float or array_like of floats, optional\n",
      " |          The scale of the gamma distribution. Should be greater than zero.\n",
      " |          Default is equal to 1.\n",
      " |      size : int or tuple of ints, optional\n",
      " |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      " |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      " |          a single value is returned if ``shape`` and ``scale`` are both scalars.\n",
      " |          Otherwise, ``np.broadcast(shape, scale).size`` samples are drawn.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : ndarray or scalar\n",
      " |          Drawn samples from the parameterized gamma distribution.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      scipy.stats.gamma : probability density function, distribution or\n",
      " |          cumulative density function, etc.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The probability density for the Gamma distribution is\n",
      " |      \n",
      " |      .. math:: p(x) = x^{k-1}\\frac{e^{-x/\\theta}}{\\theta^k\\Gamma(k)},\n",
      " |      \n",
      " |      where :math:`k` is the shape and :math:`\\theta` the scale,\n",
      " |      and :math:`\\Gamma` is the Gamma function.\n",
      " |      \n",
      " |      The Gamma distribution is often used to model the times to failure of\n",
      " |      electronic components, and arises naturally in processes for which the\n",
      " |      waiting times between Poisson distributed events are relevant.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] Weisstein, Eric W. \"Gamma Distribution.\" From MathWorld--A\n",
      " |             Wolfram Web Resource.\n",
      " |             http://mathworld.wolfram.com/GammaDistribution.html\n",
      " |      .. [2] Wikipedia, \"Gamma distribution\",\n",
      " |             http://en.wikipedia.org/wiki/Gamma_distribution\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Draw samples from the distribution:\n",
      " |      \n",
      " |      >>> shape, scale = 2., 2. # mean=4, std=2*sqrt(2)\n",
      " |      >>> s = np.random.gamma(shape, scale, 1000)\n",
      " |      \n",
      " |      Display the histogram of the samples, along with\n",
      " |      the probability density function:\n",
      " |      \n",
      " |      >>> import matplotlib.pyplot as plt\n",
      " |      >>> import scipy.special as sps\n",
      " |      >>> count, bins, ignored = plt.hist(s, 50, normed=True)\n",
      " |      >>> y = bins**(shape-1)*(np.exp(-bins/scale) /\n",
      " |      ...                      (sps.gamma(shape)*scale**shape))\n",
      " |      >>> plt.plot(bins, y, linewidth=2, color='r')\n",
      " |      >>> plt.show()\n",
      " |  \n",
      " |  geometric(...)\n",
      " |      geometric(p, size=None)\n",
      " |      \n",
      " |      Draw samples from the geometric distribution.\n",
      " |      \n",
      " |      Bernoulli trials are experiments with one of two outcomes:\n",
      " |      success or failure (an example of such an experiment is flipping\n",
      " |      a coin).  The geometric distribution models the number of trials\n",
      " |      that must be run in order to achieve success.  It is therefore\n",
      " |      supported on the positive integers, ``k = 1, 2, ...``.\n",
      " |      \n",
      " |      The probability mass function of the geometric distribution is\n",
      " |      \n",
      " |      .. math:: f(k) = (1 - p)^{k - 1} p\n",
      " |      \n",
      " |      where `p` is the probability of success of an individual trial.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      p : float or array_like of floats\n",
      " |          The probability of success of an individual trial.\n",
      " |      size : int or tuple of ints, optional\n",
      " |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      " |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      " |          a single value is returned if ``p`` is a scalar.  Otherwise,\n",
      " |          ``np.array(p).size`` samples are drawn.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : ndarray or scalar\n",
      " |          Drawn samples from the parameterized geometric distribution.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Draw ten thousand values from the geometric distribution,\n",
      " |      with the probability of an individual success equal to 0.35:\n",
      " |      \n",
      " |      >>> z = np.random.geometric(p=0.35, size=10000)\n",
      " |      \n",
      " |      How many trials succeeded after a single run?\n",
      " |      \n",
      " |      >>> (z == 1).sum() / 10000.\n",
      " |      0.34889999999999999 #random\n",
      " |  \n",
      " |  get_state(...)\n",
      " |      get_state()\n",
      " |      \n",
      " |      Return a tuple representing the internal state of the generator.\n",
      " |      \n",
      " |      For more details, see `set_state`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : tuple(str, ndarray of 624 uints, int, int, float)\n",
      " |          The returned tuple has the following items:\n",
      " |      \n",
      " |          1. the string 'MT19937'.\n",
      " |          2. a 1-D array of 624 unsigned integer keys.\n",
      " |          3. an integer ``pos``.\n",
      " |          4. an integer ``has_gauss``.\n",
      " |          5. a float ``cached_gaussian``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      set_state\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      `set_state` and `get_state` are not needed to work with any of the\n",
      " |      random distributions in NumPy. If the internal state is manually altered,\n",
      " |      the user should know exactly what he/she is doing.\n",
      " |  \n",
      " |  gumbel(...)\n",
      " |      gumbel(loc=0.0, scale=1.0, size=None)\n",
      " |      \n",
      " |      Draw samples from a Gumbel distribution.\n",
      " |      \n",
      " |      Draw samples from a Gumbel distribution with specified location and\n",
      " |      scale.  For more information on the Gumbel distribution, see\n",
      " |      Notes and References below.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      loc : float or array_like of floats, optional\n",
      " |          The location of the mode of the distribution. Default is 0.\n",
      " |      scale : float or array_like of floats, optional\n",
      " |          The scale parameter of the distribution. Default is 1.\n",
      " |      size : int or tuple of ints, optional\n",
      " |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      " |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      " |          a single value is returned if ``loc`` and ``scale`` are both scalars.\n",
      " |          Otherwise, ``np.broadcast(loc, scale).size`` samples are drawn.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : ndarray or scalar\n",
      " |          Drawn samples from the parameterized Gumbel distribution.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      scipy.stats.gumbel_l\n",
      " |      scipy.stats.gumbel_r\n",
      " |      scipy.stats.genextreme\n",
      " |      weibull\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The Gumbel (or Smallest Extreme Value (SEV) or the Smallest Extreme\n",
      " |      Value Type I) distribution is one of a class of Generalized Extreme\n",
      " |      Value (GEV) distributions used in modeling extreme value problems.\n",
      " |      The Gumbel is a special case of the Extreme Value Type I distribution\n",
      " |      for maximums from distributions with \"exponential-like\" tails.\n",
      " |      \n",
      " |      The probability density for the Gumbel distribution is\n",
      " |      \n",
      " |      .. math:: p(x) = \\frac{e^{-(x - \\mu)/ \\beta}}{\\beta} e^{ -e^{-(x - \\mu)/\n",
      " |                \\beta}},\n",
      " |      \n",
      " |      where :math:`\\mu` is the mode, a location parameter, and\n",
      " |      :math:`\\beta` is the scale parameter.\n",
      " |      \n",
      " |      The Gumbel (named for German mathematician Emil Julius Gumbel) was used\n",
      " |      very early in the hydrology literature, for modeling the occurrence of\n",
      " |      flood events. It is also used for modeling maximum wind speed and\n",
      " |      rainfall rates.  It is a \"fat-tailed\" distribution - the probability of\n",
      " |      an event in the tail of the distribution is larger than if one used a\n",
      " |      Gaussian, hence the surprisingly frequent occurrence of 100-year\n",
      " |      floods. Floods were initially modeled as a Gaussian process, which\n",
      " |      underestimated the frequency of extreme events.\n",
      " |      \n",
      " |      It is one of a class of extreme value distributions, the Generalized\n",
      " |      Extreme Value (GEV) distributions, which also includes the Weibull and\n",
      " |      Frechet.\n",
      " |      \n",
      " |      The function has a mean of :math:`\\mu + 0.57721\\beta` and a variance\n",
      " |      of :math:`\\frac{\\pi^2}{6}\\beta^2`.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] Gumbel, E. J., \"Statistics of Extremes,\"\n",
      " |             New York: Columbia University Press, 1958.\n",
      " |      .. [2] Reiss, R.-D. and Thomas, M., \"Statistical Analysis of Extreme\n",
      " |             Values from Insurance, Finance, Hydrology and Other Fields,\"\n",
      " |             Basel: Birkhauser Verlag, 2001.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Draw samples from the distribution:\n",
      " |      \n",
      " |      >>> mu, beta = 0, 0.1 # location and scale\n",
      " |      >>> s = np.random.gumbel(mu, beta, 1000)\n",
      " |      \n",
      " |      Display the histogram of the samples, along with\n",
      " |      the probability density function:\n",
      " |      \n",
      " |      >>> import matplotlib.pyplot as plt\n",
      " |      >>> count, bins, ignored = plt.hist(s, 30, normed=True)\n",
      " |      >>> plt.plot(bins, (1/beta)*np.exp(-(bins - mu)/beta)\n",
      " |      ...          * np.exp( -np.exp( -(bins - mu) /beta) ),\n",
      " |      ...          linewidth=2, color='r')\n",
      " |      >>> plt.show()\n",
      " |      \n",
      " |      Show how an extreme value distribution can arise from a Gaussian process\n",
      " |      and compare to a Gaussian:\n",
      " |      \n",
      " |      >>> means = []\n",
      " |      >>> maxima = []\n",
      " |      >>> for i in range(0,1000) :\n",
      " |      ...    a = np.random.normal(mu, beta, 1000)\n",
      " |      ...    means.append(a.mean())\n",
      " |      ...    maxima.append(a.max())\n",
      " |      >>> count, bins, ignored = plt.hist(maxima, 30, normed=True)\n",
      " |      >>> beta = np.std(maxima) * np.sqrt(6) / np.pi\n",
      " |      >>> mu = np.mean(maxima) - 0.57721*beta\n",
      " |      >>> plt.plot(bins, (1/beta)*np.exp(-(bins - mu)/beta)\n",
      " |      ...          * np.exp(-np.exp(-(bins - mu)/beta)),\n",
      " |      ...          linewidth=2, color='r')\n",
      " |      >>> plt.plot(bins, 1/(beta * np.sqrt(2 * np.pi))\n",
      " |      ...          * np.exp(-(bins - mu)**2 / (2 * beta**2)),\n",
      " |      ...          linewidth=2, color='g')\n",
      " |      >>> plt.show()\n",
      " |  \n",
      " |  hypergeometric(...)\n",
      " |      hypergeometric(ngood, nbad, nsample, size=None)\n",
      " |      \n",
      " |      Draw samples from a Hypergeometric distribution.\n",
      " |      \n",
      " |      Samples are drawn from a hypergeometric distribution with specified\n",
      " |      parameters, ngood (ways to make a good selection), nbad (ways to make\n",
      " |      a bad selection), and nsample = number of items sampled, which is less\n",
      " |      than or equal to the sum ngood + nbad.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ngood : int or array_like of ints\n",
      " |          Number of ways to make a good selection.  Must be nonnegative.\n",
      " |      nbad : int or array_like of ints\n",
      " |          Number of ways to make a bad selection.  Must be nonnegative.\n",
      " |      nsample : int or array_like of ints\n",
      " |          Number of items sampled.  Must be at least 1 and at most\n",
      " |          ``ngood + nbad``.\n",
      " |      size : int or tuple of ints, optional\n",
      " |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      " |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      " |          a single value is returned if ``ngood``, ``nbad``, and ``nsample``\n",
      " |          are all scalars.  Otherwise, ``np.broadcast(ngood, nbad, nsample).size``\n",
      " |          samples are drawn.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : ndarray or scalar\n",
      " |          Drawn samples from the parameterized hypergeometric distribution.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      scipy.stats.hypergeom : probability density function, distribution or\n",
      " |          cumulative density function, etc.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The probability density for the Hypergeometric distribution is\n",
      " |      \n",
      " |      .. math:: P(x) = \\frac{\\binom{m}{n}\\binom{N-m}{n-x}}{\\binom{N}{n}},\n",
      " |      \n",
      " |      where :math:`0 \\le x \\le m` and :math:`n+m-N \\le x \\le n`\n",
      " |      \n",
      " |      for P(x) the probability of x successes, n = ngood, m = nbad, and\n",
      " |      N = number of samples.\n",
      " |      \n",
      " |      Consider an urn with black and white marbles in it, ngood of them\n",
      " |      black and nbad are white. If you draw nsample balls without\n",
      " |      replacement, then the hypergeometric distribution describes the\n",
      " |      distribution of black balls in the drawn sample.\n",
      " |      \n",
      " |      Note that this distribution is very similar to the binomial\n",
      " |      distribution, except that in this case, samples are drawn without\n",
      " |      replacement, whereas in the Binomial case samples are drawn with\n",
      " |      replacement (or the sample space is infinite). As the sample space\n",
      " |      becomes large, this distribution approaches the binomial.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] Lentner, Marvin, \"Elementary Applied Statistics\", Bogden\n",
      " |             and Quigley, 1972.\n",
      " |      .. [2] Weisstein, Eric W. \"Hypergeometric Distribution.\" From\n",
      " |             MathWorld--A Wolfram Web Resource.\n",
      " |             http://mathworld.wolfram.com/HypergeometricDistribution.html\n",
      " |      .. [3] Wikipedia, \"Hypergeometric distribution\",\n",
      " |             http://en.wikipedia.org/wiki/Hypergeometric_distribution\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Draw samples from the distribution:\n",
      " |      \n",
      " |      >>> ngood, nbad, nsamp = 100, 2, 10\n",
      " |      # number of good, number of bad, and number of samples\n",
      " |      >>> s = np.random.hypergeometric(ngood, nbad, nsamp, 1000)\n",
      " |      >>> hist(s)\n",
      " |      #   note that it is very unlikely to grab both bad items\n",
      " |      \n",
      " |      Suppose you have an urn with 15 white and 15 black marbles.\n",
      " |      If you pull 15 marbles at random, how likely is it that\n",
      " |      12 or more of them are one color?\n",
      " |      \n",
      " |      >>> s = np.random.hypergeometric(15, 15, 15, 100000)\n",
      " |      >>> sum(s>=12)/100000. + sum(s<=3)/100000.\n",
      " |      #   answer = 0.003 ... pretty unlikely!\n",
      " |  \n",
      " |  laplace(...)\n",
      " |      laplace(loc=0.0, scale=1.0, size=None)\n",
      " |      \n",
      " |      Draw samples from the Laplace or double exponential distribution with\n",
      " |      specified location (or mean) and scale (decay).\n",
      " |      \n",
      " |      The Laplace distribution is similar to the Gaussian/normal distribution,\n",
      " |      but is sharper at the peak and has fatter tails. It represents the\n",
      " |      difference between two independent, identically distributed exponential\n",
      " |      random variables.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      loc : float or array_like of floats, optional\n",
      " |          The position, :math:`\\mu`, of the distribution peak. Default is 0.\n",
      " |      scale : float or array_like of floats, optional\n",
      " |          :math:`\\lambda`, the exponential decay. Default is 1.\n",
      " |      size : int or tuple of ints, optional\n",
      " |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      " |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      " |          a single value is returned if ``loc`` and ``scale`` are both scalars.\n",
      " |          Otherwise, ``np.broadcast(loc, scale).size`` samples are drawn.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : ndarray or scalar\n",
      " |          Drawn samples from the parameterized Laplace distribution.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      It has the probability density function\n",
      " |      \n",
      " |      .. math:: f(x; \\mu, \\lambda) = \\frac{1}{2\\lambda}\n",
      " |                                     \\exp\\left(-\\frac{|x - \\mu|}{\\lambda}\\right).\n",
      " |      \n",
      " |      The first law of Laplace, from 1774, states that the frequency\n",
      " |      of an error can be expressed as an exponential function of the\n",
      " |      absolute magnitude of the error, which leads to the Laplace\n",
      " |      distribution. For many problems in economics and health\n",
      " |      sciences, this distribution seems to model the data better\n",
      " |      than the standard Gaussian distribution.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] Abramowitz, M. and Stegun, I. A. (Eds.). \"Handbook of\n",
      " |             Mathematical Functions with Formulas, Graphs, and Mathematical\n",
      " |             Tables, 9th printing,\" New York: Dover, 1972.\n",
      " |      .. [2] Kotz, Samuel, et. al. \"The Laplace Distribution and\n",
      " |             Generalizations, \" Birkhauser, 2001.\n",
      " |      .. [3] Weisstein, Eric W. \"Laplace Distribution.\"\n",
      " |             From MathWorld--A Wolfram Web Resource.\n",
      " |             http://mathworld.wolfram.com/LaplaceDistribution.html\n",
      " |      .. [4] Wikipedia, \"Laplace distribution\",\n",
      " |             http://en.wikipedia.org/wiki/Laplace_distribution\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Draw samples from the distribution\n",
      " |      \n",
      " |      >>> loc, scale = 0., 1.\n",
      " |      >>> s = np.random.laplace(loc, scale, 1000)\n",
      " |      \n",
      " |      Display the histogram of the samples, along with\n",
      " |      the probability density function:\n",
      " |      \n",
      " |      >>> import matplotlib.pyplot as plt\n",
      " |      >>> count, bins, ignored = plt.hist(s, 30, normed=True)\n",
      " |      >>> x = np.arange(-8., 8., .01)\n",
      " |      >>> pdf = np.exp(-abs(x-loc)/scale)/(2.*scale)\n",
      " |      >>> plt.plot(x, pdf)\n",
      " |      \n",
      " |      Plot Gaussian for comparison:\n",
      " |      \n",
      " |      >>> g = (1/(scale * np.sqrt(2 * np.pi)) *\n",
      " |      ...      np.exp(-(x - loc)**2 / (2 * scale**2)))\n",
      " |      >>> plt.plot(x,g)\n",
      " |  \n",
      " |  logistic(...)\n",
      " |      logistic(loc=0.0, scale=1.0, size=None)\n",
      " |      \n",
      " |      Draw samples from a logistic distribution.\n",
      " |      \n",
      " |      Samples are drawn from a logistic distribution with specified\n",
      " |      parameters, loc (location or mean, also median), and scale (>0).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      loc : float or array_like of floats, optional\n",
      " |          Parameter of the distribution. Default is 0.\n",
      " |      scale : float or array_like of floats, optional\n",
      " |          Parameter of the distribution. Should be greater than zero.\n",
      " |          Default is 1.\n",
      " |      size : int or tuple of ints, optional\n",
      " |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      " |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      " |          a single value is returned if ``loc`` and ``scale`` are both scalars.\n",
      " |          Otherwise, ``np.broadcast(loc, scale).size`` samples are drawn.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : ndarray or scalar\n",
      " |          Drawn samples from the parameterized logistic distribution.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      scipy.stats.logistic : probability density function, distribution or\n",
      " |          cumulative density function, etc.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The probability density for the Logistic distribution is\n",
      " |      \n",
      " |      .. math:: P(x) = P(x) = \\frac{e^{-(x-\\mu)/s}}{s(1+e^{-(x-\\mu)/s})^2},\n",
      " |      \n",
      " |      where :math:`\\mu` = location and :math:`s` = scale.\n",
      " |      \n",
      " |      The Logistic distribution is used in Extreme Value problems where it\n",
      " |      can act as a mixture of Gumbel distributions, in Epidemiology, and by\n",
      " |      the World Chess Federation (FIDE) where it is used in the Elo ranking\n",
      " |      system, assuming the performance of each player is a logistically\n",
      " |      distributed random variable.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] Reiss, R.-D. and Thomas M. (2001), \"Statistical Analysis of\n",
      " |             Extreme Values, from Insurance, Finance, Hydrology and Other\n",
      " |             Fields,\" Birkhauser Verlag, Basel, pp 132-133.\n",
      " |      .. [2] Weisstein, Eric W. \"Logistic Distribution.\" From\n",
      " |             MathWorld--A Wolfram Web Resource.\n",
      " |             http://mathworld.wolfram.com/LogisticDistribution.html\n",
      " |      .. [3] Wikipedia, \"Logistic-distribution\",\n",
      " |             http://en.wikipedia.org/wiki/Logistic_distribution\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Draw samples from the distribution:\n",
      " |      \n",
      " |      >>> loc, scale = 10, 1\n",
      " |      >>> s = np.random.logistic(loc, scale, 10000)\n",
      " |      >>> count, bins, ignored = plt.hist(s, bins=50)\n",
      " |      \n",
      " |      #   plot against distribution\n",
      " |      \n",
      " |      >>> def logist(x, loc, scale):\n",
      " |      ...     return exp((loc-x)/scale)/(scale*(1+exp((loc-x)/scale))**2)\n",
      " |      >>> plt.plot(bins, logist(bins, loc, scale)*count.max()/\\\n",
      " |      ... logist(bins, loc, scale).max())\n",
      " |      >>> plt.show()\n",
      " |  \n",
      " |  lognormal(...)\n",
      " |      lognormal(mean=0.0, sigma=1.0, size=None)\n",
      " |      \n",
      " |      Draw samples from a log-normal distribution.\n",
      " |      \n",
      " |      Draw samples from a log-normal distribution with specified mean,\n",
      " |      standard deviation, and array shape.  Note that the mean and standard\n",
      " |      deviation are not the values for the distribution itself, but of the\n",
      " |      underlying normal distribution it is derived from.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      mean : float or array_like of floats, optional\n",
      " |          Mean value of the underlying normal distribution. Default is 0.\n",
      " |      sigma : float or array_like of floats, optional\n",
      " |          Standard deviation of the underlying normal distribution. Should\n",
      " |          be greater than zero. Default is 1.\n",
      " |      size : int or tuple of ints, optional\n",
      " |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      " |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      " |          a single value is returned if ``mean`` and ``sigma`` are both scalars.\n",
      " |          Otherwise, ``np.broadcast(mean, sigma).size`` samples are drawn.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : ndarray or scalar\n",
      " |          Drawn samples from the parameterized log-normal distribution.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      scipy.stats.lognorm : probability density function, distribution,\n",
      " |          cumulative density function, etc.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      A variable `x` has a log-normal distribution if `log(x)` is normally\n",
      " |      distributed.  The probability density function for the log-normal\n",
      " |      distribution is:\n",
      " |      \n",
      " |      .. math:: p(x) = \\frac{1}{\\sigma x \\sqrt{2\\pi}}\n",
      " |                       e^{(-\\frac{(ln(x)-\\mu)^2}{2\\sigma^2})}\n",
      " |      \n",
      " |      where :math:`\\mu` is the mean and :math:`\\sigma` is the standard\n",
      " |      deviation of the normally distributed logarithm of the variable.\n",
      " |      A log-normal distribution results if a random variable is the *product*\n",
      " |      of a large number of independent, identically-distributed variables in\n",
      " |      the same way that a normal distribution results if the variable is the\n",
      " |      *sum* of a large number of independent, identically-distributed\n",
      " |      variables.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] Limpert, E., Stahel, W. A., and Abbt, M., \"Log-normal\n",
      " |             Distributions across the Sciences: Keys and Clues,\"\n",
      " |             BioScience, Vol. 51, No. 5, May, 2001.\n",
      " |             http://stat.ethz.ch/~stahel/lognormal/bioscience.pdf\n",
      " |      .. [2] Reiss, R.D. and Thomas, M., \"Statistical Analysis of Extreme\n",
      " |             Values,\" Basel: Birkhauser Verlag, 2001, pp. 31-32.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Draw samples from the distribution:\n",
      " |      \n",
      " |      >>> mu, sigma = 3., 1. # mean and standard deviation\n",
      " |      >>> s = np.random.lognormal(mu, sigma, 1000)\n",
      " |      \n",
      " |      Display the histogram of the samples, along with\n",
      " |      the probability density function:\n",
      " |      \n",
      " |      >>> import matplotlib.pyplot as plt\n",
      " |      >>> count, bins, ignored = plt.hist(s, 100, normed=True, align='mid')\n",
      " |      \n",
      " |      >>> x = np.linspace(min(bins), max(bins), 10000)\n",
      " |      >>> pdf = (np.exp(-(np.log(x) - mu)**2 / (2 * sigma**2))\n",
      " |      ...        / (x * sigma * np.sqrt(2 * np.pi)))\n",
      " |      \n",
      " |      >>> plt.plot(x, pdf, linewidth=2, color='r')\n",
      " |      >>> plt.axis('tight')\n",
      " |      >>> plt.show()\n",
      " |      \n",
      " |      Demonstrate that taking the products of random samples from a uniform\n",
      " |      distribution can be fit well by a log-normal probability density\n",
      " |      function.\n",
      " |      \n",
      " |      >>> # Generate a thousand samples: each is the product of 100 random\n",
      " |      >>> # values, drawn from a normal distribution.\n",
      " |      >>> b = []\n",
      " |      >>> for i in range(1000):\n",
      " |      ...    a = 10. + np.random.random(100)\n",
      " |      ...    b.append(np.product(a))\n",
      " |      \n",
      " |      >>> b = np.array(b) / np.min(b) # scale values to be positive\n",
      " |      >>> count, bins, ignored = plt.hist(b, 100, normed=True, align='mid')\n",
      " |      >>> sigma = np.std(np.log(b))\n",
      " |      >>> mu = np.mean(np.log(b))\n",
      " |      \n",
      " |      >>> x = np.linspace(min(bins), max(bins), 10000)\n",
      " |      >>> pdf = (np.exp(-(np.log(x) - mu)**2 / (2 * sigma**2))\n",
      " |      ...        / (x * sigma * np.sqrt(2 * np.pi)))\n",
      " |      \n",
      " |      >>> plt.plot(x, pdf, color='r', linewidth=2)\n",
      " |      >>> plt.show()\n",
      " |  \n",
      " |  logseries(...)\n",
      " |      logseries(p, size=None)\n",
      " |      \n",
      " |      Draw samples from a logarithmic series distribution.\n",
      " |      \n",
      " |      Samples are drawn from a log series distribution with specified\n",
      " |      shape parameter, 0 < ``p`` < 1.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      p : float or array_like of floats\n",
      " |          Shape parameter for the distribution.  Must be in the range (0, 1).\n",
      " |      size : int or tuple of ints, optional\n",
      " |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      " |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      " |          a single value is returned if ``p`` is a scalar.  Otherwise,\n",
      " |          ``np.array(p).size`` samples are drawn.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : ndarray or scalar\n",
      " |          Drawn samples from the parameterized logarithmic series distribution.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      scipy.stats.logser : probability density function, distribution or\n",
      " |          cumulative density function, etc.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The probability density for the Log Series distribution is\n",
      " |      \n",
      " |      .. math:: P(k) = \\frac{-p^k}{k \\ln(1-p)},\n",
      " |      \n",
      " |      where p = probability.\n",
      " |      \n",
      " |      The log series distribution is frequently used to represent species\n",
      " |      richness and occurrence, first proposed by Fisher, Corbet, and\n",
      " |      Williams in 1943 [2].  It may also be used to model the numbers of\n",
      " |      occupants seen in cars [3].\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] Buzas, Martin A.; Culver, Stephen J.,  Understanding regional\n",
      " |             species diversity through the log series distribution of\n",
      " |             occurrences: BIODIVERSITY RESEARCH Diversity & Distributions,\n",
      " |             Volume 5, Number 5, September 1999 , pp. 187-195(9).\n",
      " |      .. [2] Fisher, R.A,, A.S. Corbet, and C.B. Williams. 1943. The\n",
      " |             relation between the number of species and the number of\n",
      " |             individuals in a random sample of an animal population.\n",
      " |             Journal of Animal Ecology, 12:42-58.\n",
      " |      .. [3] D. J. Hand, F. Daly, D. Lunn, E. Ostrowski, A Handbook of Small\n",
      " |             Data Sets, CRC Press, 1994.\n",
      " |      .. [4] Wikipedia, \"Logarithmic distribution\",\n",
      " |             http://en.wikipedia.org/wiki/Logarithmic_distribution\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Draw samples from the distribution:\n",
      " |      \n",
      " |      >>> a = .6\n",
      " |      >>> s = np.random.logseries(a, 10000)\n",
      " |      >>> count, bins, ignored = plt.hist(s)\n",
      " |      \n",
      " |      #   plot against distribution\n",
      " |      \n",
      " |      >>> def logseries(k, p):\n",
      " |      ...     return -p**k/(k*log(1-p))\n",
      " |      >>> plt.plot(bins, logseries(bins, a)*count.max()/\n",
      " |                   logseries(bins, a).max(), 'r')\n",
      " |      >>> plt.show()\n",
      " |  \n",
      " |  multinomial(...)\n",
      " |      multinomial(n, pvals, size=None)\n",
      " |      \n",
      " |      Draw samples from a multinomial distribution.\n",
      " |      \n",
      " |      The multinomial distribution is a multivariate generalisation of the\n",
      " |      binomial distribution.  Take an experiment with one of ``p``\n",
      " |      possible outcomes.  An example of such an experiment is throwing a dice,\n",
      " |      where the outcome can be 1 through 6.  Each sample drawn from the\n",
      " |      distribution represents `n` such experiments.  Its values,\n",
      " |      ``X_i = [X_0, X_1, ..., X_p]``, represent the number of times the\n",
      " |      outcome was ``i``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int\n",
      " |          Number of experiments.\n",
      " |      pvals : sequence of floats, length p\n",
      " |          Probabilities of each of the ``p`` different outcomes.  These\n",
      " |          should sum to 1 (however, the last element is always assumed to\n",
      " |          account for the remaining probability, as long as\n",
      " |          ``sum(pvals[:-1]) <= 1)``.\n",
      " |      size : int or tuple of ints, optional\n",
      " |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      " |          ``m * n * k`` samples are drawn.  Default is None, in which case a\n",
      " |          single value is returned.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : ndarray\n",
      " |          The drawn samples, of shape *size*, if that was provided.  If not,\n",
      " |          the shape is ``(N,)``.\n",
      " |      \n",
      " |          In other words, each entry ``out[i,j,...,:]`` is an N-dimensional\n",
      " |          value drawn from the distribution.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Throw a dice 20 times:\n",
      " |      \n",
      " |      >>> np.random.multinomial(20, [1/6.]*6, size=1)\n",
      " |      array([[4, 1, 7, 5, 2, 1]])\n",
      " |      \n",
      " |      It landed 4 times on 1, once on 2, etc.\n",
      " |      \n",
      " |      Now, throw the dice 20 times, and 20 times again:\n",
      " |      \n",
      " |      >>> np.random.multinomial(20, [1/6.]*6, size=2)\n",
      " |      array([[3, 4, 3, 3, 4, 3],\n",
      " |             [2, 4, 3, 4, 0, 7]])\n",
      " |      \n",
      " |      For the first run, we threw 3 times 1, 4 times 2, etc.  For the second,\n",
      " |      we threw 2 times 1, 4 times 2, etc.\n",
      " |      \n",
      " |      A loaded die is more likely to land on number 6:\n",
      " |      \n",
      " |      >>> np.random.multinomial(100, [1/7.]*5 + [2/7.])\n",
      " |      array([11, 16, 14, 17, 16, 26])\n",
      " |      \n",
      " |      The probability inputs should be normalized. As an implementation\n",
      " |      detail, the value of the last entry is ignored and assumed to take\n",
      " |      up any leftover probability mass, but this should not be relied on.\n",
      " |      A biased coin which has twice as much weight on one side as on the\n",
      " |      other should be sampled like so:\n",
      " |      \n",
      " |      >>> np.random.multinomial(100, [1.0 / 3, 2.0 / 3])  # RIGHT\n",
      " |      array([38, 62])\n",
      " |      \n",
      " |      not like:\n",
      " |      \n",
      " |      >>> np.random.multinomial(100, [1.0, 2.0])  # WRONG\n",
      " |      array([100,   0])\n",
      " |  \n",
      " |  multivariate_normal(...)\n",
      " |      multivariate_normal(mean, cov[, size])\n",
      " |      \n",
      " |      Draw random samples from a multivariate normal distribution.\n",
      " |      \n",
      " |      The multivariate normal, multinormal or Gaussian distribution is a\n",
      " |      generalization of the one-dimensional normal distribution to higher\n",
      " |      dimensions.  Such a distribution is specified by its mean and\n",
      " |      covariance matrix.  These parameters are analogous to the mean\n",
      " |      (average or \"center\") and variance (standard deviation, or \"width,\"\n",
      " |      squared) of the one-dimensional normal distribution.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      mean : 1-D array_like, of length N\n",
      " |          Mean of the N-dimensional distribution.\n",
      " |      cov : 2-D array_like, of shape (N, N)\n",
      " |          Covariance matrix of the distribution. It must be symmetric and\n",
      " |          positive-semidefinite for proper sampling.\n",
      " |      size : int or tuple of ints, optional\n",
      " |          Given a shape of, for example, ``(m,n,k)``, ``m*n*k`` samples are\n",
      " |          generated, and packed in an `m`-by-`n`-by-`k` arrangement.  Because\n",
      " |          each sample is `N`-dimensional, the output shape is ``(m,n,k,N)``.\n",
      " |          If no shape is specified, a single (`N`-D) sample is returned.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : ndarray\n",
      " |          The drawn samples, of shape *size*, if that was provided.  If not,\n",
      " |          the shape is ``(N,)``.\n",
      " |      \n",
      " |          In other words, each entry ``out[i,j,...,:]`` is an N-dimensional\n",
      " |          value drawn from the distribution.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The mean is a coordinate in N-dimensional space, which represents the\n",
      " |      location where samples are most likely to be generated.  This is\n",
      " |      analogous to the peak of the bell curve for the one-dimensional or\n",
      " |      univariate normal distribution.\n",
      " |      \n",
      " |      Covariance indicates the level to which two variables vary together.\n",
      " |      From the multivariate normal distribution, we draw N-dimensional\n",
      " |      samples, :math:`X = [x_1, x_2, ... x_N]`.  The covariance matrix\n",
      " |      element :math:`C_{ij}` is the covariance of :math:`x_i` and :math:`x_j`.\n",
      " |      The element :math:`C_{ii}` is the variance of :math:`x_i` (i.e. its\n",
      " |      \"spread\").\n",
      " |      \n",
      " |      Instead of specifying the full covariance matrix, popular\n",
      " |      approximations include:\n",
      " |      \n",
      " |        - Spherical covariance (*cov* is a multiple of the identity matrix)\n",
      " |        - Diagonal covariance (*cov* has non-negative elements, and only on\n",
      " |          the diagonal)\n",
      " |      \n",
      " |      This geometrical property can be seen in two dimensions by plotting\n",
      " |      generated data-points:\n",
      " |      \n",
      " |      >>> mean = [0, 0]\n",
      " |      >>> cov = [[1, 0], [0, 100]]  # diagonal covariance\n",
      " |      \n",
      " |      Diagonal covariance means that points are oriented along x or y-axis:\n",
      " |      \n",
      " |      >>> import matplotlib.pyplot as plt\n",
      " |      >>> x, y = np.random.multivariate_normal(mean, cov, 5000).T\n",
      " |      >>> plt.plot(x, y, 'x')\n",
      " |      >>> plt.axis('equal')\n",
      " |      >>> plt.show()\n",
      " |      \n",
      " |      Note that the covariance matrix must be positive semidefinite (a.k.a.\n",
      " |      nonnegative-definite). Otherwise, the behavior of this method is\n",
      " |      undefined and backwards compatibility is not guaranteed.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] Papoulis, A., \"Probability, Random Variables, and Stochastic\n",
      " |             Processes,\" 3rd ed., New York: McGraw-Hill, 1991.\n",
      " |      .. [2] Duda, R. O., Hart, P. E., and Stork, D. G., \"Pattern\n",
      " |             Classification,\" 2nd ed., New York: Wiley, 2001.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> mean = (1, 2)\n",
      " |      >>> cov = [[1, 0], [0, 1]]\n",
      " |      >>> x = np.random.multivariate_normal(mean, cov, (3, 3))\n",
      " |      >>> x.shape\n",
      " |      (3, 3, 2)\n",
      " |      \n",
      " |      The following is probably true, given that 0.6 is roughly twice the\n",
      " |      standard deviation:\n",
      " |      \n",
      " |      >>> list((x[0,0,:] - mean) < 0.6)\n",
      " |      [True, True]\n",
      " |  \n",
      " |  negative_binomial(...)\n",
      " |      negative_binomial(n, p, size=None)\n",
      " |      \n",
      " |      Draw samples from a negative binomial distribution.\n",
      " |      \n",
      " |      Samples are drawn from a negative binomial distribution with specified\n",
      " |      parameters, `n` trials and `p` probability of success where `n` is an\n",
      " |      integer > 0 and `p` is in the interval [0, 1].\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : int or array_like of ints\n",
      " |          Parameter of the distribution, > 0. Floats are also accepted,\n",
      " |          but they will be truncated to integers.\n",
      " |      p : float or array_like of floats\n",
      " |          Parameter of the distribution, >= 0 and <=1.\n",
      " |      size : int or tuple of ints, optional\n",
      " |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      " |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      " |          a single value is returned if ``n`` and ``p`` are both scalars.\n",
      " |          Otherwise, ``np.broadcast(n, p).size`` samples are drawn.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : ndarray or scalar\n",
      " |          Drawn samples from the parameterized negative binomial distribution,\n",
      " |          where each sample is equal to N, the number of trials it took to\n",
      " |          achieve n - 1 successes, N - (n - 1) failures, and a success on the,\n",
      " |          (N + n)th trial.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The probability density for the negative binomial distribution is\n",
      " |      \n",
      " |      .. math:: P(N;n,p) = \\binom{N+n-1}{n-1}p^{n}(1-p)^{N},\n",
      " |      \n",
      " |      where :math:`n-1` is the number of successes, :math:`p` is the\n",
      " |      probability of success, and :math:`N+n-1` is the number of trials.\n",
      " |      The negative binomial distribution gives the probability of n-1\n",
      " |      successes and N failures in N+n-1 trials, and success on the (N+n)th\n",
      " |      trial.\n",
      " |      \n",
      " |      If one throws a die repeatedly until the third time a \"1\" appears,\n",
      " |      then the probability distribution of the number of non-\"1\"s that\n",
      " |      appear before the third \"1\" is a negative binomial distribution.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] Weisstein, Eric W. \"Negative Binomial Distribution.\" From\n",
      " |             MathWorld--A Wolfram Web Resource.\n",
      " |             http://mathworld.wolfram.com/NegativeBinomialDistribution.html\n",
      " |      .. [2] Wikipedia, \"Negative binomial distribution\",\n",
      " |             http://en.wikipedia.org/wiki/Negative_binomial_distribution\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Draw samples from the distribution:\n",
      " |      \n",
      " |      A real world example. A company drills wild-cat oil\n",
      " |      exploration wells, each with an estimated probability of\n",
      " |      success of 0.1.  What is the probability of having one success\n",
      " |      for each successive well, that is what is the probability of a\n",
      " |      single success after drilling 5 wells, after 6 wells, etc.?\n",
      " |      \n",
      " |      >>> s = np.random.negative_binomial(1, 0.1, 100000)\n",
      " |      >>> for i in range(1, 11):\n",
      " |      ...    probability = sum(s<i) / 100000.\n",
      " |      ...    print i, \"wells drilled, probability of one success =\", probability\n",
      " |  \n",
      " |  noncentral_chisquare(...)\n",
      " |      noncentral_chisquare(df, nonc, size=None)\n",
      " |      \n",
      " |      Draw samples from a noncentral chi-square distribution.\n",
      " |      \n",
      " |      The noncentral :math:`\\chi^2` distribution is a generalisation of\n",
      " |      the :math:`\\chi^2` distribution.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      df : int or array_like of ints\n",
      " |          Degrees of freedom, should be > 0 as of NumPy 1.10.0,\n",
      " |          should be > 1 for earlier versions.\n",
      " |      nonc : float or array_like of floats\n",
      " |          Non-centrality, should be non-negative.\n",
      " |      size : int or tuple of ints, optional\n",
      " |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      " |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      " |          a single value is returned if ``df`` and ``nonc`` are both scalars.\n",
      " |          Otherwise, ``np.broadcast(df, nonc).size`` samples are drawn.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : ndarray or scalar\n",
      " |          Drawn samples from the parameterized noncentral chi-square distribution.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The probability density function for the noncentral Chi-square\n",
      " |      distribution is\n",
      " |      \n",
      " |      .. math:: P(x;df,nonc) = \\sum^{\\infty}_{i=0}\n",
      " |                             \\frac{e^{-nonc/2}(nonc/2)^{i}}{i!}\n",
      " |                             \\P_{Y_{df+2i}}(x),\n",
      " |      \n",
      " |      where :math:`Y_{q}` is the Chi-square with q degrees of freedom.\n",
      " |      \n",
      " |      In Delhi (2007), it is noted that the noncentral chi-square is\n",
      " |      useful in bombing and coverage problems, the probability of\n",
      " |      killing the point target given by the noncentral chi-squared\n",
      " |      distribution.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] Delhi, M.S. Holla, \"On a noncentral chi-square distribution in\n",
      " |             the analysis of weapon systems effectiveness\", Metrika,\n",
      " |             Volume 15, Number 1 / December, 1970.\n",
      " |      .. [2] Wikipedia, \"Noncentral chi-square distribution\"\n",
      " |             http://en.wikipedia.org/wiki/Noncentral_chi-square_distribution\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Draw values from the distribution and plot the histogram\n",
      " |      \n",
      " |      >>> import matplotlib.pyplot as plt\n",
      " |      >>> values = plt.hist(np.random.noncentral_chisquare(3, 20, 100000),\n",
      " |      ...                   bins=200, normed=True)\n",
      " |      >>> plt.show()\n",
      " |      \n",
      " |      Draw values from a noncentral chisquare with very small noncentrality,\n",
      " |      and compare to a chisquare.\n",
      " |      \n",
      " |      >>> plt.figure()\n",
      " |      >>> values = plt.hist(np.random.noncentral_chisquare(3, .0000001, 100000),\n",
      " |      ...                   bins=np.arange(0., 25, .1), normed=True)\n",
      " |      >>> values2 = plt.hist(np.random.chisquare(3, 100000),\n",
      " |      ...                    bins=np.arange(0., 25, .1), normed=True)\n",
      " |      >>> plt.plot(values[1][0:-1], values[0]-values2[0], 'ob')\n",
      " |      >>> plt.show()\n",
      " |      \n",
      " |      Demonstrate how large values of non-centrality lead to a more symmetric\n",
      " |      distribution.\n",
      " |      \n",
      " |      >>> plt.figure()\n",
      " |      >>> values = plt.hist(np.random.noncentral_chisquare(3, 20, 100000),\n",
      " |      ...                   bins=200, normed=True)\n",
      " |      >>> plt.show()\n",
      " |  \n",
      " |  noncentral_f(...)\n",
      " |      noncentral_f(dfnum, dfden, nonc, size=None)\n",
      " |      \n",
      " |      Draw samples from the noncentral F distribution.\n",
      " |      \n",
      " |      Samples are drawn from an F distribution with specified parameters,\n",
      " |      `dfnum` (degrees of freedom in numerator) and `dfden` (degrees of\n",
      " |      freedom in denominator), where both parameters > 1.\n",
      " |      `nonc` is the non-centrality parameter.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dfnum : int or array_like of ints\n",
      " |          Parameter, should be > 1.\n",
      " |      dfden : int or array_like of ints\n",
      " |          Parameter, should be > 1.\n",
      " |      nonc : float or array_like of floats\n",
      " |          Parameter, should be >= 0.\n",
      " |      size : int or tuple of ints, optional\n",
      " |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      " |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      " |          a single value is returned if ``dfnum``, ``dfden``, and ``nonc``\n",
      " |          are all scalars.  Otherwise, ``np.broadcast(dfnum, dfden, nonc).size``\n",
      " |          samples are drawn.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : ndarray or scalar\n",
      " |          Drawn samples from the parameterized noncentral Fisher distribution.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      When calculating the power of an experiment (power = probability of\n",
      " |      rejecting the null hypothesis when a specific alternative is true) the\n",
      " |      non-central F statistic becomes important.  When the null hypothesis is\n",
      " |      true, the F statistic follows a central F distribution. When the null\n",
      " |      hypothesis is not true, then it follows a non-central F statistic.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] Weisstein, Eric W. \"Noncentral F-Distribution.\"\n",
      " |             From MathWorld--A Wolfram Web Resource.\n",
      " |             http://mathworld.wolfram.com/NoncentralF-Distribution.html\n",
      " |      .. [2] Wikipedia, \"Noncentral F-distribution\",\n",
      " |             http://en.wikipedia.org/wiki/Noncentral_F-distribution\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      In a study, testing for a specific alternative to the null hypothesis\n",
      " |      requires use of the Noncentral F distribution. We need to calculate the\n",
      " |      area in the tail of the distribution that exceeds the value of the F\n",
      " |      distribution for the null hypothesis.  We'll plot the two probability\n",
      " |      distributions for comparison.\n",
      " |      \n",
      " |      >>> dfnum = 3 # between group deg of freedom\n",
      " |      >>> dfden = 20 # within groups degrees of freedom\n",
      " |      >>> nonc = 3.0\n",
      " |      >>> nc_vals = np.random.noncentral_f(dfnum, dfden, nonc, 1000000)\n",
      " |      >>> NF = np.histogram(nc_vals, bins=50, normed=True)\n",
      " |      >>> c_vals = np.random.f(dfnum, dfden, 1000000)\n",
      " |      >>> F = np.histogram(c_vals, bins=50, normed=True)\n",
      " |      >>> plt.plot(F[1][1:], F[0])\n",
      " |      >>> plt.plot(NF[1][1:], NF[0])\n",
      " |      >>> plt.show()\n",
      " |  \n",
      " |  normal(...)\n",
      " |      normal(loc=0.0, scale=1.0, size=None)\n",
      " |      \n",
      " |      Draw random samples from a normal (Gaussian) distribution.\n",
      " |      \n",
      " |      The probability density function of the normal distribution, first\n",
      " |      derived by De Moivre and 200 years later by both Gauss and Laplace\n",
      " |      independently [2]_, is often called the bell curve because of\n",
      " |      its characteristic shape (see the example below).\n",
      " |      \n",
      " |      The normal distributions occurs often in nature.  For example, it\n",
      " |      describes the commonly occurring distribution of samples influenced\n",
      " |      by a large number of tiny, random disturbances, each with its own\n",
      " |      unique distribution [2]_.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      loc : float or array_like of floats\n",
      " |          Mean (\"centre\") of the distribution.\n",
      " |      scale : float or array_like of floats\n",
      " |          Standard deviation (spread or \"width\") of the distribution.\n",
      " |      size : int or tuple of ints, optional\n",
      " |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      " |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      " |          a single value is returned if ``loc`` and ``scale`` are both scalars.\n",
      " |          Otherwise, ``np.broadcast(loc, scale).size`` samples are drawn.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : ndarray or scalar\n",
      " |          Drawn samples from the parameterized normal distribution.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      scipy.stats.norm : probability density function, distribution or\n",
      " |          cumulative density function, etc.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The probability density for the Gaussian distribution is\n",
      " |      \n",
      " |      .. math:: p(x) = \\frac{1}{\\sqrt{ 2 \\pi \\sigma^2 }}\n",
      " |                       e^{ - \\frac{ (x - \\mu)^2 } {2 \\sigma^2} },\n",
      " |      \n",
      " |      where :math:`\\mu` is the mean and :math:`\\sigma` the standard\n",
      " |      deviation. The square of the standard deviation, :math:`\\sigma^2`,\n",
      " |      is called the variance.\n",
      " |      \n",
      " |      The function has its peak at the mean, and its \"spread\" increases with\n",
      " |      the standard deviation (the function reaches 0.607 times its maximum at\n",
      " |      :math:`x + \\sigma` and :math:`x - \\sigma` [2]_).  This implies that\n",
      " |      `numpy.random.normal` is more likely to return samples lying close to\n",
      " |      the mean, rather than those far away.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] Wikipedia, \"Normal distribution\",\n",
      " |             http://en.wikipedia.org/wiki/Normal_distribution\n",
      " |      .. [2] P. R. Peebles Jr., \"Central Limit Theorem\" in \"Probability,\n",
      " |             Random Variables and Random Signal Principles\", 4th ed., 2001,\n",
      " |             pp. 51, 51, 125.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Draw samples from the distribution:\n",
      " |      \n",
      " |      >>> mu, sigma = 0, 0.1 # mean and standard deviation\n",
      " |      >>> s = np.random.normal(mu, sigma, 1000)\n",
      " |      \n",
      " |      Verify the mean and the variance:\n",
      " |      \n",
      " |      >>> abs(mu - np.mean(s)) < 0.01\n",
      " |      True\n",
      " |      \n",
      " |      >>> abs(sigma - np.std(s, ddof=1)) < 0.01\n",
      " |      True\n",
      " |      \n",
      " |      Display the histogram of the samples, along with\n",
      " |      the probability density function:\n",
      " |      \n",
      " |      >>> import matplotlib.pyplot as plt\n",
      " |      >>> count, bins, ignored = plt.hist(s, 30, normed=True)\n",
      " |      >>> plt.plot(bins, 1/(sigma * np.sqrt(2 * np.pi)) *\n",
      " |      ...                np.exp( - (bins - mu)**2 / (2 * sigma**2) ),\n",
      " |      ...          linewidth=2, color='r')\n",
      " |      >>> plt.show()\n",
      " |  \n",
      " |  pareto(...)\n",
      " |      pareto(a, size=None)\n",
      " |      \n",
      " |      Draw samples from a Pareto II or Lomax distribution with\n",
      " |      specified shape.\n",
      " |      \n",
      " |      The Lomax or Pareto II distribution is a shifted Pareto\n",
      " |      distribution. The classical Pareto distribution can be\n",
      " |      obtained from the Lomax distribution by adding 1 and\n",
      " |      multiplying by the scale parameter ``m`` (see Notes).  The\n",
      " |      smallest value of the Lomax distribution is zero while for the\n",
      " |      classical Pareto distribution it is ``mu``, where the standard\n",
      " |      Pareto distribution has location ``mu = 1``.  Lomax can also\n",
      " |      be considered as a simplified version of the Generalized\n",
      " |      Pareto distribution (available in SciPy), with the scale set\n",
      " |      to one and the location set to zero.\n",
      " |      \n",
      " |      The Pareto distribution must be greater than zero, and is\n",
      " |      unbounded above.  It is also known as the \"80-20 rule\".  In\n",
      " |      this distribution, 80 percent of the weights are in the lowest\n",
      " |      20 percent of the range, while the other 20 percent fill the\n",
      " |      remaining 80 percent of the range.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      a : float or array_like of floats\n",
      " |          Shape of the distribution. Should be greater than zero.\n",
      " |      size : int or tuple of ints, optional\n",
      " |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      " |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      " |          a single value is returned if ``a`` is a scalar.  Otherwise,\n",
      " |          ``np.array(a).size`` samples are drawn.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : ndarray or scalar\n",
      " |          Drawn samples from the parameterized Pareto distribution.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      scipy.stats.lomax : probability density function, distribution or\n",
      " |          cumulative density function, etc.\n",
      " |      scipy.stats.genpareto : probability density function, distribution or\n",
      " |          cumulative density function, etc.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The probability density for the Pareto distribution is\n",
      " |      \n",
      " |      .. math:: p(x) = \\frac{am^a}{x^{a+1}}\n",
      " |      \n",
      " |      where :math:`a` is the shape and :math:`m` the scale.\n",
      " |      \n",
      " |      The Pareto distribution, named after the Italian economist\n",
      " |      Vilfredo Pareto, is a power law probability distribution\n",
      " |      useful in many real world problems.  Outside the field of\n",
      " |      economics it is generally referred to as the Bradford\n",
      " |      distribution. Pareto developed the distribution to describe\n",
      " |      the distribution of wealth in an economy.  It has also found\n",
      " |      use in insurance, web page access statistics, oil field sizes,\n",
      " |      and many other problems, including the download frequency for\n",
      " |      projects in Sourceforge [1]_.  It is one of the so-called\n",
      " |      \"fat-tailed\" distributions.\n",
      " |      \n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] Francis Hunt and Paul Johnson, On the Pareto Distribution of\n",
      " |             Sourceforge projects.\n",
      " |      .. [2] Pareto, V. (1896). Course of Political Economy. Lausanne.\n",
      " |      .. [3] Reiss, R.D., Thomas, M.(2001), Statistical Analysis of Extreme\n",
      " |             Values, Birkhauser Verlag, Basel, pp 23-30.\n",
      " |      .. [4] Wikipedia, \"Pareto distribution\",\n",
      " |             http://en.wikipedia.org/wiki/Pareto_distribution\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Draw samples from the distribution:\n",
      " |      \n",
      " |      >>> a, m = 3., 2.  # shape and mode\n",
      " |      >>> s = (np.random.pareto(a, 1000) + 1) * m\n",
      " |      \n",
      " |      Display the histogram of the samples, along with the probability\n",
      " |      density function:\n",
      " |      \n",
      " |      >>> import matplotlib.pyplot as plt\n",
      " |      >>> count, bins, _ = plt.hist(s, 100, normed=True)\n",
      " |      >>> fit = a*m**a / bins**(a+1)\n",
      " |      >>> plt.plot(bins, max(count)*fit/max(fit), linewidth=2, color='r')\n",
      " |      >>> plt.show()\n",
      " |  \n",
      " |  permutation(...)\n",
      " |      permutation(x)\n",
      " |      \n",
      " |      Randomly permute a sequence, or return a permuted range.\n",
      " |      \n",
      " |      If `x` is a multi-dimensional array, it is only shuffled along its\n",
      " |      first index.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      x : int or array_like\n",
      " |          If `x` is an integer, randomly permute ``np.arange(x)``.\n",
      " |          If `x` is an array, make a copy and shuffle the elements\n",
      " |          randomly.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : ndarray\n",
      " |          Permuted sequence or array range.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> np.random.permutation(10)\n",
      " |      array([1, 7, 4, 3, 0, 9, 2, 5, 8, 6])\n",
      " |      \n",
      " |      >>> np.random.permutation([1, 4, 9, 12, 15])\n",
      " |      array([15,  1,  9,  4, 12])\n",
      " |      \n",
      " |      >>> arr = np.arange(9).reshape((3, 3))\n",
      " |      >>> np.random.permutation(arr)\n",
      " |      array([[6, 7, 8],\n",
      " |             [0, 1, 2],\n",
      " |             [3, 4, 5]])\n",
      " |  \n",
      " |  poisson(...)\n",
      " |      poisson(lam=1.0, size=None)\n",
      " |      \n",
      " |      Draw samples from a Poisson distribution.\n",
      " |      \n",
      " |      The Poisson distribution is the limit of the binomial distribution\n",
      " |      for large N.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      lam : float or array_like of floats\n",
      " |          Expectation of interval, should be >= 0. A sequence of expectation\n",
      " |          intervals must be broadcastable over the requested size.\n",
      " |      size : int or tuple of ints, optional\n",
      " |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      " |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      " |          a single value is returned if ``lam`` is a scalar. Otherwise,\n",
      " |          ``np.array(lam).size`` samples are drawn.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : ndarray or scalar\n",
      " |          Drawn samples from the parameterized Poisson distribution.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The Poisson distribution\n",
      " |      \n",
      " |      .. math:: f(k; \\lambda)=\\frac{\\lambda^k e^{-\\lambda}}{k!}\n",
      " |      \n",
      " |      For events with an expected separation :math:`\\lambda` the Poisson\n",
      " |      distribution :math:`f(k; \\lambda)` describes the probability of\n",
      " |      :math:`k` events occurring within the observed\n",
      " |      interval :math:`\\lambda`.\n",
      " |      \n",
      " |      Because the output is limited to the range of the C long type, a\n",
      " |      ValueError is raised when `lam` is within 10 sigma of the maximum\n",
      " |      representable value.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] Weisstein, Eric W. \"Poisson Distribution.\"\n",
      " |             From MathWorld--A Wolfram Web Resource.\n",
      " |             http://mathworld.wolfram.com/PoissonDistribution.html\n",
      " |      .. [2] Wikipedia, \"Poisson distribution\",\n",
      " |             http://en.wikipedia.org/wiki/Poisson_distribution\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Draw samples from the distribution:\n",
      " |      \n",
      " |      >>> import numpy as np\n",
      " |      >>> s = np.random.poisson(5, 10000)\n",
      " |      \n",
      " |      Display histogram of the sample:\n",
      " |      \n",
      " |      >>> import matplotlib.pyplot as plt\n",
      " |      >>> count, bins, ignored = plt.hist(s, 14, normed=True)\n",
      " |      >>> plt.show()\n",
      " |      \n",
      " |      Draw each 100 values for lambda 100 and 500:\n",
      " |      \n",
      " |      >>> s = np.random.poisson(lam=(100., 500.), size=(100, 2))\n",
      " |  \n",
      " |  power(...)\n",
      " |      power(a, size=None)\n",
      " |      \n",
      " |      Draws samples in [0, 1] from a power distribution with positive\n",
      " |      exponent a - 1.\n",
      " |      \n",
      " |      Also known as the power function distribution.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      a : float or array_like of floats\n",
      " |          Parameter of the distribution. Should be greater than zero.\n",
      " |      size : int or tuple of ints, optional\n",
      " |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      " |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      " |          a single value is returned if ``a`` is a scalar.  Otherwise,\n",
      " |          ``np.array(a).size`` samples are drawn.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : ndarray or scalar\n",
      " |          Drawn samples from the parameterized power distribution.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          If a < 1.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The probability density function is\n",
      " |      \n",
      " |      .. math:: P(x; a) = ax^{a-1}, 0 \\le x \\le 1, a>0.\n",
      " |      \n",
      " |      The power function distribution is just the inverse of the Pareto\n",
      " |      distribution. It may also be seen as a special case of the Beta\n",
      " |      distribution.\n",
      " |      \n",
      " |      It is used, for example, in modeling the over-reporting of insurance\n",
      " |      claims.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] Christian Kleiber, Samuel Kotz, \"Statistical size distributions\n",
      " |             in economics and actuarial sciences\", Wiley, 2003.\n",
      " |      .. [2] Heckert, N. A. and Filliben, James J. \"NIST Handbook 148:\n",
      " |             Dataplot Reference Manual, Volume 2: Let Subcommands and Library\n",
      " |             Functions\", National Institute of Standards and Technology\n",
      " |             Handbook Series, June 2003.\n",
      " |             http://www.itl.nist.gov/div898/software/dataplot/refman2/auxillar/powpdf.pdf\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Draw samples from the distribution:\n",
      " |      \n",
      " |      >>> a = 5. # shape\n",
      " |      >>> samples = 1000\n",
      " |      >>> s = np.random.power(a, samples)\n",
      " |      \n",
      " |      Display the histogram of the samples, along with\n",
      " |      the probability density function:\n",
      " |      \n",
      " |      >>> import matplotlib.pyplot as plt\n",
      " |      >>> count, bins, ignored = plt.hist(s, bins=30)\n",
      " |      >>> x = np.linspace(0, 1, 100)\n",
      " |      >>> y = a*x**(a-1.)\n",
      " |      >>> normed_y = samples*np.diff(bins)[0]*y\n",
      " |      >>> plt.plot(x, normed_y)\n",
      " |      >>> plt.show()\n",
      " |      \n",
      " |      Compare the power function distribution to the inverse of the Pareto.\n",
      " |      \n",
      " |      >>> from scipy import stats\n",
      " |      >>> rvs = np.random.power(5, 1000000)\n",
      " |      >>> rvsp = np.random.pareto(5, 1000000)\n",
      " |      >>> xx = np.linspace(0,1,100)\n",
      " |      >>> powpdf = stats.powerlaw.pdf(xx,5)\n",
      " |      \n",
      " |      >>> plt.figure()\n",
      " |      >>> plt.hist(rvs, bins=50, normed=True)\n",
      " |      >>> plt.plot(xx,powpdf,'r-')\n",
      " |      >>> plt.title('np.random.power(5)')\n",
      " |      \n",
      " |      >>> plt.figure()\n",
      " |      >>> plt.hist(1./(1.+rvsp), bins=50, normed=True)\n",
      " |      >>> plt.plot(xx,powpdf,'r-')\n",
      " |      >>> plt.title('inverse of 1 + np.random.pareto(5)')\n",
      " |      \n",
      " |      >>> plt.figure()\n",
      " |      >>> plt.hist(1./(1.+rvsp), bins=50, normed=True)\n",
      " |      >>> plt.plot(xx,powpdf,'r-')\n",
      " |      >>> plt.title('inverse of stats.pareto(5)')\n",
      " |  \n",
      " |  rand(...)\n",
      " |      rand(d0, d1, ..., dn)\n",
      " |      \n",
      " |      Random values in a given shape.\n",
      " |      \n",
      " |      Create an array of the given shape and populate it with\n",
      " |      random samples from a uniform distribution\n",
      " |      over ``[0, 1)``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      d0, d1, ..., dn : int, optional\n",
      " |          The dimensions of the returned array, should all be positive.\n",
      " |          If no argument is given a single Python float is returned.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : ndarray, shape ``(d0, d1, ..., dn)``\n",
      " |          Random values.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      random\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This is a convenience function. If you want an interface that\n",
      " |      takes a shape-tuple as the first argument, refer to\n",
      " |      np.random.random_sample .\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> np.random.rand(3,2)\n",
      " |      array([[ 0.14022471,  0.96360618],  #random\n",
      " |             [ 0.37601032,  0.25528411],  #random\n",
      " |             [ 0.49313049,  0.94909878]]) #random\n",
      " |  \n",
      " |  randint(...)\n",
      " |      randint(low, high=None, size=None, dtype='l')\n",
      " |      \n",
      " |      Return random integers from `low` (inclusive) to `high` (exclusive).\n",
      " |      \n",
      " |      Return random integers from the \"discrete uniform\" distribution of\n",
      " |      the specified dtype in the \"half-open\" interval [`low`, `high`). If\n",
      " |      `high` is None (the default), then results are from [0, `low`).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      low : int\n",
      " |          Lowest (signed) integer to be drawn from the distribution (unless\n",
      " |          ``high=None``, in which case this parameter is one above the\n",
      " |          *highest* such integer).\n",
      " |      high : int, optional\n",
      " |          If provided, one above the largest (signed) integer to be drawn\n",
      " |          from the distribution (see above for behavior if ``high=None``).\n",
      " |      size : int or tuple of ints, optional\n",
      " |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      " |          ``m * n * k`` samples are drawn.  Default is None, in which case a\n",
      " |          single value is returned.\n",
      " |      dtype : dtype, optional\n",
      " |          Desired dtype of the result. All dtypes are determined by their\n",
      " |          name, i.e., 'int64', 'int', etc, so byteorder is not available\n",
      " |          and a specific precision may have different C types depending\n",
      " |          on the platform. The default value is 'np.int'.\n",
      " |      \n",
      " |          .. versionadded:: 1.11.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : int or ndarray of ints\n",
      " |          `size`-shaped array of random integers from the appropriate\n",
      " |          distribution, or a single such random int if `size` not provided.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      random.random_integers : similar to `randint`, only for the closed\n",
      " |          interval [`low`, `high`], and 1 is the lowest value if `high` is\n",
      " |          omitted. In particular, this other one is the one to use to generate\n",
      " |          uniformly distributed discrete non-integers.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> np.random.randint(2, size=10)\n",
      " |      array([1, 0, 0, 0, 1, 1, 0, 0, 1, 0])\n",
      " |      >>> np.random.randint(1, size=10)\n",
      " |      array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      " |      \n",
      " |      Generate a 2 x 4 array of ints between 0 and 4, inclusive:\n",
      " |      \n",
      " |      >>> np.random.randint(5, size=(2, 4))\n",
      " |      array([[4, 0, 2, 1],\n",
      " |             [3, 2, 2, 0]])\n",
      " |  \n",
      " |  randn(...)\n",
      " |      randn(d0, d1, ..., dn)\n",
      " |      \n",
      " |      Return a sample (or samples) from the \"standard normal\" distribution.\n",
      " |      \n",
      " |      If positive, int_like or int-convertible arguments are provided,\n",
      " |      `randn` generates an array of shape ``(d0, d1, ..., dn)``, filled\n",
      " |      with random floats sampled from a univariate \"normal\" (Gaussian)\n",
      " |      distribution of mean 0 and variance 1 (if any of the :math:`d_i` are\n",
      " |      floats, they are first converted to integers by truncation). A single\n",
      " |      float randomly sampled from the distribution is returned if no\n",
      " |      argument is provided.\n",
      " |      \n",
      " |      This is a convenience function.  If you want an interface that takes a\n",
      " |      tuple as the first argument, use `numpy.random.standard_normal` instead.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      d0, d1, ..., dn : int, optional\n",
      " |          The dimensions of the returned array, should be all positive.\n",
      " |          If no argument is given a single Python float is returned.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Z : ndarray or float\n",
      " |          A ``(d0, d1, ..., dn)``-shaped array of floating-point samples from\n",
      " |          the standard normal distribution, or a single such float if\n",
      " |          no parameters were supplied.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      random.standard_normal : Similar, but takes a tuple as its argument.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For random samples from :math:`N(\\mu, \\sigma^2)`, use:\n",
      " |      \n",
      " |      ``sigma * np.random.randn(...) + mu``\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> np.random.randn()\n",
      " |      2.1923875335537315 #random\n",
      " |      \n",
      " |      Two-by-four array of samples from N(3, 6.25):\n",
      " |      \n",
      " |      >>> 2.5 * np.random.randn(2, 4) + 3\n",
      " |      array([[-4.49401501,  4.00950034, -1.81814867,  7.29718677],  #random\n",
      " |             [ 0.39924804,  4.68456316,  4.99394529,  4.84057254]]) #random\n",
      " |  \n",
      " |  random_integers(...)\n",
      " |      random_integers(low, high=None, size=None)\n",
      " |      \n",
      " |      Random integers of type np.int between `low` and `high`, inclusive.\n",
      " |      \n",
      " |      Return random integers of type np.int from the \"discrete uniform\"\n",
      " |      distribution in the closed interval [`low`, `high`].  If `high` is\n",
      " |      None (the default), then results are from [1, `low`]. The np.int\n",
      " |      type translates to the C long type used by Python 2 for \"short\"\n",
      " |      integers and its precision is platform dependent.\n",
      " |      \n",
      " |      This function has been deprecated. Use randint instead.\n",
      " |      \n",
      " |      .. deprecated:: 1.11.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      low : int\n",
      " |          Lowest (signed) integer to be drawn from the distribution (unless\n",
      " |          ``high=None``, in which case this parameter is the *highest* such\n",
      " |          integer).\n",
      " |      high : int, optional\n",
      " |          If provided, the largest (signed) integer to be drawn from the\n",
      " |          distribution (see above for behavior if ``high=None``).\n",
      " |      size : int or tuple of ints, optional\n",
      " |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      " |          ``m * n * k`` samples are drawn.  Default is None, in which case a\n",
      " |          single value is returned.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : int or ndarray of ints\n",
      " |          `size`-shaped array of random integers from the appropriate\n",
      " |          distribution, or a single such random int if `size` not provided.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      random.randint : Similar to `random_integers`, only for the half-open\n",
      " |          interval [`low`, `high`), and 0 is the lowest value if `high` is\n",
      " |          omitted.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      To sample from N evenly spaced floating-point numbers between a and b,\n",
      " |      use::\n",
      " |      \n",
      " |        a + (b - a) * (np.random.random_integers(N) - 1) / (N - 1.)\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> np.random.random_integers(5)\n",
      " |      4\n",
      " |      >>> type(np.random.random_integers(5))\n",
      " |      <type 'int'>\n",
      " |      >>> np.random.random_integers(5, size=(3.,2.))\n",
      " |      array([[5, 4],\n",
      " |             [3, 3],\n",
      " |             [4, 5]])\n",
      " |      \n",
      " |      Choose five random numbers from the set of five evenly-spaced\n",
      " |      numbers between 0 and 2.5, inclusive (*i.e.*, from the set\n",
      " |      :math:`{0, 5/8, 10/8, 15/8, 20/8}`):\n",
      " |      \n",
      " |      >>> 2.5 * (np.random.random_integers(5, size=(5,)) - 1) / 4.\n",
      " |      array([ 0.625,  1.25 ,  0.625,  0.625,  2.5  ])\n",
      " |      \n",
      " |      Roll two six sided dice 1000 times and sum the results:\n",
      " |      \n",
      " |      >>> d1 = np.random.random_integers(1, 6, 1000)\n",
      " |      >>> d2 = np.random.random_integers(1, 6, 1000)\n",
      " |      >>> dsums = d1 + d2\n",
      " |      \n",
      " |      Display results as a histogram:\n",
      " |      \n",
      " |      >>> import matplotlib.pyplot as plt\n",
      " |      >>> count, bins, ignored = plt.hist(dsums, 11, normed=True)\n",
      " |      >>> plt.show()\n",
      " |  \n",
      " |  random_sample(...)\n",
      " |      random_sample(size=None)\n",
      " |      \n",
      " |      Return random floats in the half-open interval [0.0, 1.0).\n",
      " |      \n",
      " |      Results are from the \"continuous uniform\" distribution over the\n",
      " |      stated interval.  To sample :math:`Unif[a, b), b > a` multiply\n",
      " |      the output of `random_sample` by `(b-a)` and add `a`::\n",
      " |      \n",
      " |        (b - a) * random_sample() + a\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      size : int or tuple of ints, optional\n",
      " |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      " |          ``m * n * k`` samples are drawn.  Default is None, in which case a\n",
      " |          single value is returned.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : float or ndarray of floats\n",
      " |          Array of random floats of shape `size` (unless ``size=None``, in which\n",
      " |          case a single float is returned).\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> np.random.random_sample()\n",
      " |      0.47108547995356098\n",
      " |      >>> type(np.random.random_sample())\n",
      " |      <type 'float'>\n",
      " |      >>> np.random.random_sample((5,))\n",
      " |      array([ 0.30220482,  0.86820401,  0.1654503 ,  0.11659149,  0.54323428])\n",
      " |      \n",
      " |      Three-by-two array of random numbers from [-5, 0):\n",
      " |      \n",
      " |      >>> 5 * np.random.random_sample((3, 2)) - 5\n",
      " |      array([[-3.99149989, -0.52338984],\n",
      " |             [-2.99091858, -0.79479508],\n",
      " |             [-1.23204345, -1.75224494]])\n",
      " |  \n",
      " |  rayleigh(...)\n",
      " |      rayleigh(scale=1.0, size=None)\n",
      " |      \n",
      " |      Draw samples from a Rayleigh distribution.\n",
      " |      \n",
      " |      The :math:`\\chi` and Weibull distributions are generalizations of the\n",
      " |      Rayleigh.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      scale : float or array_like of floats, optional\n",
      " |          Scale, also equals the mode. Should be >= 0. Default is 1.\n",
      " |      size : int or tuple of ints, optional\n",
      " |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      " |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      " |          a single value is returned if ``scale`` is a scalar.  Otherwise,\n",
      " |          ``np.array(scale).size`` samples are drawn.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : ndarray or scalar\n",
      " |          Drawn samples from the parameterized Rayleigh distribution.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The probability density function for the Rayleigh distribution is\n",
      " |      \n",
      " |      .. math:: P(x;scale) = \\frac{x}{scale^2}e^{\\frac{-x^2}{2 \\cdotp scale^2}}\n",
      " |      \n",
      " |      The Rayleigh distribution would arise, for example, if the East\n",
      " |      and North components of the wind velocity had identical zero-mean\n",
      " |      Gaussian distributions.  Then the wind speed would have a Rayleigh\n",
      " |      distribution.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] Brighton Webs Ltd., \"Rayleigh Distribution,\"\n",
      " |             http://www.brighton-webs.co.uk/distributions/rayleigh.asp\n",
      " |      .. [2] Wikipedia, \"Rayleigh distribution\"\n",
      " |             http://en.wikipedia.org/wiki/Rayleigh_distribution\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Draw values from the distribution and plot the histogram\n",
      " |      \n",
      " |      >>> values = hist(np.random.rayleigh(3, 100000), bins=200, normed=True)\n",
      " |      \n",
      " |      Wave heights tend to follow a Rayleigh distribution. If the mean wave\n",
      " |      height is 1 meter, what fraction of waves are likely to be larger than 3\n",
      " |      meters?\n",
      " |      \n",
      " |      >>> meanvalue = 1\n",
      " |      >>> modevalue = np.sqrt(2 / np.pi) * meanvalue\n",
      " |      >>> s = np.random.rayleigh(modevalue, 1000000)\n",
      " |      \n",
      " |      The percentage of waves larger than 3 meters is:\n",
      " |      \n",
      " |      >>> 100.*sum(s>3)/1000000.\n",
      " |      0.087300000000000003\n",
      " |  \n",
      " |  seed(...)\n",
      " |      seed(seed=None)\n",
      " |      \n",
      " |      Seed the generator.\n",
      " |      \n",
      " |      This method is called when `RandomState` is initialized. It can be\n",
      " |      called again to re-seed the generator. For details, see `RandomState`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      seed : int or array_like, optional\n",
      " |          Seed for `RandomState`.\n",
      " |          Must be convertible to 32 bit unsigned integers.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      RandomState\n",
      " |  \n",
      " |  set_state(...)\n",
      " |      set_state(state)\n",
      " |      \n",
      " |      Set the internal state of the generator from a tuple.\n",
      " |      \n",
      " |      For use if one has reason to manually (re-)set the internal state of the\n",
      " |      \"Mersenne Twister\"[1]_ pseudo-random number generating algorithm.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      state : tuple(str, ndarray of 624 uints, int, int, float)\n",
      " |          The `state` tuple has the following items:\n",
      " |      \n",
      " |          1. the string 'MT19937', specifying the Mersenne Twister algorithm.\n",
      " |          2. a 1-D array of 624 unsigned integers ``keys``.\n",
      " |          3. an integer ``pos``.\n",
      " |          4. an integer ``has_gauss``.\n",
      " |          5. a float ``cached_gaussian``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : None\n",
      " |          Returns 'None' on success.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      get_state\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      `set_state` and `get_state` are not needed to work with any of the\n",
      " |      random distributions in NumPy. If the internal state is manually altered,\n",
      " |      the user should know exactly what he/she is doing.\n",
      " |      \n",
      " |      For backwards compatibility, the form (str, array of 624 uints, int) is\n",
      " |      also accepted although it is missing some information about the cached\n",
      " |      Gaussian value: ``state = ('MT19937', keys, pos)``.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] M. Matsumoto and T. Nishimura, \"Mersenne Twister: A\n",
      " |         623-dimensionally equidistributed uniform pseudorandom number\n",
      " |         generator,\" *ACM Trans. on Modeling and Computer Simulation*,\n",
      " |         Vol. 8, No. 1, pp. 3-30, Jan. 1998.\n",
      " |  \n",
      " |  shuffle(...)\n",
      " |      shuffle(x)\n",
      " |      \n",
      " |      Modify a sequence in-place by shuffling its contents.\n",
      " |      \n",
      " |      This function only shuffles the array along the first axis of a\n",
      " |      multi-dimensional array. The order of sub-arrays is changed but\n",
      " |      their contents remains the same.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      x : array_like\n",
      " |          The array or list to be shuffled.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      None\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> arr = np.arange(10)\n",
      " |      >>> np.random.shuffle(arr)\n",
      " |      >>> arr\n",
      " |      [1 7 5 2 9 4 3 6 0 8]\n",
      " |      \n",
      " |      Multi-dimensional arrays are only shuffled along the first axis:\n",
      " |      \n",
      " |      >>> arr = np.arange(9).reshape((3, 3))\n",
      " |      >>> np.random.shuffle(arr)\n",
      " |      >>> arr\n",
      " |      array([[3, 4, 5],\n",
      " |             [6, 7, 8],\n",
      " |             [0, 1, 2]])\n",
      " |  \n",
      " |  standard_cauchy(...)\n",
      " |      standard_cauchy(size=None)\n",
      " |      \n",
      " |      Draw samples from a standard Cauchy distribution with mode = 0.\n",
      " |      \n",
      " |      Also known as the Lorentz distribution.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      size : int or tuple of ints, optional\n",
      " |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      " |          ``m * n * k`` samples are drawn.  Default is None, in which case a\n",
      " |          single value is returned.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      samples : ndarray or scalar\n",
      " |          The drawn samples.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The probability density function for the full Cauchy distribution is\n",
      " |      \n",
      " |      .. math:: P(x; x_0, \\gamma) = \\frac{1}{\\pi \\gamma \\bigl[ 1+\n",
      " |                (\\frac{x-x_0}{\\gamma})^2 \\bigr] }\n",
      " |      \n",
      " |      and the Standard Cauchy distribution just sets :math:`x_0=0` and\n",
      " |      :math:`\\gamma=1`\n",
      " |      \n",
      " |      The Cauchy distribution arises in the solution to the driven harmonic\n",
      " |      oscillator problem, and also describes spectral line broadening. It\n",
      " |      also describes the distribution of values at which a line tilted at\n",
      " |      a random angle will cut the x axis.\n",
      " |      \n",
      " |      When studying hypothesis tests that assume normality, seeing how the\n",
      " |      tests perform on data from a Cauchy distribution is a good indicator of\n",
      " |      their sensitivity to a heavy-tailed distribution, since the Cauchy looks\n",
      " |      very much like a Gaussian distribution, but with heavier tails.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] NIST/SEMATECH e-Handbook of Statistical Methods, \"Cauchy\n",
      " |            Distribution\",\n",
      " |            http://www.itl.nist.gov/div898/handbook/eda/section3/eda3663.htm\n",
      " |      .. [2] Weisstein, Eric W. \"Cauchy Distribution.\" From MathWorld--A\n",
      " |            Wolfram Web Resource.\n",
      " |            http://mathworld.wolfram.com/CauchyDistribution.html\n",
      " |      .. [3] Wikipedia, \"Cauchy distribution\"\n",
      " |            http://en.wikipedia.org/wiki/Cauchy_distribution\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Draw samples and plot the distribution:\n",
      " |      \n",
      " |      >>> s = np.random.standard_cauchy(1000000)\n",
      " |      >>> s = s[(s>-25) & (s<25)]  # truncate distribution so it plots well\n",
      " |      >>> plt.hist(s, bins=100)\n",
      " |      >>> plt.show()\n",
      " |  \n",
      " |  standard_exponential(...)\n",
      " |      standard_exponential(size=None)\n",
      " |      \n",
      " |      Draw samples from the standard exponential distribution.\n",
      " |      \n",
      " |      `standard_exponential` is identical to the exponential distribution\n",
      " |      with a scale parameter of 1.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      size : int or tuple of ints, optional\n",
      " |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      " |          ``m * n * k`` samples are drawn.  Default is None, in which case a\n",
      " |          single value is returned.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : float or ndarray\n",
      " |          Drawn samples.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Output a 3x8000 array:\n",
      " |      \n",
      " |      >>> n = np.random.standard_exponential((3, 8000))\n",
      " |  \n",
      " |  standard_gamma(...)\n",
      " |      standard_gamma(shape, size=None)\n",
      " |      \n",
      " |      Draw samples from a standard Gamma distribution.\n",
      " |      \n",
      " |      Samples are drawn from a Gamma distribution with specified parameters,\n",
      " |      shape (sometimes designated \"k\") and scale=1.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      shape : float or array_like of floats\n",
      " |          Parameter, should be > 0.\n",
      " |      size : int or tuple of ints, optional\n",
      " |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      " |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      " |          a single value is returned if ``shape`` is a scalar.  Otherwise,\n",
      " |          ``np.array(shape).size`` samples are drawn.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : ndarray or scalar\n",
      " |          Drawn samples from the parameterized standard gamma distribution.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      scipy.stats.gamma : probability density function, distribution or\n",
      " |          cumulative density function, etc.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The probability density for the Gamma distribution is\n",
      " |      \n",
      " |      .. math:: p(x) = x^{k-1}\\frac{e^{-x/\\theta}}{\\theta^k\\Gamma(k)},\n",
      " |      \n",
      " |      where :math:`k` is the shape and :math:`\\theta` the scale,\n",
      " |      and :math:`\\Gamma` is the Gamma function.\n",
      " |      \n",
      " |      The Gamma distribution is often used to model the times to failure of\n",
      " |      electronic components, and arises naturally in processes for which the\n",
      " |      waiting times between Poisson distributed events are relevant.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] Weisstein, Eric W. \"Gamma Distribution.\" From MathWorld--A\n",
      " |             Wolfram Web Resource.\n",
      " |             http://mathworld.wolfram.com/GammaDistribution.html\n",
      " |      .. [2] Wikipedia, \"Gamma distribution\",\n",
      " |             http://en.wikipedia.org/wiki/Gamma_distribution\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Draw samples from the distribution:\n",
      " |      \n",
      " |      >>> shape, scale = 2., 1. # mean and width\n",
      " |      >>> s = np.random.standard_gamma(shape, 1000000)\n",
      " |      \n",
      " |      Display the histogram of the samples, along with\n",
      " |      the probability density function:\n",
      " |      \n",
      " |      >>> import matplotlib.pyplot as plt\n",
      " |      >>> import scipy.special as sps\n",
      " |      >>> count, bins, ignored = plt.hist(s, 50, normed=True)\n",
      " |      >>> y = bins**(shape-1) * ((np.exp(-bins/scale))/ \\\n",
      " |      ...                       (sps.gamma(shape) * scale**shape))\n",
      " |      >>> plt.plot(bins, y, linewidth=2, color='r')\n",
      " |      >>> plt.show()\n",
      " |  \n",
      " |  standard_normal(...)\n",
      " |      standard_normal(size=None)\n",
      " |      \n",
      " |      Draw samples from a standard Normal distribution (mean=0, stdev=1).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      size : int or tuple of ints, optional\n",
      " |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      " |          ``m * n * k`` samples are drawn.  Default is None, in which case a\n",
      " |          single value is returned.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : float or ndarray\n",
      " |          Drawn samples.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> s = np.random.standard_normal(8000)\n",
      " |      >>> s\n",
      " |      array([ 0.6888893 ,  0.78096262, -0.89086505, ...,  0.49876311, #random\n",
      " |             -0.38672696, -0.4685006 ])                               #random\n",
      " |      >>> s.shape\n",
      " |      (8000,)\n",
      " |      >>> s = np.random.standard_normal(size=(3, 4, 2))\n",
      " |      >>> s.shape\n",
      " |      (3, 4, 2)\n",
      " |  \n",
      " |  standard_t(...)\n",
      " |      standard_t(df, size=None)\n",
      " |      \n",
      " |      Draw samples from a standard Student's t distribution with `df` degrees\n",
      " |      of freedom.\n",
      " |      \n",
      " |      A special case of the hyperbolic distribution.  As `df` gets\n",
      " |      large, the result resembles that of the standard normal\n",
      " |      distribution (`standard_normal`).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      df : int or array_like of ints\n",
      " |          Degrees of freedom, should be > 0.\n",
      " |      size : int or tuple of ints, optional\n",
      " |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      " |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      " |          a single value is returned if ``df`` is a scalar.  Otherwise,\n",
      " |          ``np.array(df).size`` samples are drawn.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : ndarray or scalar\n",
      " |          Drawn samples from the parameterized standard Student's t distribution.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The probability density function for the t distribution is\n",
      " |      \n",
      " |      .. math:: P(x, df) = \\frac{\\Gamma(\\frac{df+1}{2})}{\\sqrt{\\pi df}\n",
      " |                \\Gamma(\\frac{df}{2})}\\Bigl( 1+\\frac{x^2}{df} \\Bigr)^{-(df+1)/2}\n",
      " |      \n",
      " |      The t test is based on an assumption that the data come from a\n",
      " |      Normal distribution. The t test provides a way to test whether\n",
      " |      the sample mean (that is the mean calculated from the data) is\n",
      " |      a good estimate of the true mean.\n",
      " |      \n",
      " |      The derivation of the t-distribution was first published in\n",
      " |      1908 by William Gisset while working for the Guinness Brewery\n",
      " |      in Dublin. Due to proprietary issues, he had to publish under\n",
      " |      a pseudonym, and so he used the name Student.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] Dalgaard, Peter, \"Introductory Statistics With R\",\n",
      " |             Springer, 2002.\n",
      " |      .. [2] Wikipedia, \"Student's t-distribution\"\n",
      " |             http://en.wikipedia.org/wiki/Student's_t-distribution\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      From Dalgaard page 83 [1]_, suppose the daily energy intake for 11\n",
      " |      women in Kj is:\n",
      " |      \n",
      " |      >>> intake = np.array([5260., 5470, 5640, 6180, 6390, 6515, 6805, 7515, \\\n",
      " |      ...                    7515, 8230, 8770])\n",
      " |      \n",
      " |      Does their energy intake deviate systematically from the recommended\n",
      " |      value of 7725 kJ?\n",
      " |      \n",
      " |      We have 10 degrees of freedom, so is the sample mean within 95% of the\n",
      " |      recommended value?\n",
      " |      \n",
      " |      >>> s = np.random.standard_t(10, size=100000)\n",
      " |      >>> np.mean(intake)\n",
      " |      6753.636363636364\n",
      " |      >>> intake.std(ddof=1)\n",
      " |      1142.1232221373727\n",
      " |      \n",
      " |      Calculate the t statistic, setting the ddof parameter to the unbiased\n",
      " |      value so the divisor in the standard deviation will be degrees of\n",
      " |      freedom, N-1.\n",
      " |      \n",
      " |      >>> t = (np.mean(intake)-7725)/(intake.std(ddof=1)/np.sqrt(len(intake)))\n",
      " |      >>> import matplotlib.pyplot as plt\n",
      " |      >>> h = plt.hist(s, bins=100, normed=True)\n",
      " |      \n",
      " |      For a one-sided t-test, how far out in the distribution does the t\n",
      " |      statistic appear?\n",
      " |      \n",
      " |      >>> np.sum(s<t) / float(len(s))\n",
      " |      0.0090699999999999999  #random\n",
      " |      \n",
      " |      So the p-value is about 0.009, which says the null hypothesis has a\n",
      " |      probability of about 99% of being true.\n",
      " |  \n",
      " |  tomaxint(...)\n",
      " |      tomaxint(size=None)\n",
      " |      \n",
      " |      Random integers between 0 and ``sys.maxint``, inclusive.\n",
      " |      \n",
      " |      Return a sample of uniformly distributed random integers in the interval\n",
      " |      [0, ``sys.maxint``].\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      size : int or tuple of ints, optional\n",
      " |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      " |          ``m * n * k`` samples are drawn.  Default is None, in which case a\n",
      " |          single value is returned.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : ndarray\n",
      " |          Drawn samples, with shape `size`.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      randint : Uniform sampling over a given half-open interval of integers.\n",
      " |      random_integers : Uniform sampling over a given closed interval of\n",
      " |          integers.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> RS = np.random.mtrand.RandomState() # need a RandomState object\n",
      " |      >>> RS.tomaxint((2,2,2))\n",
      " |      array([[[1170048599, 1600360186],\n",
      " |              [ 739731006, 1947757578]],\n",
      " |             [[1871712945,  752307660],\n",
      " |              [1601631370, 1479324245]]])\n",
      " |      >>> import sys\n",
      " |      >>> sys.maxint\n",
      " |      2147483647\n",
      " |      >>> RS.tomaxint((2,2,2)) < sys.maxint\n",
      " |      array([[[ True,  True],\n",
      " |              [ True,  True]],\n",
      " |             [[ True,  True],\n",
      " |              [ True,  True]]], dtype=bool)\n",
      " |  \n",
      " |  triangular(...)\n",
      " |      triangular(left, mode, right, size=None)\n",
      " |      \n",
      " |      Draw samples from the triangular distribution over the\n",
      " |      interval ``[left, right]``.\n",
      " |      \n",
      " |      The triangular distribution is a continuous probability\n",
      " |      distribution with lower limit left, peak at mode, and upper\n",
      " |      limit right. Unlike the other distributions, these parameters\n",
      " |      directly define the shape of the pdf.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      left : float or array_like of floats\n",
      " |          Lower limit.\n",
      " |      mode : float or array_like of floats\n",
      " |          The value where the peak of the distribution occurs.\n",
      " |          The value should fulfill the condition ``left <= mode <= right``.\n",
      " |      right : float or array_like of floats\n",
      " |          Upper limit, should be larger than `left`.\n",
      " |      size : int or tuple of ints, optional\n",
      " |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      " |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      " |          a single value is returned if ``left``, ``mode``, and ``right``\n",
      " |          are all scalars.  Otherwise, ``np.broadcast(left, mode, right).size``\n",
      " |          samples are drawn.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : ndarray or scalar\n",
      " |          Drawn samples from the parameterized triangular distribution.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The probability density function for the triangular distribution is\n",
      " |      \n",
      " |      .. math:: P(x;l, m, r) = \\begin{cases}\n",
      " |                \\frac{2(x-l)}{(r-l)(m-l)}& \\text{for $l \\leq x \\leq m$},\\\\\n",
      " |                \\frac{2(r-x)}{(r-l)(r-m)}& \\text{for $m \\leq x \\leq r$},\\\\\n",
      " |                0& \\text{otherwise}.\n",
      " |                \\end{cases}\n",
      " |      \n",
      " |      The triangular distribution is often used in ill-defined\n",
      " |      problems where the underlying distribution is not known, but\n",
      " |      some knowledge of the limits and mode exists. Often it is used\n",
      " |      in simulations.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] Wikipedia, \"Triangular distribution\"\n",
      " |             http://en.wikipedia.org/wiki/Triangular_distribution\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Draw values from the distribution and plot the histogram:\n",
      " |      \n",
      " |      >>> import matplotlib.pyplot as plt\n",
      " |      >>> h = plt.hist(np.random.triangular(-3, 0, 8, 100000), bins=200,\n",
      " |      ...              normed=True)\n",
      " |      >>> plt.show()\n",
      " |  \n",
      " |  uniform(...)\n",
      " |      uniform(low=0.0, high=1.0, size=None)\n",
      " |      \n",
      " |      Draw samples from a uniform distribution.\n",
      " |      \n",
      " |      Samples are uniformly distributed over the half-open interval\n",
      " |      ``[low, high)`` (includes low, but excludes high).  In other words,\n",
      " |      any value within the given interval is equally likely to be drawn\n",
      " |      by `uniform`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      low : float or array_like of floats, optional\n",
      " |          Lower boundary of the output interval.  All values generated will be\n",
      " |          greater than or equal to low.  The default value is 0.\n",
      " |      high : float or array_like of floats\n",
      " |          Upper boundary of the output interval.  All values generated will be\n",
      " |          less than high.  The default value is 1.0.\n",
      " |      size : int or tuple of ints, optional\n",
      " |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      " |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      " |          a single value is returned if ``low`` and ``high`` are both scalars.\n",
      " |          Otherwise, ``np.broadcast(low, high).size`` samples are drawn.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : ndarray or scalar\n",
      " |          Drawn samples from the parameterized uniform distribution.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      randint : Discrete uniform distribution, yielding integers.\n",
      " |      random_integers : Discrete uniform distribution over the closed\n",
      " |                        interval ``[low, high]``.\n",
      " |      random_sample : Floats uniformly distributed over ``[0, 1)``.\n",
      " |      random : Alias for `random_sample`.\n",
      " |      rand : Convenience function that accepts dimensions as input, e.g.,\n",
      " |             ``rand(2,2)`` would generate a 2-by-2 array of floats,\n",
      " |             uniformly distributed over ``[0, 1)``.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The probability density function of the uniform distribution is\n",
      " |      \n",
      " |      .. math:: p(x) = \\frac{1}{b - a}\n",
      " |      \n",
      " |      anywhere within the interval ``[a, b)``, and zero elsewhere.\n",
      " |      \n",
      " |      When ``high`` == ``low``, values of ``low`` will be returned.\n",
      " |      If ``high`` < ``low``, the results are officially undefined\n",
      " |      and may eventually raise an error, i.e. do not rely on this\n",
      " |      function to behave when passed arguments satisfying that\n",
      " |      inequality condition.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Draw samples from the distribution:\n",
      " |      \n",
      " |      >>> s = np.random.uniform(-1,0,1000)\n",
      " |      \n",
      " |      All values are within the given interval:\n",
      " |      \n",
      " |      >>> np.all(s >= -1)\n",
      " |      True\n",
      " |      >>> np.all(s < 0)\n",
      " |      True\n",
      " |      \n",
      " |      Display the histogram of the samples, along with the\n",
      " |      probability density function:\n",
      " |      \n",
      " |      >>> import matplotlib.pyplot as plt\n",
      " |      >>> count, bins, ignored = plt.hist(s, 15, normed=True)\n",
      " |      >>> plt.plot(bins, np.ones_like(bins), linewidth=2, color='r')\n",
      " |      >>> plt.show()\n",
      " |  \n",
      " |  vonmises(...)\n",
      " |      vonmises(mu, kappa, size=None)\n",
      " |      \n",
      " |      Draw samples from a von Mises distribution.\n",
      " |      \n",
      " |      Samples are drawn from a von Mises distribution with specified mode\n",
      " |      (mu) and dispersion (kappa), on the interval [-pi, pi].\n",
      " |      \n",
      " |      The von Mises distribution (also known as the circular normal\n",
      " |      distribution) is a continuous probability distribution on the unit\n",
      " |      circle.  It may be thought of as the circular analogue of the normal\n",
      " |      distribution.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      mu : float or array_like of floats\n",
      " |          Mode (\"center\") of the distribution.\n",
      " |      kappa : float or array_like of floats\n",
      " |          Dispersion of the distribution, has to be >=0.\n",
      " |      size : int or tuple of ints, optional\n",
      " |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      " |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      " |          a single value is returned if ``mu`` and ``kappa`` are both scalars.\n",
      " |          Otherwise, ``np.broadcast(mu, kappa).size`` samples are drawn.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : ndarray or scalar\n",
      " |          Drawn samples from the parameterized von Mises distribution.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      scipy.stats.vonmises : probability density function, distribution, or\n",
      " |          cumulative density function, etc.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The probability density for the von Mises distribution is\n",
      " |      \n",
      " |      .. math:: p(x) = \\frac{e^{\\kappa cos(x-\\mu)}}{2\\pi I_0(\\kappa)},\n",
      " |      \n",
      " |      where :math:`\\mu` is the mode and :math:`\\kappa` the dispersion,\n",
      " |      and :math:`I_0(\\kappa)` is the modified Bessel function of order 0.\n",
      " |      \n",
      " |      The von Mises is named for Richard Edler von Mises, who was born in\n",
      " |      Austria-Hungary, in what is now the Ukraine.  He fled to the United\n",
      " |      States in 1939 and became a professor at Harvard.  He worked in\n",
      " |      probability theory, aerodynamics, fluid mechanics, and philosophy of\n",
      " |      science.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] Abramowitz, M. and Stegun, I. A. (Eds.). \"Handbook of\n",
      " |             Mathematical Functions with Formulas, Graphs, and Mathematical\n",
      " |             Tables, 9th printing,\" New York: Dover, 1972.\n",
      " |      .. [2] von Mises, R., \"Mathematical Theory of Probability\n",
      " |             and Statistics\", New York: Academic Press, 1964.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Draw samples from the distribution:\n",
      " |      \n",
      " |      >>> mu, kappa = 0.0, 4.0 # mean and dispersion\n",
      " |      >>> s = np.random.vonmises(mu, kappa, 1000)\n",
      " |      \n",
      " |      Display the histogram of the samples, along with\n",
      " |      the probability density function:\n",
      " |      \n",
      " |      >>> import matplotlib.pyplot as plt\n",
      " |      >>> from scipy.special import i0\n",
      " |      >>> plt.hist(s, 50, normed=True)\n",
      " |      >>> x = np.linspace(-np.pi, np.pi, num=51)\n",
      " |      >>> y = np.exp(kappa*np.cos(x-mu))/(2*np.pi*i0(kappa))\n",
      " |      >>> plt.plot(x, y, linewidth=2, color='r')\n",
      " |      >>> plt.show()\n",
      " |  \n",
      " |  wald(...)\n",
      " |      wald(mean, scale, size=None)\n",
      " |      \n",
      " |      Draw samples from a Wald, or inverse Gaussian, distribution.\n",
      " |      \n",
      " |      As the scale approaches infinity, the distribution becomes more like a\n",
      " |      Gaussian. Some references claim that the Wald is an inverse Gaussian\n",
      " |      with mean equal to 1, but this is by no means universal.\n",
      " |      \n",
      " |      The inverse Gaussian distribution was first studied in relationship to\n",
      " |      Brownian motion. In 1956 M.C.K. Tweedie used the name inverse Gaussian\n",
      " |      because there is an inverse relationship between the time to cover a\n",
      " |      unit distance and distance covered in unit time.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      mean : float or array_like of floats\n",
      " |          Distribution mean, should be > 0.\n",
      " |      scale : float or array_like of floats\n",
      " |          Scale parameter, should be >= 0.\n",
      " |      size : int or tuple of ints, optional\n",
      " |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      " |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      " |          a single value is returned if ``mean`` and ``scale`` are both scalars.\n",
      " |          Otherwise, ``np.broadcast(mean, scale).size`` samples are drawn.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : ndarray or scalar\n",
      " |          Drawn samples from the parameterized Wald distribution.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The probability density function for the Wald distribution is\n",
      " |      \n",
      " |      .. math:: P(x;mean,scale) = \\sqrt{\\frac{scale}{2\\pi x^3}}e^\n",
      " |                                  \\frac{-scale(x-mean)^2}{2\\cdotp mean^2x}\n",
      " |      \n",
      " |      As noted above the inverse Gaussian distribution first arise\n",
      " |      from attempts to model Brownian motion. It is also a\n",
      " |      competitor to the Weibull for use in reliability modeling and\n",
      " |      modeling stock returns and interest rate processes.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] Brighton Webs Ltd., Wald Distribution,\n",
      " |             http://www.brighton-webs.co.uk/distributions/wald.asp\n",
      " |      .. [2] Chhikara, Raj S., and Folks, J. Leroy, \"The Inverse Gaussian\n",
      " |             Distribution: Theory : Methodology, and Applications\", CRC Press,\n",
      " |             1988.\n",
      " |      .. [3] Wikipedia, \"Wald distribution\"\n",
      " |             http://en.wikipedia.org/wiki/Wald_distribution\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Draw values from the distribution and plot the histogram:\n",
      " |      \n",
      " |      >>> import matplotlib.pyplot as plt\n",
      " |      >>> h = plt.hist(np.random.wald(3, 2, 100000), bins=200, normed=True)\n",
      " |      >>> plt.show()\n",
      " |  \n",
      " |  weibull(...)\n",
      " |      weibull(a, size=None)\n",
      " |      \n",
      " |      Draw samples from a Weibull distribution.\n",
      " |      \n",
      " |      Draw samples from a 1-parameter Weibull distribution with the given\n",
      " |      shape parameter `a`.\n",
      " |      \n",
      " |      .. math:: X = (-ln(U))^{1/a}\n",
      " |      \n",
      " |      Here, U is drawn from the uniform distribution over (0,1].\n",
      " |      \n",
      " |      The more common 2-parameter Weibull, including a scale parameter\n",
      " |      :math:`\\lambda` is just :math:`X = \\lambda(-ln(U))^{1/a}`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      a : float or array_like of floats\n",
      " |          Shape of the distribution. Should be greater than zero.\n",
      " |      size : int or tuple of ints, optional\n",
      " |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      " |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      " |          a single value is returned if ``a`` is a scalar.  Otherwise,\n",
      " |          ``np.array(a).size`` samples are drawn.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : ndarray or scalar\n",
      " |          Drawn samples from the parameterized Weibull distribution.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      scipy.stats.weibull_max\n",
      " |      scipy.stats.weibull_min\n",
      " |      scipy.stats.genextreme\n",
      " |      gumbel\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The Weibull (or Type III asymptotic extreme value distribution\n",
      " |      for smallest values, SEV Type III, or Rosin-Rammler\n",
      " |      distribution) is one of a class of Generalized Extreme Value\n",
      " |      (GEV) distributions used in modeling extreme value problems.\n",
      " |      This class includes the Gumbel and Frechet distributions.\n",
      " |      \n",
      " |      The probability density for the Weibull distribution is\n",
      " |      \n",
      " |      .. math:: p(x) = \\frac{a}\n",
      " |                       {\\lambda}(\\frac{x}{\\lambda})^{a-1}e^{-(x/\\lambda)^a},\n",
      " |      \n",
      " |      where :math:`a` is the shape and :math:`\\lambda` the scale.\n",
      " |      \n",
      " |      The function has its peak (the mode) at\n",
      " |      :math:`\\lambda(\\frac{a-1}{a})^{1/a}`.\n",
      " |      \n",
      " |      When ``a = 1``, the Weibull distribution reduces to the exponential\n",
      " |      distribution.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] Waloddi Weibull, Royal Technical University, Stockholm,\n",
      " |             1939 \"A Statistical Theory Of The Strength Of Materials\",\n",
      " |             Ingeniorsvetenskapsakademiens Handlingar Nr 151, 1939,\n",
      " |             Generalstabens Litografiska Anstalts Forlag, Stockholm.\n",
      " |      .. [2] Waloddi Weibull, \"A Statistical Distribution Function of\n",
      " |             Wide Applicability\", Journal Of Applied Mechanics ASME Paper\n",
      " |             1951.\n",
      " |      .. [3] Wikipedia, \"Weibull distribution\",\n",
      " |             http://en.wikipedia.org/wiki/Weibull_distribution\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Draw samples from the distribution:\n",
      " |      \n",
      " |      >>> a = 5. # shape\n",
      " |      >>> s = np.random.weibull(a, 1000)\n",
      " |      \n",
      " |      Display the histogram of the samples, along with\n",
      " |      the probability density function:\n",
      " |      \n",
      " |      >>> import matplotlib.pyplot as plt\n",
      " |      >>> x = np.arange(1,100.)/50.\n",
      " |      >>> def weib(x,n,a):\n",
      " |      ...     return (a / n) * (x / n)**(a - 1) * np.exp(-(x / n)**a)\n",
      " |      \n",
      " |      >>> count, bins, ignored = plt.hist(np.random.weibull(5.,1000))\n",
      " |      >>> x = np.arange(1,100.)/50.\n",
      " |      >>> scale = count.max()/weib(x, 1., 5.).max()\n",
      " |      >>> plt.plot(x, weib(x, 1., 5.)*scale)\n",
      " |      >>> plt.show()\n",
      " |  \n",
      " |  zipf(...)\n",
      " |      zipf(a, size=None)\n",
      " |      \n",
      " |      Draw samples from a Zipf distribution.\n",
      " |      \n",
      " |      Samples are drawn from a Zipf distribution with specified parameter\n",
      " |      `a` > 1.\n",
      " |      \n",
      " |      The Zipf distribution (also known as the zeta distribution) is a\n",
      " |      continuous probability distribution that satisfies Zipf's law: the\n",
      " |      frequency of an item is inversely proportional to its rank in a\n",
      " |      frequency table.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      a : float or array_like of floats\n",
      " |          Distribution parameter. Should be greater than 1.\n",
      " |      size : int or tuple of ints, optional\n",
      " |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      " |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      " |          a single value is returned if ``a`` is a scalar. Otherwise,\n",
      " |          ``np.array(a).size`` samples are drawn.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      out : ndarray or scalar\n",
      " |          Drawn samples from the parameterized Zipf distribution.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      scipy.stats.zipf : probability density function, distribution, or\n",
      " |          cumulative density function, etc.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The probability density for the Zipf distribution is\n",
      " |      \n",
      " |      .. math:: p(x) = \\frac{x^{-a}}{\\zeta(a)},\n",
      " |      \n",
      " |      where :math:`\\zeta` is the Riemann Zeta function.\n",
      " |      \n",
      " |      It is named for the American linguist George Kingsley Zipf, who noted\n",
      " |      that the frequency of any word in a sample of a language is inversely\n",
      " |      proportional to its rank in the frequency table.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] Zipf, G. K., \"Selected Studies of the Principle of Relative\n",
      " |             Frequency in Language,\" Cambridge, MA: Harvard Univ. Press,\n",
      " |             1932.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Draw samples from the distribution:\n",
      " |      \n",
      " |      >>> a = 2. # parameter\n",
      " |      >>> s = np.random.zipf(a, 1000)\n",
      " |      \n",
      " |      Display the histogram of the samples, along with\n",
      " |      the probability density function:\n",
      " |      \n",
      " |      >>> import matplotlib.pyplot as plt\n",
      " |      >>> from scipy import special\n",
      " |      \n",
      " |      Truncate s values at 50 so plot is interesting:\n",
      " |      \n",
      " |      >>> count, bins, ignored = plt.hist(s[s<50], 50, normed=True)\n",
      " |      >>> x = np.arange(1., 50.)\n",
      " |      >>> y = x**(-a) / special.zetac(a)\n",
      " |      >>> plt.plot(x, y/max(y), linewidth=2, color='r')\n",
      " |      >>> plt.show()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __pyx_vtable__ = <capsule object NULL>\n",
      " |  \n",
      " |  poisson_lam_max = 9.2233720064847708e+18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(RandomState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_size=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=rdm.rand(dataset_size,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y=[[int(x1 + x2 < 1)] for (x1,x2) in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.81131822  1.48459876  0.06532937]\n",
      " [-2.44270396  0.0992484   0.59122431]]\n",
      "[[-0.81131822]\n",
      " [ 1.48459876]\n",
      " [ 0.06532937]]\n",
      "After 0 training step(s),cross entropy on all data is 0.0674925\n",
      "After 1 training step(s),cross entropy on all data is 0.0672511\n",
      "After 2 training step(s),cross entropy on all data is 0.0670647\n",
      "After 3 training step(s),cross entropy on all data is 0.066914\n",
      "After 4 training step(s),cross entropy on all data is 0.0667947\n",
      "After 5 training step(s),cross entropy on all data is 0.0666918\n",
      "After 6 training step(s),cross entropy on all data is 0.0665712\n",
      "After 7 training step(s),cross entropy on all data is 0.0664202\n",
      "After 8 training step(s),cross entropy on all data is 0.0662492\n",
      "After 9 training step(s),cross entropy on all data is 0.066075\n",
      "After 10 training step(s),cross entropy on all data is 0.0659034\n",
      "After 11 training step(s),cross entropy on all data is 0.0657333\n",
      "After 12 training step(s),cross entropy on all data is 0.0655595\n",
      "After 13 training step(s),cross entropy on all data is 0.065385\n",
      "After 14 training step(s),cross entropy on all data is 0.0652272\n",
      "After 15 training step(s),cross entropy on all data is 0.0650843\n",
      "After 16 training step(s),cross entropy on all data is 0.0649217\n",
      "After 17 training step(s),cross entropy on all data is 0.0647457\n",
      "After 18 training step(s),cross entropy on all data is 0.0645858\n",
      "After 19 training step(s),cross entropy on all data is 0.0644406\n",
      "After 20 training step(s),cross entropy on all data is 0.0643085\n",
      "After 21 training step(s),cross entropy on all data is 0.0641883\n",
      "After 22 training step(s),cross entropy on all data is 0.0640613\n",
      "After 23 training step(s),cross entropy on all data is 0.0639122\n",
      "After 24 training step(s),cross entropy on all data is 0.0637453\n",
      "After 25 training step(s),cross entropy on all data is 0.0635762\n",
      "After 26 training step(s),cross entropy on all data is 0.0634173\n",
      "After 27 training step(s),cross entropy on all data is 0.0632631\n",
      "After 28 training step(s),cross entropy on all data is 0.063106\n",
      "After 29 training step(s),cross entropy on all data is 0.0629485\n",
      "After 30 training step(s),cross entropy on all data is 0.0628051\n",
      "After 31 training step(s),cross entropy on all data is 0.0626746\n",
      "After 32 training step(s),cross entropy on all data is 0.0625259\n",
      "After 33 training step(s),cross entropy on all data is 0.0623641\n",
      "After 34 training step(s),cross entropy on all data is 0.0622169\n",
      "After 35 training step(s),cross entropy on all data is 0.0620829\n",
      "After 36 training step(s),cross entropy on all data is 0.061961\n",
      "After 37 training step(s),cross entropy on all data is 0.0618501\n",
      "After 38 training step(s),cross entropy on all data is 0.0617338\n",
      "After 39 training step(s),cross entropy on all data is 0.0615971\n",
      "After 40 training step(s),cross entropy on all data is 0.0614568\n",
      "After 41 training step(s),cross entropy on all data is 0.0613131\n",
      "After 42 training step(s),cross entropy on all data is 0.0611695\n",
      "After 43 training step(s),cross entropy on all data is 0.0610255\n",
      "After 44 training step(s),cross entropy on all data is 0.0608774\n",
      "After 45 training step(s),cross entropy on all data is 0.0607281\n",
      "After 46 training step(s),cross entropy on all data is 0.0605924\n",
      "After 47 training step(s),cross entropy on all data is 0.0604691\n",
      "After 48 training step(s),cross entropy on all data is 0.060326\n",
      "After 49 training step(s),cross entropy on all data is 0.0601682\n",
      "After 50 training step(s),cross entropy on all data is 0.0600249\n",
      "After 51 training step(s),cross entropy on all data is 0.0598948\n",
      "After 52 training step(s),cross entropy on all data is 0.0597766\n",
      "After 53 training step(s),cross entropy on all data is 0.0596694\n",
      "After 54 training step(s),cross entropy on all data is 0.0595566\n",
      "After 55 training step(s),cross entropy on all data is 0.0594224\n",
      "After 56 training step(s),cross entropy on all data is 0.0592843\n",
      "After 57 training step(s),cross entropy on all data is 0.0591428\n",
      "After 58 training step(s),cross entropy on all data is 0.059001\n",
      "After 59 training step(s),cross entropy on all data is 0.0588588\n",
      "After 60 training step(s),cross entropy on all data is 0.0587123\n",
      "After 61 training step(s),cross entropy on all data is 0.0585645\n",
      "After 62 training step(s),cross entropy on all data is 0.0584304\n",
      "After 63 training step(s),cross entropy on all data is 0.0583089\n",
      "After 64 training step(s),cross entropy on all data is 0.0581669\n",
      "After 65 training step(s),cross entropy on all data is 0.0580096\n",
      "After 66 training step(s),cross entropy on all data is 0.057867\n",
      "After 67 training step(s),cross entropy on all data is 0.0577378\n",
      "After 68 training step(s),cross entropy on all data is 0.0576207\n",
      "After 69 training step(s),cross entropy on all data is 0.0575145\n",
      "After 70 training step(s),cross entropy on all data is 0.0574029\n",
      "After 71 training step(s),cross entropy on all data is 0.0572694\n",
      "After 72 training step(s),cross entropy on all data is 0.0571322\n",
      "After 73 training step(s),cross entropy on all data is 0.0569914\n",
      "After 74 training step(s),cross entropy on all data is 0.0568505\n",
      "After 75 training step(s),cross entropy on all data is 0.056709\n",
      "After 76 training step(s),cross entropy on all data is 0.0565632\n",
      "After 77 training step(s),cross entropy on all data is 0.0564162\n",
      "After 78 training step(s),cross entropy on all data is 0.0562831\n",
      "After 79 training step(s),cross entropy on all data is 0.0561626\n",
      "After 80 training step(s),cross entropy on all data is 0.0560214\n",
      "After 81 training step(s),cross entropy on all data is 0.0558645\n",
      "After 82 training step(s),cross entropy on all data is 0.0557225\n",
      "After 83 training step(s),cross entropy on all data is 0.055594\n",
      "After 84 training step(s),cross entropy on all data is 0.0554777\n",
      "After 85 training step(s),cross entropy on all data is 0.0553724\n",
      "After 86 training step(s),cross entropy on all data is 0.0552617\n",
      "After 87 training step(s),cross entropy on all data is 0.055129\n",
      "After 88 training step(s),cross entropy on all data is 0.0549926\n",
      "After 89 training step(s),cross entropy on all data is 0.0548574\n",
      "After 90 training step(s),cross entropy on all data is 0.054727\n",
      "After 91 training step(s),cross entropy on all data is 0.0546091\n",
      "After 92 training step(s),cross entropy on all data is 0.0544855\n",
      "After 93 training step(s),cross entropy on all data is 0.0543597\n",
      "After 94 training step(s),cross entropy on all data is 0.0542459\n",
      "After 95 training step(s),cross entropy on all data is 0.054143\n",
      "After 96 training step(s),cross entropy on all data is 0.0540194\n",
      "After 97 training step(s),cross entropy on all data is 0.0538804\n",
      "After 98 training step(s),cross entropy on all data is 0.0537547\n",
      "After 99 training step(s),cross entropy on all data is 0.053641\n",
      "After 100 training step(s),cross entropy on all data is 0.0535382\n",
      "After 101 training step(s),cross entropy on all data is 0.0534453\n",
      "After 102 training step(s),cross entropy on all data is 0.053347\n",
      "After 103 training step(s),cross entropy on all data is 0.0532273\n",
      "After 104 training step(s),cross entropy on all data is 0.0531037\n",
      "After 105 training step(s),cross entropy on all data is 0.0529766\n",
      "After 106 training step(s),cross entropy on all data is 0.0528494\n",
      "After 107 training step(s),cross entropy on all data is 0.0527344\n",
      "After 108 training step(s),cross entropy on all data is 0.0526136\n",
      "After 109 training step(s),cross entropy on all data is 0.0524904\n",
      "After 110 training step(s),cross entropy on all data is 0.052379\n",
      "After 111 training step(s),cross entropy on all data is 0.0522784\n",
      "After 112 training step(s),cross entropy on all data is 0.0521569\n",
      "After 113 training step(s),cross entropy on all data is 0.0520196\n",
      "After 114 training step(s),cross entropy on all data is 0.0518957\n",
      "After 115 training step(s),cross entropy on all data is 0.0517836\n",
      "After 116 training step(s),cross entropy on all data is 0.0516824\n",
      "After 117 training step(s),cross entropy on all data is 0.0515909\n",
      "After 118 training step(s),cross entropy on all data is 0.0514939\n",
      "After 119 training step(s),cross entropy on all data is 0.0513755\n",
      "After 120 training step(s),cross entropy on all data is 0.0512533\n",
      "After 121 training step(s),cross entropy on all data is 0.0511275\n",
      "After 122 training step(s),cross entropy on all data is 0.0510015\n",
      "After 123 training step(s),cross entropy on all data is 0.0508876\n",
      "After 124 training step(s),cross entropy on all data is 0.050768\n",
      "After 125 training step(s),cross entropy on all data is 0.0506459\n",
      "After 126 training step(s),cross entropy on all data is 0.0505357\n",
      "After 127 training step(s),cross entropy on all data is 0.0504361\n",
      "After 128 training step(s),cross entropy on all data is 0.0503156\n",
      "After 129 training step(s),cross entropy on all data is 0.0501794\n",
      "After 130 training step(s),cross entropy on all data is 0.0500563\n",
      "After 131 training step(s),cross entropy on all data is 0.0499452\n",
      "After 132 training step(s),cross entropy on all data is 0.0498448\n",
      "After 133 training step(s),cross entropy on all data is 0.0497542\n",
      "After 134 training step(s),cross entropy on all data is 0.0496581\n",
      "After 135 training step(s),cross entropy on all data is 0.0495406\n",
      "After 136 training step(s),cross entropy on all data is 0.0494194\n",
      "After 137 training step(s),cross entropy on all data is 0.0492945\n",
      "After 138 training step(s),cross entropy on all data is 0.0491694\n",
      "After 139 training step(s),cross entropy on all data is 0.0490648\n",
      "After 140 training step(s),cross entropy on all data is 0.0489559\n",
      "After 141 training step(s),cross entropy on all data is 0.0488449\n",
      "After 142 training step(s),cross entropy on all data is 0.0487446\n",
      "After 143 training step(s),cross entropy on all data is 0.048654\n",
      "After 144 training step(s),cross entropy on all data is 0.0485445\n",
      "After 145 training step(s),cross entropy on all data is 0.0484332\n",
      "After 146 training step(s),cross entropy on all data is 0.0483328\n",
      "After 147 training step(s),cross entropy on all data is 0.0482422\n",
      "After 148 training step(s),cross entropy on all data is 0.0481603\n",
      "After 149 training step(s),cross entropy on all data is 0.0480864\n",
      "After 150 training step(s),cross entropy on all data is 0.0480066\n",
      "After 151 training step(s),cross entropy on all data is 0.0479063\n",
      "After 152 training step(s),cross entropy on all data is 0.0478018\n",
      "After 153 training step(s),cross entropy on all data is 0.0476933\n",
      "After 154 training step(s),cross entropy on all data is 0.0475839\n",
      "After 155 training step(s),cross entropy on all data is 0.0474852\n",
      "After 156 training step(s),cross entropy on all data is 0.0473809\n",
      "After 157 training step(s),cross entropy on all data is 0.0472738\n",
      "After 158 training step(s),cross entropy on all data is 0.0471772\n",
      "After 159 training step(s),cross entropy on all data is 0.04709\n",
      "After 160 training step(s),cross entropy on all data is 0.0469834\n",
      "After 161 training step(s),cross entropy on all data is 0.0468749\n",
      "After 162 training step(s),cross entropy on all data is 0.0467769\n",
      "After 163 training step(s),cross entropy on all data is 0.0466884\n",
      "After 164 training step(s),cross entropy on all data is 0.0466086\n",
      "After 165 training step(s),cross entropy on all data is 0.0465366\n",
      "After 166 training step(s),cross entropy on all data is 0.0464584\n",
      "After 167 training step(s),cross entropy on all data is 0.0463597\n",
      "After 168 training step(s),cross entropy on all data is 0.0462566\n",
      "After 169 training step(s),cross entropy on all data is 0.0461494\n",
      "After 170 training step(s),cross entropy on all data is 0.0460413\n",
      "After 171 training step(s),cross entropy on all data is 0.0459436\n",
      "After 172 training step(s),cross entropy on all data is 0.0458403\n",
      "After 173 training step(s),cross entropy on all data is 0.0457342\n",
      "After 174 training step(s),cross entropy on all data is 0.0456385\n",
      "After 175 training step(s),cross entropy on all data is 0.0455521\n",
      "After 176 training step(s),cross entropy on all data is 0.0454463\n",
      "After 177 training step(s),cross entropy on all data is 0.0453384\n",
      "After 178 training step(s),cross entropy on all data is 0.0452411\n",
      "After 179 training step(s),cross entropy on all data is 0.0451533\n",
      "After 180 training step(s),cross entropy on all data is 0.0450741\n",
      "After 181 training step(s),cross entropy on all data is 0.0450026\n",
      "After 182 training step(s),cross entropy on all data is 0.0449249\n",
      "After 183 training step(s),cross entropy on all data is 0.0448267\n",
      "After 184 training step(s),cross entropy on all data is 0.0447242\n",
      "After 185 training step(s),cross entropy on all data is 0.0446176\n",
      "After 186 training step(s),cross entropy on all data is 0.0445099\n",
      "After 187 training step(s),cross entropy on all data is 0.0444127\n",
      "After 188 training step(s),cross entropy on all data is 0.0443099\n",
      "After 189 training step(s),cross entropy on all data is 0.0442043\n",
      "After 190 training step(s),cross entropy on all data is 0.044109\n",
      "After 191 training step(s),cross entropy on all data is 0.044023\n",
      "After 192 training step(s),cross entropy on all data is 0.0439177\n",
      "After 193 training step(s),cross entropy on all data is 0.0438108\n",
      "After 194 training step(s),cross entropy on all data is 0.0437223\n",
      "After 195 training step(s),cross entropy on all data is 0.0436425\n",
      "After 196 training step(s),cross entropy on all data is 0.0435705\n",
      "After 197 training step(s),cross entropy on all data is 0.0435055\n",
      "After 198 training step(s),cross entropy on all data is 0.0434469\n",
      "After 199 training step(s),cross entropy on all data is 0.0433681\n",
      "After 200 training step(s),cross entropy on all data is 0.0432842\n",
      "After 201 training step(s),cross entropy on all data is 0.0431957\n",
      "After 202 training step(s),cross entropy on all data is 0.0431054\n",
      "After 203 training step(s),cross entropy on all data is 0.043024\n",
      "After 204 training step(s),cross entropy on all data is 0.0429366\n",
      "After 205 training step(s),cross entropy on all data is 0.0428461\n",
      "After 206 training step(s),cross entropy on all data is 0.0427644\n",
      "After 207 training step(s),cross entropy on all data is 0.0426907\n",
      "After 208 training step(s),cross entropy on all data is 0.0425988\n",
      "After 209 training step(s),cross entropy on all data is 0.0425047\n",
      "After 210 training step(s),cross entropy on all data is 0.0424198\n",
      "After 211 training step(s),cross entropy on all data is 0.0423432\n",
      "After 212 training step(s),cross entropy on all data is 0.0422741\n",
      "After 213 training step(s),cross entropy on all data is 0.0422118\n",
      "After 214 training step(s),cross entropy on all data is 0.0421556\n",
      "After 215 training step(s),cross entropy on all data is 0.042079\n",
      "After 216 training step(s),cross entropy on all data is 0.0419972\n",
      "After 217 training step(s),cross entropy on all data is 0.0419106\n",
      "After 218 training step(s),cross entropy on all data is 0.041822\n",
      "After 219 training step(s),cross entropy on all data is 0.041742\n",
      "After 220 training step(s),cross entropy on all data is 0.0416567\n",
      "After 221 training step(s),cross entropy on all data is 0.0415864\n",
      "After 222 training step(s),cross entropy on all data is 0.0415229\n",
      "After 223 training step(s),cross entropy on all data is 0.0414657\n",
      "After 224 training step(s),cross entropy on all data is 0.0413908\n",
      "After 225 training step(s),cross entropy on all data is 0.0413132\n",
      "After 226 training step(s),cross entropy on all data is 0.0412433\n",
      "After 227 training step(s),cross entropy on all data is 0.0411802\n",
      "After 228 training step(s),cross entropy on all data is 0.0411233\n",
      "After 229 training step(s),cross entropy on all data is 0.041072\n",
      "After 230 training step(s),cross entropy on all data is 0.0410257\n",
      "After 231 training step(s),cross entropy on all data is 0.0409603\n",
      "After 232 training step(s),cross entropy on all data is 0.0408898\n",
      "After 233 training step(s),cross entropy on all data is 0.0408145\n",
      "After 234 training step(s),cross entropy on all data is 0.0407374\n",
      "After 235 training step(s),cross entropy on all data is 0.0406678\n",
      "After 236 training step(s),cross entropy on all data is 0.0405923\n",
      "After 237 training step(s),cross entropy on all data is 0.0405242\n",
      "After 238 training step(s),cross entropy on all data is 0.0404628\n",
      "After 239 training step(s),cross entropy on all data is 0.0404075\n",
      "After 240 training step(s),cross entropy on all data is 0.0403343\n",
      "After 241 training step(s),cross entropy on all data is 0.0402582\n",
      "After 242 training step(s),cross entropy on all data is 0.0401897\n",
      "After 243 training step(s),cross entropy on all data is 0.0401278\n",
      "After 244 training step(s),cross entropy on all data is 0.040072\n",
      "After 245 training step(s),cross entropy on all data is 0.0400217\n",
      "After 246 training step(s),cross entropy on all data is 0.0399764\n",
      "After 247 training step(s),cross entropy on all data is 0.0399119\n",
      "After 248 training step(s),cross entropy on all data is 0.0398423\n",
      "After 249 training step(s),cross entropy on all data is 0.0397678\n",
      "After 250 training step(s),cross entropy on all data is 0.0396912\n",
      "After 251 training step(s),cross entropy on all data is 0.0396222\n",
      "After 252 training step(s),cross entropy on all data is 0.0395474\n",
      "After 253 training step(s),cross entropy on all data is 0.0394799\n",
      "After 254 training step(s),cross entropy on all data is 0.039419\n",
      "After 255 training step(s),cross entropy on all data is 0.0393641\n",
      "After 256 training step(s),cross entropy on all data is 0.0392914\n",
      "After 257 training step(s),cross entropy on all data is 0.0392157\n",
      "After 258 training step(s),cross entropy on all data is 0.0391475\n",
      "After 259 training step(s),cross entropy on all data is 0.039086\n",
      "After 260 training step(s),cross entropy on all data is 0.0390306\n",
      "After 261 training step(s),cross entropy on all data is 0.0389806\n",
      "After 262 training step(s),cross entropy on all data is 0.0389355\n",
      "After 263 training step(s),cross entropy on all data is 0.0388713\n",
      "After 264 training step(s),cross entropy on all data is 0.038802\n",
      "After 265 training step(s),cross entropy on all data is 0.0387278\n",
      "After 266 training step(s),cross entropy on all data is 0.0386515\n",
      "After 267 training step(s),cross entropy on all data is 0.0385828\n",
      "After 268 training step(s),cross entropy on all data is 0.0385082\n",
      "After 269 training step(s),cross entropy on all data is 0.0384409\n",
      "After 270 training step(s),cross entropy on all data is 0.0383803\n",
      "After 271 training step(s),cross entropy on all data is 0.0383256\n",
      "After 272 training step(s),cross entropy on all data is 0.0382532\n",
      "After 273 training step(s),cross entropy on all data is 0.0381778\n",
      "After 274 training step(s),cross entropy on all data is 0.0381098\n",
      "After 275 training step(s),cross entropy on all data is 0.0380485\n",
      "After 276 training step(s),cross entropy on all data is 0.0379933\n",
      "After 277 training step(s),cross entropy on all data is 0.0379434\n",
      "After 278 training step(s),cross entropy on all data is 0.0378985\n",
      "After 279 training step(s),cross entropy on all data is 0.0378346\n",
      "After 280 training step(s),cross entropy on all data is 0.0377655\n",
      "After 281 training step(s),cross entropy on all data is 0.0376916\n",
      "After 282 training step(s),cross entropy on all data is 0.0376156\n",
      "After 283 training step(s),cross entropy on all data is 0.037547\n",
      "After 284 training step(s),cross entropy on all data is 0.0374727\n",
      "After 285 training step(s),cross entropy on all data is 0.0374057\n",
      "After 286 training step(s),cross entropy on all data is 0.0373453\n",
      "After 287 training step(s),cross entropy on all data is 0.0372908\n",
      "After 288 training step(s),cross entropy on all data is 0.0372187\n",
      "After 289 training step(s),cross entropy on all data is 0.0371435\n",
      "After 290 training step(s),cross entropy on all data is 0.0370757\n",
      "After 291 training step(s),cross entropy on all data is 0.0370146\n",
      "After 292 training step(s),cross entropy on all data is 0.0369596\n",
      "After 293 training step(s),cross entropy on all data is 0.0369099\n",
      "After 294 training step(s),cross entropy on all data is 0.0368652\n",
      "After 295 training step(s),cross entropy on all data is 0.0368015\n",
      "After 296 training step(s),cross entropy on all data is 0.0367327\n",
      "After 297 training step(s),cross entropy on all data is 0.0366591\n",
      "After 298 training step(s),cross entropy on all data is 0.0365833\n",
      "After 299 training step(s),cross entropy on all data is 0.0365149\n",
      "After 300 training step(s),cross entropy on all data is 0.0364409\n",
      "After 301 training step(s),cross entropy on all data is 0.0363741\n",
      "After 302 training step(s),cross entropy on all data is 0.036314\n",
      "After 303 training step(s),cross entropy on all data is 0.0362598\n",
      "After 304 training step(s),cross entropy on all data is 0.0361879\n",
      "After 305 training step(s),cross entropy on all data is 0.036113\n",
      "After 306 training step(s),cross entropy on all data is 0.0360455\n",
      "After 307 training step(s),cross entropy on all data is 0.0359846\n",
      "After 308 training step(s),cross entropy on all data is 0.0359298\n",
      "After 309 training step(s),cross entropy on all data is 0.0358803\n",
      "After 310 training step(s),cross entropy on all data is 0.0358358\n",
      "After 311 training step(s),cross entropy on all data is 0.0357724\n",
      "After 312 training step(s),cross entropy on all data is 0.0357038\n",
      "After 313 training step(s),cross entropy on all data is 0.0356305\n",
      "After 314 training step(s),cross entropy on all data is 0.035555\n",
      "After 315 training step(s),cross entropy on all data is 0.0354869\n",
      "After 316 training step(s),cross entropy on all data is 0.0354132\n",
      "After 317 training step(s),cross entropy on all data is 0.0353467\n",
      "After 318 training step(s),cross entropy on all data is 0.0352868\n",
      "After 319 training step(s),cross entropy on all data is 0.0352328\n",
      "After 320 training step(s),cross entropy on all data is 0.0351613\n",
      "After 321 training step(s),cross entropy on all data is 0.0350936\n",
      "After 322 training step(s),cross entropy on all data is 0.0350346\n",
      "After 323 training step(s),cross entropy on all data is 0.0349814\n",
      "After 324 training step(s),cross entropy on all data is 0.0349335\n",
      "After 325 training step(s),cross entropy on all data is 0.0348903\n",
      "After 326 training step(s),cross entropy on all data is 0.0348514\n",
      "After 327 training step(s),cross entropy on all data is 0.0347963\n",
      "After 328 training step(s),cross entropy on all data is 0.0347368\n",
      "After 329 training step(s),cross entropy on all data is 0.0346732\n",
      "After 330 training step(s),cross entropy on all data is 0.034607\n",
      "After 331 training step(s),cross entropy on all data is 0.0345473\n",
      "After 332 training step(s),cross entropy on all data is 0.0344831\n",
      "After 333 training step(s),cross entropy on all data is 0.0344253\n",
      "After 334 training step(s),cross entropy on all data is 0.0343732\n",
      "After 335 training step(s),cross entropy on all data is 0.0343263\n",
      "After 336 training step(s),cross entropy on all data is 0.0342745\n",
      "After 337 training step(s),cross entropy on all data is 0.0342186\n",
      "After 338 training step(s),cross entropy on all data is 0.0341682\n",
      "After 339 training step(s),cross entropy on all data is 0.0341227\n",
      "After 340 training step(s),cross entropy on all data is 0.0340818\n",
      "After 341 training step(s),cross entropy on all data is 0.0340449\n",
      "After 342 training step(s),cross entropy on all data is 0.0340116\n",
      "After 343 training step(s),cross entropy on all data is 0.0339616\n",
      "After 344 training step(s),cross entropy on all data is 0.0339066\n",
      "After 345 training step(s),cross entropy on all data is 0.0338471\n",
      "After 346 training step(s),cross entropy on all data is 0.0337845\n",
      "After 347 training step(s),cross entropy on all data is 0.0337281\n",
      "After 348 training step(s),cross entropy on all data is 0.0336669\n",
      "After 349 training step(s),cross entropy on all data is 0.0336117\n",
      "After 350 training step(s),cross entropy on all data is 0.033562\n",
      "After 351 training step(s),cross entropy on all data is 0.0335172\n",
      "After 352 training step(s),cross entropy on all data is 0.0334674\n",
      "After 353 training step(s),cross entropy on all data is 0.0334132\n",
      "After 354 training step(s),cross entropy on all data is 0.0333644\n",
      "After 355 training step(s),cross entropy on all data is 0.0333203\n",
      "After 356 training step(s),cross entropy on all data is 0.0332807\n",
      "After 357 training step(s),cross entropy on all data is 0.0332449\n",
      "After 358 training step(s),cross entropy on all data is 0.0332127\n",
      "After 359 training step(s),cross entropy on all data is 0.0331636\n",
      "After 360 training step(s),cross entropy on all data is 0.0331094\n",
      "After 361 training step(s),cross entropy on all data is 0.0330506\n",
      "After 362 training step(s),cross entropy on all data is 0.0329886\n",
      "After 363 training step(s),cross entropy on all data is 0.0329328\n",
      "After 364 training step(s),cross entropy on all data is 0.0328721\n",
      "After 365 training step(s),cross entropy on all data is 0.0328174\n",
      "After 366 training step(s),cross entropy on all data is 0.0327682\n",
      "After 367 training step(s),cross entropy on all data is 0.0327237\n",
      "After 368 training step(s),cross entropy on all data is 0.0326743\n",
      "After 369 training step(s),cross entropy on all data is 0.0326203\n",
      "After 370 training step(s),cross entropy on all data is 0.0325718\n",
      "After 371 training step(s),cross entropy on all data is 0.032528\n",
      "After 372 training step(s),cross entropy on all data is 0.0324885\n",
      "After 373 training step(s),cross entropy on all data is 0.032453\n",
      "After 374 training step(s),cross entropy on all data is 0.0324209\n",
      "After 375 training step(s),cross entropy on all data is 0.032372\n",
      "After 376 training step(s),cross entropy on all data is 0.0323179\n",
      "After 377 training step(s),cross entropy on all data is 0.0322592\n",
      "After 378 training step(s),cross entropy on all data is 0.0321974\n",
      "After 379 training step(s),cross entropy on all data is 0.0321417\n",
      "After 380 training step(s),cross entropy on all data is 0.0320811\n",
      "After 381 training step(s),cross entropy on all data is 0.0320265\n",
      "After 382 training step(s),cross entropy on all data is 0.0319773\n",
      "After 383 training step(s),cross entropy on all data is 0.0319329\n",
      "After 384 training step(s),cross entropy on all data is 0.0318835\n",
      "After 385 training step(s),cross entropy on all data is 0.0318297\n",
      "After 386 training step(s),cross entropy on all data is 0.0317811\n",
      "After 387 training step(s),cross entropy on all data is 0.0317374\n",
      "After 388 training step(s),cross entropy on all data is 0.031698\n",
      "After 389 training step(s),cross entropy on all data is 0.0316624\n",
      "After 390 training step(s),cross entropy on all data is 0.0316304\n",
      "After 391 training step(s),cross entropy on all data is 0.0315815\n",
      "After 392 training step(s),cross entropy on all data is 0.0315275\n",
      "After 393 training step(s),cross entropy on all data is 0.0314689\n",
      "After 394 training step(s),cross entropy on all data is 0.0314071\n",
      "After 395 training step(s),cross entropy on all data is 0.0313514\n",
      "After 396 training step(s),cross entropy on all data is 0.0312908\n",
      "After 397 training step(s),cross entropy on all data is 0.0312362\n",
      "After 398 training step(s),cross entropy on all data is 0.0311871\n",
      "After 399 training step(s),cross entropy on all data is 0.0311428\n",
      "After 400 training step(s),cross entropy on all data is 0.0310934\n",
      "After 401 training step(s),cross entropy on all data is 0.0310395\n",
      "After 402 training step(s),cross entropy on all data is 0.030991\n",
      "After 403 training step(s),cross entropy on all data is 0.0309473\n",
      "After 404 training step(s),cross entropy on all data is 0.0309079\n",
      "After 405 training step(s),cross entropy on all data is 0.0308724\n",
      "After 406 training step(s),cross entropy on all data is 0.0308404\n",
      "After 407 training step(s),cross entropy on all data is 0.0307915\n",
      "After 408 training step(s),cross entropy on all data is 0.0307376\n",
      "After 409 training step(s),cross entropy on all data is 0.030679\n",
      "After 410 training step(s),cross entropy on all data is 0.0306172\n",
      "After 411 training step(s),cross entropy on all data is 0.0305615\n",
      "After 412 training step(s),cross entropy on all data is 0.030501\n",
      "After 413 training step(s),cross entropy on all data is 0.0304494\n",
      "After 414 training step(s),cross entropy on all data is 0.0304069\n",
      "After 415 training step(s),cross entropy on all data is 0.0303687\n",
      "After 416 training step(s),cross entropy on all data is 0.0303258\n",
      "After 417 training step(s),cross entropy on all data is 0.0302788\n",
      "After 418 training step(s),cross entropy on all data is 0.0302365\n",
      "After 419 training step(s),cross entropy on all data is 0.0301984\n",
      "After 420 training step(s),cross entropy on all data is 0.030164\n",
      "After 421 training step(s),cross entropy on all data is 0.030133\n",
      "After 422 training step(s),cross entropy on all data is 0.0301051\n",
      "After 423 training step(s),cross entropy on all data is 0.0300714\n",
      "After 424 training step(s),cross entropy on all data is 0.0300325\n",
      "After 425 training step(s),cross entropy on all data is 0.0299888\n",
      "After 426 training step(s),cross entropy on all data is 0.0299412\n",
      "After 427 training step(s),cross entropy on all data is 0.0298983\n",
      "After 428 training step(s),cross entropy on all data is 0.029851\n",
      "After 429 training step(s),cross entropy on all data is 0.0298084\n",
      "After 430 training step(s),cross entropy on all data is 0.02977\n",
      "After 431 training step(s),cross entropy on all data is 0.0297354\n",
      "After 432 training step(s),cross entropy on all data is 0.0296958\n",
      "After 433 training step(s),cross entropy on all data is 0.0296517\n",
      "After 434 training step(s),cross entropy on all data is 0.029612\n",
      "After 435 training step(s),cross entropy on all data is 0.0295762\n",
      "After 436 training step(s),cross entropy on all data is 0.0295439\n",
      "After 437 training step(s),cross entropy on all data is 0.0295148\n",
      "After 438 training step(s),cross entropy on all data is 0.0294887\n",
      "After 439 training step(s),cross entropy on all data is 0.0294565\n",
      "After 440 training step(s),cross entropy on all data is 0.0294189\n",
      "After 441 training step(s),cross entropy on all data is 0.0293764\n",
      "After 442 training step(s),cross entropy on all data is 0.0293299\n",
      "After 443 training step(s),cross entropy on all data is 0.0292879\n",
      "After 444 training step(s),cross entropy on all data is 0.0292414\n",
      "After 445 training step(s),cross entropy on all data is 0.0291995\n",
      "After 446 training step(s),cross entropy on all data is 0.0291617\n",
      "After 447 training step(s),cross entropy on all data is 0.0291277\n",
      "After 448 training step(s),cross entropy on all data is 0.0290886\n",
      "After 449 training step(s),cross entropy on all data is 0.0290449\n",
      "After 450 training step(s),cross entropy on all data is 0.0290056\n",
      "After 451 training step(s),cross entropy on all data is 0.0289701\n",
      "After 452 training step(s),cross entropy on all data is 0.0289382\n",
      "After 453 training step(s),cross entropy on all data is 0.0289094\n",
      "After 454 training step(s),cross entropy on all data is 0.0288835\n",
      "After 455 training step(s),cross entropy on all data is 0.0288515\n",
      "After 456 training step(s),cross entropy on all data is 0.0288141\n",
      "After 457 training step(s),cross entropy on all data is 0.0287718\n",
      "After 458 training step(s),cross entropy on all data is 0.0287253\n",
      "After 459 training step(s),cross entropy on all data is 0.0286834\n",
      "After 460 training step(s),cross entropy on all data is 0.0286369\n",
      "After 461 training step(s),cross entropy on all data is 0.0285951\n",
      "After 462 training step(s),cross entropy on all data is 0.0285573\n",
      "After 463 training step(s),cross entropy on all data is 0.0285233\n",
      "After 464 training step(s),cross entropy on all data is 0.0284842\n",
      "After 465 training step(s),cross entropy on all data is 0.0284406\n",
      "After 466 training step(s),cross entropy on all data is 0.0284012\n",
      "After 467 training step(s),cross entropy on all data is 0.0283658\n",
      "After 468 training step(s),cross entropy on all data is 0.0283338\n",
      "After 469 training step(s),cross entropy on all data is 0.028305\n",
      "After 470 training step(s),cross entropy on all data is 0.0282791\n",
      "After 471 training step(s),cross entropy on all data is 0.0282471\n",
      "After 472 training step(s),cross entropy on all data is 0.0282096\n",
      "After 473 training step(s),cross entropy on all data is 0.0281672\n",
      "After 474 training step(s),cross entropy on all data is 0.0281206\n",
      "After 475 training step(s),cross entropy on all data is 0.0280787\n",
      "After 476 training step(s),cross entropy on all data is 0.0280321\n",
      "After 477 training step(s),cross entropy on all data is 0.0279902\n",
      "After 478 training step(s),cross entropy on all data is 0.0279524\n",
      "After 479 training step(s),cross entropy on all data is 0.0279183\n",
      "After 480 training step(s),cross entropy on all data is 0.0278792\n",
      "After 481 training step(s),cross entropy on all data is 0.0278354\n",
      "After 482 training step(s),cross entropy on all data is 0.027796\n",
      "After 483 training step(s),cross entropy on all data is 0.0277604\n",
      "After 484 training step(s),cross entropy on all data is 0.0277284\n",
      "After 485 training step(s),cross entropy on all data is 0.0276996\n",
      "After 486 training step(s),cross entropy on all data is 0.0276736\n",
      "After 487 training step(s),cross entropy on all data is 0.0276416\n",
      "After 488 training step(s),cross entropy on all data is 0.027604\n",
      "After 489 training step(s),cross entropy on all data is 0.0275615\n",
      "After 490 training step(s),cross entropy on all data is 0.0275149\n",
      "After 491 training step(s),cross entropy on all data is 0.0274728\n",
      "After 492 training step(s),cross entropy on all data is 0.0274262\n",
      "After 493 training step(s),cross entropy on all data is 0.0273841\n",
      "After 494 training step(s),cross entropy on all data is 0.0273463\n",
      "After 495 training step(s),cross entropy on all data is 0.0273122\n",
      "After 496 training step(s),cross entropy on all data is 0.0272729\n",
      "After 497 training step(s),cross entropy on all data is 0.027229\n",
      "After 498 training step(s),cross entropy on all data is 0.0271895\n",
      "After 499 training step(s),cross entropy on all data is 0.027154\n",
      "After 500 training step(s),cross entropy on all data is 0.0271219\n",
      "After 501 training step(s),cross entropy on all data is 0.027093\n",
      "After 502 training step(s),cross entropy on all data is 0.027067\n",
      "After 503 training step(s),cross entropy on all data is 0.0270349\n",
      "After 504 training step(s),cross entropy on all data is 0.0269973\n",
      "After 505 training step(s),cross entropy on all data is 0.0269547\n",
      "After 506 training step(s),cross entropy on all data is 0.0269079\n",
      "After 507 training step(s),cross entropy on all data is 0.0268707\n",
      "After 508 training step(s),cross entropy on all data is 0.0268304\n",
      "After 509 training step(s),cross entropy on all data is 0.0267942\n",
      "After 510 training step(s),cross entropy on all data is 0.0267615\n",
      "After 511 training step(s),cross entropy on all data is 0.0267321\n",
      "After 512 training step(s),cross entropy on all data is 0.0267056\n",
      "After 513 training step(s),cross entropy on all data is 0.0266745\n",
      "After 514 training step(s),cross entropy on all data is 0.0266465\n",
      "After 515 training step(s),cross entropy on all data is 0.0266212\n",
      "After 516 training step(s),cross entropy on all data is 0.0265985\n",
      "After 517 training step(s),cross entropy on all data is 0.026578\n",
      "After 518 training step(s),cross entropy on all data is 0.0265596\n",
      "After 519 training step(s),cross entropy on all data is 0.0265355\n",
      "After 520 training step(s),cross entropy on all data is 0.0265062\n",
      "After 521 training step(s),cross entropy on all data is 0.0264722\n",
      "After 522 training step(s),cross entropy on all data is 0.0264346\n",
      "After 523 training step(s),cross entropy on all data is 0.0264007\n",
      "After 524 training step(s),cross entropy on all data is 0.0263624\n",
      "After 525 training step(s),cross entropy on all data is 0.0263279\n",
      "After 526 training step(s),cross entropy on all data is 0.0262968\n",
      "After 527 training step(s),cross entropy on all data is 0.0262688\n",
      "After 528 training step(s),cross entropy on all data is 0.0262436\n",
      "After 529 training step(s),cross entropy on all data is 0.0262136\n",
      "After 530 training step(s),cross entropy on all data is 0.0261866\n",
      "After 531 training step(s),cross entropy on all data is 0.0261623\n",
      "After 532 training step(s),cross entropy on all data is 0.0261403\n",
      "After 533 training step(s),cross entropy on all data is 0.0261206\n",
      "After 534 training step(s),cross entropy on all data is 0.0261028\n",
      "After 535 training step(s),cross entropy on all data is 0.0260793\n",
      "After 536 training step(s),cross entropy on all data is 0.0260505\n",
      "After 537 training step(s),cross entropy on all data is 0.0260169\n",
      "After 538 training step(s),cross entropy on all data is 0.0259797\n",
      "After 539 training step(s),cross entropy on all data is 0.0259461\n",
      "After 540 training step(s),cross entropy on all data is 0.0259081\n",
      "After 541 training step(s),cross entropy on all data is 0.0258738\n",
      "After 542 training step(s),cross entropy on all data is 0.0258429\n",
      "After 543 training step(s),cross entropy on all data is 0.0258151\n",
      "After 544 training step(s),cross entropy on all data is 0.02579\n",
      "After 545 training step(s),cross entropy on all data is 0.0257602\n",
      "After 546 training step(s),cross entropy on all data is 0.0257333\n",
      "After 547 training step(s),cross entropy on all data is 0.0257091\n",
      "After 548 training step(s),cross entropy on all data is 0.0256872\n",
      "After 549 training step(s),cross entropy on all data is 0.0256676\n",
      "After 550 training step(s),cross entropy on all data is 0.0256499\n",
      "After 551 training step(s),cross entropy on all data is 0.0256264\n",
      "After 552 training step(s),cross entropy on all data is 0.0255976\n",
      "After 553 training step(s),cross entropy on all data is 0.0255641\n",
      "After 554 training step(s),cross entropy on all data is 0.0255268\n",
      "After 555 training step(s),cross entropy on all data is 0.0254932\n",
      "After 556 training step(s),cross entropy on all data is 0.0254551\n",
      "After 557 training step(s),cross entropy on all data is 0.0254208\n",
      "After 558 training step(s),cross entropy on all data is 0.0253898\n",
      "After 559 training step(s),cross entropy on all data is 0.025362\n",
      "After 560 training step(s),cross entropy on all data is 0.0253369\n",
      "After 561 training step(s),cross entropy on all data is 0.025307\n",
      "After 562 training step(s),cross entropy on all data is 0.0252801\n",
      "After 563 training step(s),cross entropy on all data is 0.0252558\n",
      "After 564 training step(s),cross entropy on all data is 0.025234\n",
      "After 565 training step(s),cross entropy on all data is 0.0252143\n",
      "After 566 training step(s),cross entropy on all data is 0.0251966\n",
      "After 567 training step(s),cross entropy on all data is 0.025173\n",
      "After 568 training step(s),cross entropy on all data is 0.0251442\n",
      "After 569 training step(s),cross entropy on all data is 0.0251106\n",
      "After 570 training step(s),cross entropy on all data is 0.0250774\n",
      "After 571 training step(s),cross entropy on all data is 0.0250494\n",
      "After 572 training step(s),cross entropy on all data is 0.0250241\n",
      "After 573 training step(s),cross entropy on all data is 0.0250013\n",
      "After 574 training step(s),cross entropy on all data is 0.0249808\n",
      "After 575 training step(s),cross entropy on all data is 0.0249624\n",
      "After 576 training step(s),cross entropy on all data is 0.0249457\n",
      "After 577 training step(s),cross entropy on all data is 0.0249244\n",
      "After 578 training step(s),cross entropy on all data is 0.0249052\n",
      "After 579 training step(s),cross entropy on all data is 0.0248879\n",
      "After 580 training step(s),cross entropy on all data is 0.0248723\n",
      "After 581 training step(s),cross entropy on all data is 0.0248582\n",
      "After 582 training step(s),cross entropy on all data is 0.0248456\n",
      "After 583 training step(s),cross entropy on all data is 0.0248279\n",
      "After 584 training step(s),cross entropy on all data is 0.0248058\n",
      "After 585 training step(s),cross entropy on all data is 0.0247797\n",
      "After 586 training step(s),cross entropy on all data is 0.0247499\n",
      "After 587 training step(s),cross entropy on all data is 0.0247229\n",
      "After 588 training step(s),cross entropy on all data is 0.0246987\n",
      "After 589 training step(s),cross entropy on all data is 0.0246768\n",
      "After 590 training step(s),cross entropy on all data is 0.0246572\n",
      "After 591 training step(s),cross entropy on all data is 0.0246394\n",
      "After 592 training step(s),cross entropy on all data is 0.0246235\n",
      "After 593 training step(s),cross entropy on all data is 0.0246027\n",
      "After 594 training step(s),cross entropy on all data is 0.024584\n",
      "After 595 training step(s),cross entropy on all data is 0.0245672\n",
      "After 596 training step(s),cross entropy on all data is 0.024552\n",
      "After 597 training step(s),cross entropy on all data is 0.0245384\n",
      "After 598 training step(s),cross entropy on all data is 0.024526\n",
      "After 599 training step(s),cross entropy on all data is 0.0245087\n",
      "After 600 training step(s),cross entropy on all data is 0.0244868\n",
      "After 601 training step(s),cross entropy on all data is 0.0244609\n",
      "After 602 training step(s),cross entropy on all data is 0.0244311\n",
      "After 603 training step(s),cross entropy on all data is 0.0244043\n",
      "After 604 training step(s),cross entropy on all data is 0.0243802\n",
      "After 605 training step(s),cross entropy on all data is 0.0243584\n",
      "After 606 training step(s),cross entropy on all data is 0.0243388\n",
      "After 607 training step(s),cross entropy on all data is 0.0243212\n",
      "After 608 training step(s),cross entropy on all data is 0.0243053\n",
      "After 609 training step(s),cross entropy on all data is 0.0242846\n",
      "After 610 training step(s),cross entropy on all data is 0.0242659\n",
      "After 611 training step(s),cross entropy on all data is 0.0242491\n",
      "After 612 training step(s),cross entropy on all data is 0.024234\n",
      "After 613 training step(s),cross entropy on all data is 0.0242204\n",
      "After 614 training step(s),cross entropy on all data is 0.0242081\n",
      "After 615 training step(s),cross entropy on all data is 0.0241907\n",
      "After 616 training step(s),cross entropy on all data is 0.0241688\n",
      "After 617 training step(s),cross entropy on all data is 0.0241428\n",
      "After 618 training step(s),cross entropy on all data is 0.024113\n",
      "After 619 training step(s),cross entropy on all data is 0.0240861\n",
      "After 620 training step(s),cross entropy on all data is 0.0240619\n",
      "After 621 training step(s),cross entropy on all data is 0.0240401\n",
      "After 622 training step(s),cross entropy on all data is 0.0240205\n",
      "After 623 training step(s),cross entropy on all data is 0.0240028\n",
      "After 624 training step(s),cross entropy on all data is 0.0239869\n",
      "After 625 training step(s),cross entropy on all data is 0.0239661\n",
      "After 626 training step(s),cross entropy on all data is 0.0239474\n",
      "After 627 training step(s),cross entropy on all data is 0.0239306\n",
      "After 628 training step(s),cross entropy on all data is 0.0239154\n",
      "After 629 training step(s),cross entropy on all data is 0.0239017\n",
      "After 630 training step(s),cross entropy on all data is 0.0238894\n",
      "After 631 training step(s),cross entropy on all data is 0.023872\n",
      "After 632 training step(s),cross entropy on all data is 0.02385\n",
      "After 633 training step(s),cross entropy on all data is 0.0238239\n",
      "After 634 training step(s),cross entropy on all data is 0.023794\n",
      "After 635 training step(s),cross entropy on all data is 0.023767\n",
      "After 636 training step(s),cross entropy on all data is 0.0237427\n",
      "After 637 training step(s),cross entropy on all data is 0.0237209\n",
      "After 638 training step(s),cross entropy on all data is 0.0237012\n",
      "After 639 training step(s),cross entropy on all data is 0.0236834\n",
      "After 640 training step(s),cross entropy on all data is 0.0236674\n",
      "After 641 training step(s),cross entropy on all data is 0.0236466\n",
      "After 642 training step(s),cross entropy on all data is 0.0236278\n",
      "After 643 training step(s),cross entropy on all data is 0.0236109\n",
      "After 644 training step(s),cross entropy on all data is 0.0235957\n",
      "After 645 training step(s),cross entropy on all data is 0.023582\n",
      "After 646 training step(s),cross entropy on all data is 0.0235696\n",
      "After 647 training step(s),cross entropy on all data is 0.0235522\n",
      "After 648 training step(s),cross entropy on all data is 0.0235301\n",
      "After 649 training step(s),cross entropy on all data is 0.0235039\n",
      "After 650 training step(s),cross entropy on all data is 0.0234739\n",
      "After 651 training step(s),cross entropy on all data is 0.0234468\n",
      "After 652 training step(s),cross entropy on all data is 0.0234225\n",
      "After 653 training step(s),cross entropy on all data is 0.0234005\n",
      "After 654 training step(s),cross entropy on all data is 0.0233807\n",
      "After 655 training step(s),cross entropy on all data is 0.0233629\n",
      "After 656 training step(s),cross entropy on all data is 0.0233469\n",
      "After 657 training step(s),cross entropy on all data is 0.023326\n",
      "After 658 training step(s),cross entropy on all data is 0.0233072\n",
      "After 659 training step(s),cross entropy on all data is 0.0232902\n",
      "After 660 training step(s),cross entropy on all data is 0.0232749\n",
      "After 661 training step(s),cross entropy on all data is 0.0232612\n",
      "After 662 training step(s),cross entropy on all data is 0.0232488\n",
      "After 663 training step(s),cross entropy on all data is 0.0232313\n",
      "After 664 training step(s),cross entropy on all data is 0.0232091\n",
      "After 665 training step(s),cross entropy on all data is 0.0231829\n",
      "After 666 training step(s),cross entropy on all data is 0.0231527\n",
      "After 667 training step(s),cross entropy on all data is 0.0231256\n",
      "After 668 training step(s),cross entropy on all data is 0.0231011\n",
      "After 669 training step(s),cross entropy on all data is 0.0230791\n",
      "After 670 training step(s),cross entropy on all data is 0.0230593\n",
      "After 671 training step(s),cross entropy on all data is 0.0230414\n",
      "After 672 training step(s),cross entropy on all data is 0.0230253\n",
      "After 673 training step(s),cross entropy on all data is 0.0230044\n",
      "After 674 training step(s),cross entropy on all data is 0.0229855\n",
      "After 675 training step(s),cross entropy on all data is 0.0229685\n",
      "After 676 training step(s),cross entropy on all data is 0.0229532\n",
      "After 677 training step(s),cross entropy on all data is 0.0229394\n",
      "After 678 training step(s),cross entropy on all data is 0.0229269\n",
      "After 679 training step(s),cross entropy on all data is 0.0229093\n",
      "After 680 training step(s),cross entropy on all data is 0.0228871\n",
      "After 681 training step(s),cross entropy on all data is 0.0228608\n",
      "After 682 training step(s),cross entropy on all data is 0.0228306\n",
      "After 683 training step(s),cross entropy on all data is 0.0228033\n",
      "After 684 training step(s),cross entropy on all data is 0.0227788\n",
      "After 685 training step(s),cross entropy on all data is 0.0227567\n",
      "After 686 training step(s),cross entropy on all data is 0.0227368\n",
      "After 687 training step(s),cross entropy on all data is 0.0227189\n",
      "After 688 training step(s),cross entropy on all data is 0.0227028\n",
      "After 689 training step(s),cross entropy on all data is 0.0226818\n",
      "After 690 training step(s),cross entropy on all data is 0.0226628\n",
      "After 691 training step(s),cross entropy on all data is 0.0226458\n",
      "After 692 training step(s),cross entropy on all data is 0.0226304\n",
      "After 693 training step(s),cross entropy on all data is 0.0226166\n",
      "After 694 training step(s),cross entropy on all data is 0.0226041\n",
      "After 695 training step(s),cross entropy on all data is 0.0225865\n",
      "After 696 training step(s),cross entropy on all data is 0.0225642\n",
      "After 697 training step(s),cross entropy on all data is 0.0225378\n",
      "After 698 training step(s),cross entropy on all data is 0.0225075\n",
      "After 699 training step(s),cross entropy on all data is 0.0224802\n",
      "After 700 training step(s),cross entropy on all data is 0.0224556\n",
      "After 701 training step(s),cross entropy on all data is 0.0224335\n",
      "After 702 training step(s),cross entropy on all data is 0.0224135\n",
      "After 703 training step(s),cross entropy on all data is 0.0223956\n",
      "After 704 training step(s),cross entropy on all data is 0.0223794\n",
      "After 705 training step(s),cross entropy on all data is 0.0223583\n",
      "After 706 training step(s),cross entropy on all data is 0.0223393\n",
      "After 707 training step(s),cross entropy on all data is 0.0223223\n",
      "After 708 training step(s),cross entropy on all data is 0.0223069\n",
      "After 709 training step(s),cross entropy on all data is 0.022293\n",
      "After 710 training step(s),cross entropy on all data is 0.0222805\n",
      "After 711 training step(s),cross entropy on all data is 0.0222628\n",
      "After 712 training step(s),cross entropy on all data is 0.0222405\n",
      "After 713 training step(s),cross entropy on all data is 0.022214\n",
      "After 714 training step(s),cross entropy on all data is 0.0221836\n",
      "After 715 training step(s),cross entropy on all data is 0.0221562\n",
      "After 716 training step(s),cross entropy on all data is 0.0221316\n",
      "After 717 training step(s),cross entropy on all data is 0.0221094\n",
      "After 718 training step(s),cross entropy on all data is 0.0220894\n",
      "After 719 training step(s),cross entropy on all data is 0.0220714\n",
      "After 720 training step(s),cross entropy on all data is 0.0220552\n",
      "After 721 training step(s),cross entropy on all data is 0.022034\n",
      "After 722 training step(s),cross entropy on all data is 0.022015\n",
      "After 723 training step(s),cross entropy on all data is 0.0219979\n",
      "After 724 training step(s),cross entropy on all data is 0.0219825\n",
      "After 725 training step(s),cross entropy on all data is 0.0219686\n",
      "After 726 training step(s),cross entropy on all data is 0.0219561\n",
      "After 727 training step(s),cross entropy on all data is 0.0219383\n",
      "After 728 training step(s),cross entropy on all data is 0.0219159\n",
      "After 729 training step(s),cross entropy on all data is 0.0218894\n",
      "After 730 training step(s),cross entropy on all data is 0.0218589\n",
      "After 731 training step(s),cross entropy on all data is 0.0218315\n",
      "After 732 training step(s),cross entropy on all data is 0.0218068\n",
      "After 733 training step(s),cross entropy on all data is 0.0217845\n",
      "After 734 training step(s),cross entropy on all data is 0.0217645\n",
      "After 735 training step(s),cross entropy on all data is 0.0217465\n",
      "After 736 training step(s),cross entropy on all data is 0.0217302\n",
      "After 737 training step(s),cross entropy on all data is 0.0217091\n",
      "After 738 training step(s),cross entropy on all data is 0.02169\n",
      "After 739 training step(s),cross entropy on all data is 0.0216728\n",
      "After 740 training step(s),cross entropy on all data is 0.0216574\n",
      "After 741 training step(s),cross entropy on all data is 0.0216435\n",
      "After 742 training step(s),cross entropy on all data is 0.0216309\n",
      "After 743 training step(s),cross entropy on all data is 0.0216131\n",
      "After 744 training step(s),cross entropy on all data is 0.0215907\n",
      "After 745 training step(s),cross entropy on all data is 0.0215641\n",
      "After 746 training step(s),cross entropy on all data is 0.0215336\n",
      "After 747 training step(s),cross entropy on all data is 0.0215061\n",
      "After 748 training step(s),cross entropy on all data is 0.0214813\n",
      "After 749 training step(s),cross entropy on all data is 0.021459\n",
      "After 750 training step(s),cross entropy on all data is 0.021439\n",
      "After 751 training step(s),cross entropy on all data is 0.0214209\n",
      "After 752 training step(s),cross entropy on all data is 0.0214046\n",
      "After 753 training step(s),cross entropy on all data is 0.0213834\n",
      "After 754 training step(s),cross entropy on all data is 0.0213643\n",
      "After 755 training step(s),cross entropy on all data is 0.0213471\n",
      "After 756 training step(s),cross entropy on all data is 0.0213316\n",
      "After 757 training step(s),cross entropy on all data is 0.0213177\n",
      "After 758 training step(s),cross entropy on all data is 0.0213051\n",
      "After 759 training step(s),cross entropy on all data is 0.0212873\n",
      "After 760 training step(s),cross entropy on all data is 0.0212648\n",
      "After 761 training step(s),cross entropy on all data is 0.0212381\n",
      "After 762 training step(s),cross entropy on all data is 0.0212076\n",
      "After 763 training step(s),cross entropy on all data is 0.02118\n",
      "After 764 training step(s),cross entropy on all data is 0.0211552\n",
      "After 765 training step(s),cross entropy on all data is 0.0211329\n",
      "After 766 training step(s),cross entropy on all data is 0.0211128\n",
      "After 767 training step(s),cross entropy on all data is 0.0210947\n",
      "After 768 training step(s),cross entropy on all data is 0.0210784\n",
      "After 769 training step(s),cross entropy on all data is 0.0210571\n",
      "After 770 training step(s),cross entropy on all data is 0.021038\n",
      "After 771 training step(s),cross entropy on all data is 0.0210208\n",
      "After 772 training step(s),cross entropy on all data is 0.0210053\n",
      "After 773 training step(s),cross entropy on all data is 0.0209913\n",
      "After 774 training step(s),cross entropy on all data is 0.0209787\n",
      "After 775 training step(s),cross entropy on all data is 0.0209609\n",
      "After 776 training step(s),cross entropy on all data is 0.0209384\n",
      "After 777 training step(s),cross entropy on all data is 0.0209117\n",
      "After 778 training step(s),cross entropy on all data is 0.020881\n",
      "After 779 training step(s),cross entropy on all data is 0.0208535\n",
      "After 780 training step(s),cross entropy on all data is 0.0208286\n",
      "After 781 training step(s),cross entropy on all data is 0.0208062\n",
      "After 782 training step(s),cross entropy on all data is 0.0207861\n",
      "After 783 training step(s),cross entropy on all data is 0.020768\n",
      "After 784 training step(s),cross entropy on all data is 0.0207516\n",
      "After 785 training step(s),cross entropy on all data is 0.0207304\n",
      "After 786 training step(s),cross entropy on all data is 0.0207112\n",
      "After 787 training step(s),cross entropy on all data is 0.020694\n",
      "After 788 training step(s),cross entropy on all data is 0.0206784\n",
      "After 789 training step(s),cross entropy on all data is 0.0206644\n",
      "After 790 training step(s),cross entropy on all data is 0.0206518\n",
      "After 791 training step(s),cross entropy on all data is 0.020634\n",
      "After 792 training step(s),cross entropy on all data is 0.0206114\n",
      "After 793 training step(s),cross entropy on all data is 0.0205846\n",
      "After 794 training step(s),cross entropy on all data is 0.020554\n",
      "After 795 training step(s),cross entropy on all data is 0.0205264\n",
      "After 796 training step(s),cross entropy on all data is 0.0205015\n",
      "After 797 training step(s),cross entropy on all data is 0.0204791\n",
      "After 798 training step(s),cross entropy on all data is 0.0204589\n",
      "After 799 training step(s),cross entropy on all data is 0.0204407\n",
      "After 800 training step(s),cross entropy on all data is 0.0204244\n",
      "After 801 training step(s),cross entropy on all data is 0.0204031\n",
      "After 802 training step(s),cross entropy on all data is 0.0203839\n",
      "After 803 training step(s),cross entropy on all data is 0.0203667\n",
      "After 804 training step(s),cross entropy on all data is 0.0203511\n",
      "After 805 training step(s),cross entropy on all data is 0.0203371\n",
      "After 806 training step(s),cross entropy on all data is 0.0203245\n",
      "After 807 training step(s),cross entropy on all data is 0.0203066\n",
      "After 808 training step(s),cross entropy on all data is 0.020284\n",
      "After 809 training step(s),cross entropy on all data is 0.0202572\n",
      "After 810 training step(s),cross entropy on all data is 0.0202265\n",
      "After 811 training step(s),cross entropy on all data is 0.0201988\n",
      "After 812 training step(s),cross entropy on all data is 0.0201739\n",
      "After 813 training step(s),cross entropy on all data is 0.0201515\n",
      "After 814 training step(s),cross entropy on all data is 0.0201313\n",
      "After 815 training step(s),cross entropy on all data is 0.0201131\n",
      "After 816 training step(s),cross entropy on all data is 0.0200967\n",
      "After 817 training step(s),cross entropy on all data is 0.0200754\n",
      "After 818 training step(s),cross entropy on all data is 0.0200562\n",
      "After 819 training step(s),cross entropy on all data is 0.020039\n",
      "After 820 training step(s),cross entropy on all data is 0.0200234\n",
      "After 821 training step(s),cross entropy on all data is 0.0200094\n",
      "After 822 training step(s),cross entropy on all data is 0.0199967\n",
      "After 823 training step(s),cross entropy on all data is 0.0199788\n",
      "After 824 training step(s),cross entropy on all data is 0.0199562\n",
      "After 825 training step(s),cross entropy on all data is 0.0199294\n",
      "After 826 training step(s),cross entropy on all data is 0.0198986\n",
      "After 827 training step(s),cross entropy on all data is 0.0198709\n",
      "After 828 training step(s),cross entropy on all data is 0.019846\n",
      "After 829 training step(s),cross entropy on all data is 0.0198236\n",
      "After 830 training step(s),cross entropy on all data is 0.0198033\n",
      "After 831 training step(s),cross entropy on all data is 0.0197851\n",
      "After 832 training step(s),cross entropy on all data is 0.0197687\n",
      "After 833 training step(s),cross entropy on all data is 0.0197474\n",
      "After 834 training step(s),cross entropy on all data is 0.0197282\n",
      "After 835 training step(s),cross entropy on all data is 0.0197109\n",
      "After 836 training step(s),cross entropy on all data is 0.0196953\n",
      "After 837 training step(s),cross entropy on all data is 0.0196813\n",
      "After 838 training step(s),cross entropy on all data is 0.0196686\n",
      "After 839 training step(s),cross entropy on all data is 0.0196507\n",
      "After 840 training step(s),cross entropy on all data is 0.0196281\n",
      "After 841 training step(s),cross entropy on all data is 0.0196012\n",
      "After 842 training step(s),cross entropy on all data is 0.0195704\n",
      "After 843 training step(s),cross entropy on all data is 0.0195427\n",
      "After 844 training step(s),cross entropy on all data is 0.0195177\n",
      "After 845 training step(s),cross entropy on all data is 0.0194953\n",
      "After 846 training step(s),cross entropy on all data is 0.019475\n",
      "After 847 training step(s),cross entropy on all data is 0.0194568\n",
      "After 848 training step(s),cross entropy on all data is 0.0194404\n",
      "After 849 training step(s),cross entropy on all data is 0.019419\n",
      "After 850 training step(s),cross entropy on all data is 0.0193998\n",
      "After 851 training step(s),cross entropy on all data is 0.0193825\n",
      "After 852 training step(s),cross entropy on all data is 0.0193669\n",
      "After 853 training step(s),cross entropy on all data is 0.0193529\n",
      "After 854 training step(s),cross entropy on all data is 0.0193402\n",
      "After 855 training step(s),cross entropy on all data is 0.0193223\n",
      "After 856 training step(s),cross entropy on all data is 0.0192996\n",
      "After 857 training step(s),cross entropy on all data is 0.0192727\n",
      "After 858 training step(s),cross entropy on all data is 0.0192419\n",
      "After 859 training step(s),cross entropy on all data is 0.0192142\n",
      "After 860 training step(s),cross entropy on all data is 0.0191892\n",
      "After 861 training step(s),cross entropy on all data is 0.0191667\n",
      "After 862 training step(s),cross entropy on all data is 0.0191465\n",
      "After 863 training step(s),cross entropy on all data is 0.0191282\n",
      "After 864 training step(s),cross entropy on all data is 0.0191118\n",
      "After 865 training step(s),cross entropy on all data is 0.0190905\n",
      "After 866 training step(s),cross entropy on all data is 0.0190712\n",
      "After 867 training step(s),cross entropy on all data is 0.0190539\n",
      "After 868 training step(s),cross entropy on all data is 0.0190383\n",
      "After 869 training step(s),cross entropy on all data is 0.0190242\n",
      "After 870 training step(s),cross entropy on all data is 0.0190116\n",
      "After 871 training step(s),cross entropy on all data is 0.0189937\n",
      "After 872 training step(s),cross entropy on all data is 0.018971\n",
      "After 873 training step(s),cross entropy on all data is 0.018944\n",
      "After 874 training step(s),cross entropy on all data is 0.0189132\n",
      "After 875 training step(s),cross entropy on all data is 0.0188855\n",
      "After 876 training step(s),cross entropy on all data is 0.0188605\n",
      "After 877 training step(s),cross entropy on all data is 0.018838\n",
      "After 878 training step(s),cross entropy on all data is 0.0188177\n",
      "After 879 training step(s),cross entropy on all data is 0.0187995\n",
      "After 880 training step(s),cross entropy on all data is 0.018783\n",
      "After 881 training step(s),cross entropy on all data is 0.0187617\n",
      "After 882 training step(s),cross entropy on all data is 0.0187424\n",
      "After 883 training step(s),cross entropy on all data is 0.0187251\n",
      "After 884 training step(s),cross entropy on all data is 0.0187095\n",
      "After 885 training step(s),cross entropy on all data is 0.0186954\n",
      "After 886 training step(s),cross entropy on all data is 0.0186828\n",
      "After 887 training step(s),cross entropy on all data is 0.0186648\n",
      "After 888 training step(s),cross entropy on all data is 0.0186421\n",
      "After 889 training step(s),cross entropy on all data is 0.0186152\n",
      "After 890 training step(s),cross entropy on all data is 0.0185843\n",
      "After 891 training step(s),cross entropy on all data is 0.0185566\n",
      "After 892 training step(s),cross entropy on all data is 0.0185316\n",
      "After 893 training step(s),cross entropy on all data is 0.0185091\n",
      "After 894 training step(s),cross entropy on all data is 0.0184888\n",
      "After 895 training step(s),cross entropy on all data is 0.0184705\n",
      "After 896 training step(s),cross entropy on all data is 0.0184541\n",
      "After 897 training step(s),cross entropy on all data is 0.0184327\n",
      "After 898 training step(s),cross entropy on all data is 0.0184135\n",
      "After 899 training step(s),cross entropy on all data is 0.0183961\n",
      "After 900 training step(s),cross entropy on all data is 0.0183805\n",
      "After 901 training step(s),cross entropy on all data is 0.0183664\n",
      "After 902 training step(s),cross entropy on all data is 0.0183538\n",
      "After 903 training step(s),cross entropy on all data is 0.0183358\n",
      "After 904 training step(s),cross entropy on all data is 0.0183131\n",
      "After 905 training step(s),cross entropy on all data is 0.0182861\n",
      "After 906 training step(s),cross entropy on all data is 0.0182553\n",
      "After 907 training step(s),cross entropy on all data is 0.0182275\n",
      "After 908 training step(s),cross entropy on all data is 0.0182025\n",
      "After 909 training step(s),cross entropy on all data is 0.01818\n",
      "After 910 training step(s),cross entropy on all data is 0.0181597\n",
      "After 911 training step(s),cross entropy on all data is 0.0181415\n",
      "After 912 training step(s),cross entropy on all data is 0.018125\n",
      "After 913 training step(s),cross entropy on all data is 0.0181036\n",
      "After 914 training step(s),cross entropy on all data is 0.0180844\n",
      "After 915 training step(s),cross entropy on all data is 0.018067\n",
      "After 916 training step(s),cross entropy on all data is 0.0180514\n",
      "After 917 training step(s),cross entropy on all data is 0.0180374\n",
      "After 918 training step(s),cross entropy on all data is 0.0180247\n",
      "After 919 training step(s),cross entropy on all data is 0.0180067\n",
      "After 920 training step(s),cross entropy on all data is 0.017984\n",
      "After 921 training step(s),cross entropy on all data is 0.017957\n",
      "After 922 training step(s),cross entropy on all data is 0.0179262\n",
      "After 923 training step(s),cross entropy on all data is 0.0178984\n",
      "After 924 training step(s),cross entropy on all data is 0.0178734\n",
      "After 925 training step(s),cross entropy on all data is 0.0178509\n",
      "After 926 training step(s),cross entropy on all data is 0.0178306\n",
      "After 927 training step(s),cross entropy on all data is 0.0178123\n",
      "After 928 training step(s),cross entropy on all data is 0.0177959\n",
      "After 929 training step(s),cross entropy on all data is 0.0177745\n",
      "After 930 training step(s),cross entropy on all data is 0.0177552\n",
      "After 931 training step(s),cross entropy on all data is 0.0177379\n",
      "After 932 training step(s),cross entropy on all data is 0.0177223\n",
      "After 933 training step(s),cross entropy on all data is 0.0177082\n",
      "After 934 training step(s),cross entropy on all data is 0.0176956\n",
      "After 935 training step(s),cross entropy on all data is 0.0176776\n",
      "After 936 training step(s),cross entropy on all data is 0.0176549\n",
      "After 937 training step(s),cross entropy on all data is 0.0176279\n",
      "After 938 training step(s),cross entropy on all data is 0.017597\n",
      "After 939 training step(s),cross entropy on all data is 0.0175692\n",
      "After 940 training step(s),cross entropy on all data is 0.0175442\n",
      "After 941 training step(s),cross entropy on all data is 0.0175217\n",
      "After 942 training step(s),cross entropy on all data is 0.0175014\n",
      "After 943 training step(s),cross entropy on all data is 0.0174831\n",
      "After 944 training step(s),cross entropy on all data is 0.0174667\n",
      "After 945 training step(s),cross entropy on all data is 0.0174453\n",
      "After 946 training step(s),cross entropy on all data is 0.0174261\n",
      "After 947 training step(s),cross entropy on all data is 0.0174087\n",
      "After 948 training step(s),cross entropy on all data is 0.0173931\n",
      "After 949 training step(s),cross entropy on all data is 0.017379\n",
      "After 950 training step(s),cross entropy on all data is 0.0173664\n",
      "After 951 training step(s),cross entropy on all data is 0.0173484\n",
      "After 952 training step(s),cross entropy on all data is 0.0173257\n",
      "After 953 training step(s),cross entropy on all data is 0.0172987\n",
      "After 954 training step(s),cross entropy on all data is 0.0172679\n",
      "After 955 training step(s),cross entropy on all data is 0.0172401\n",
      "After 956 training step(s),cross entropy on all data is 0.0172151\n",
      "After 957 training step(s),cross entropy on all data is 0.0171925\n",
      "After 958 training step(s),cross entropy on all data is 0.0171723\n",
      "After 959 training step(s),cross entropy on all data is 0.017154\n",
      "After 960 training step(s),cross entropy on all data is 0.0171375\n",
      "After 961 training step(s),cross entropy on all data is 0.0171162\n",
      "After 962 training step(s),cross entropy on all data is 0.0170969\n",
      "After 963 training step(s),cross entropy on all data is 0.0170796\n",
      "After 964 training step(s),cross entropy on all data is 0.017064\n",
      "After 965 training step(s),cross entropy on all data is 0.0170499\n",
      "After 966 training step(s),cross entropy on all data is 0.0170372\n",
      "After 967 training step(s),cross entropy on all data is 0.0170193\n",
      "After 968 training step(s),cross entropy on all data is 0.0169966\n",
      "After 969 training step(s),cross entropy on all data is 0.0169696\n",
      "After 970 training step(s),cross entropy on all data is 0.0169387\n",
      "After 971 training step(s),cross entropy on all data is 0.0169109\n",
      "After 972 training step(s),cross entropy on all data is 0.0168859\n",
      "After 973 training step(s),cross entropy on all data is 0.0168634\n",
      "After 974 training step(s),cross entropy on all data is 0.0168431\n",
      "After 975 training step(s),cross entropy on all data is 0.0168249\n",
      "After 976 training step(s),cross entropy on all data is 0.0168084\n",
      "After 977 training step(s),cross entropy on all data is 0.016787\n",
      "After 978 training step(s),cross entropy on all data is 0.0167678\n",
      "After 979 training step(s),cross entropy on all data is 0.0167505\n",
      "After 980 training step(s),cross entropy on all data is 0.0167349\n",
      "After 981 training step(s),cross entropy on all data is 0.0167208\n",
      "After 982 training step(s),cross entropy on all data is 0.0167082\n",
      "After 983 training step(s),cross entropy on all data is 0.0166902\n",
      "After 984 training step(s),cross entropy on all data is 0.0166675\n",
      "After 985 training step(s),cross entropy on all data is 0.0166405\n",
      "After 986 training step(s),cross entropy on all data is 0.0166097\n",
      "After 987 training step(s),cross entropy on all data is 0.0165819\n",
      "After 988 training step(s),cross entropy on all data is 0.0165569\n",
      "After 989 training step(s),cross entropy on all data is 0.0165344\n",
      "After 990 training step(s),cross entropy on all data is 0.0165141\n",
      "After 991 training step(s),cross entropy on all data is 0.0164958\n",
      "After 992 training step(s),cross entropy on all data is 0.0164794\n",
      "After 993 training step(s),cross entropy on all data is 0.016458\n",
      "After 994 training step(s),cross entropy on all data is 0.0164388\n",
      "After 995 training step(s),cross entropy on all data is 0.0164215\n",
      "After 996 training step(s),cross entropy on all data is 0.0164059\n",
      "After 997 training step(s),cross entropy on all data is 0.0163918\n",
      "After 998 training step(s),cross entropy on all data is 0.0163792\n",
      "After 999 training step(s),cross entropy on all data is 0.0163612\n",
      "After 1000 training step(s),cross entropy on all data is 0.0163385\n",
      "After 1001 training step(s),cross entropy on all data is 0.0163115\n",
      "After 1002 training step(s),cross entropy on all data is 0.0162807\n",
      "After 1003 training step(s),cross entropy on all data is 0.0162529\n",
      "After 1004 training step(s),cross entropy on all data is 0.0162279\n",
      "After 1005 training step(s),cross entropy on all data is 0.0162054\n",
      "After 1006 training step(s),cross entropy on all data is 0.0161852\n",
      "After 1007 training step(s),cross entropy on all data is 0.0161669\n",
      "After 1008 training step(s),cross entropy on all data is 0.0161505\n",
      "After 1009 training step(s),cross entropy on all data is 0.0161291\n",
      "After 1010 training step(s),cross entropy on all data is 0.0161099\n",
      "After 1011 training step(s),cross entropy on all data is 0.0160926\n",
      "After 1012 training step(s),cross entropy on all data is 0.016077\n",
      "After 1013 training step(s),cross entropy on all data is 0.016063\n",
      "After 1014 training step(s),cross entropy on all data is 0.0160503\n",
      "After 1015 training step(s),cross entropy on all data is 0.0160324\n",
      "After 1016 training step(s),cross entropy on all data is 0.0160097\n",
      "After 1017 training step(s),cross entropy on all data is 0.0159827\n",
      "After 1018 training step(s),cross entropy on all data is 0.0159551\n",
      "After 1019 training step(s),cross entropy on all data is 0.0159329\n",
      "After 1020 training step(s),cross entropy on all data is 0.0159129\n",
      "After 1021 training step(s),cross entropy on all data is 0.0158949\n",
      "After 1022 training step(s),cross entropy on all data is 0.0158787\n",
      "After 1023 training step(s),cross entropy on all data is 0.0158641\n",
      "After 1024 training step(s),cross entropy on all data is 0.0158509\n",
      "After 1025 training step(s),cross entropy on all data is 0.015834\n",
      "After 1026 training step(s),cross entropy on all data is 0.0158188\n",
      "After 1027 training step(s),cross entropy on all data is 0.0158051\n",
      "After 1028 training step(s),cross entropy on all data is 0.0157928\n",
      "After 1029 training step(s),cross entropy on all data is 0.0157816\n",
      "After 1030 training step(s),cross entropy on all data is 0.0157716\n",
      "After 1031 training step(s),cross entropy on all data is 0.0157573\n",
      "After 1032 training step(s),cross entropy on all data is 0.0157389\n",
      "After 1033 training step(s),cross entropy on all data is 0.0157169\n",
      "After 1034 training step(s),cross entropy on all data is 0.0156971\n",
      "After 1035 training step(s),cross entropy on all data is 0.0156793\n",
      "After 1036 training step(s),cross entropy on all data is 0.0156632\n",
      "After 1037 training step(s),cross entropy on all data is 0.0156488\n",
      "After 1038 training step(s),cross entropy on all data is 0.0156357\n",
      "After 1039 training step(s),cross entropy on all data is 0.015624\n",
      "After 1040 training step(s),cross entropy on all data is 0.0156135\n",
      "After 1041 training step(s),cross entropy on all data is 0.0155989\n",
      "After 1042 training step(s),cross entropy on all data is 0.0155857\n",
      "After 1043 training step(s),cross entropy on all data is 0.0155739\n",
      "After 1044 training step(s),cross entropy on all data is 0.0155632\n",
      "After 1045 training step(s),cross entropy on all data is 0.0155536\n",
      "After 1046 training step(s),cross entropy on all data is 0.015545\n",
      "After 1047 training step(s),cross entropy on all data is 0.0155319\n",
      "After 1048 training step(s),cross entropy on all data is 0.0155146\n",
      "After 1049 training step(s),cross entropy on all data is 0.0154936\n",
      "After 1050 training step(s),cross entropy on all data is 0.0154747\n",
      "After 1051 training step(s),cross entropy on all data is 0.0154576\n",
      "After 1052 training step(s),cross entropy on all data is 0.0154423\n",
      "After 1053 training step(s),cross entropy on all data is 0.0154284\n",
      "After 1054 training step(s),cross entropy on all data is 0.015416\n",
      "After 1055 training step(s),cross entropy on all data is 0.0154048\n",
      "After 1056 training step(s),cross entropy on all data is 0.0153947\n",
      "After 1057 training step(s),cross entropy on all data is 0.0153805\n",
      "After 1058 training step(s),cross entropy on all data is 0.0153677\n",
      "After 1059 training step(s),cross entropy on all data is 0.0153562\n",
      "After 1060 training step(s),cross entropy on all data is 0.0153459\n",
      "After 1061 training step(s),cross entropy on all data is 0.0153365\n",
      "After 1062 training step(s),cross entropy on all data is 0.0153281\n",
      "After 1063 training step(s),cross entropy on all data is 0.0153152\n",
      "After 1064 training step(s),cross entropy on all data is 0.0152981\n",
      "After 1065 training step(s),cross entropy on all data is 0.0152772\n",
      "After 1066 training step(s),cross entropy on all data is 0.0152584\n",
      "After 1067 training step(s),cross entropy on all data is 0.0152415\n",
      "After 1068 training step(s),cross entropy on all data is 0.0152263\n",
      "After 1069 training step(s),cross entropy on all data is 0.0152125\n",
      "After 1070 training step(s),cross entropy on all data is 0.0152002\n",
      "After 1071 training step(s),cross entropy on all data is 0.0151891\n",
      "After 1072 training step(s),cross entropy on all data is 0.015179\n",
      "After 1073 training step(s),cross entropy on all data is 0.0151649\n",
      "After 1074 training step(s),cross entropy on all data is 0.0151522\n",
      "After 1075 training step(s),cross entropy on all data is 0.0151407\n",
      "After 1076 training step(s),cross entropy on all data is 0.0151304\n",
      "After 1077 training step(s),cross entropy on all data is 0.0151211\n",
      "After 1078 training step(s),cross entropy on all data is 0.0151127\n",
      "After 1079 training step(s),cross entropy on all data is 0.0150998\n",
      "After 1080 training step(s),cross entropy on all data is 0.0150827\n",
      "After 1081 training step(s),cross entropy on all data is 0.0150619\n",
      "After 1082 training step(s),cross entropy on all data is 0.0150431\n",
      "After 1083 training step(s),cross entropy on all data is 0.0150261\n",
      "After 1084 training step(s),cross entropy on all data is 0.0150109\n",
      "After 1085 training step(s),cross entropy on all data is 0.0149972\n",
      "After 1086 training step(s),cross entropy on all data is 0.0149848\n",
      "After 1087 training step(s),cross entropy on all data is 0.0149737\n",
      "After 1088 training step(s),cross entropy on all data is 0.0149637\n",
      "After 1089 training step(s),cross entropy on all data is 0.0149495\n",
      "After 1090 training step(s),cross entropy on all data is 0.0149368\n",
      "After 1091 training step(s),cross entropy on all data is 0.0149253\n",
      "After 1092 training step(s),cross entropy on all data is 0.014915\n",
      "After 1093 training step(s),cross entropy on all data is 0.0149057\n",
      "After 1094 training step(s),cross entropy on all data is 0.0148973\n",
      "After 1095 training step(s),cross entropy on all data is 0.0148844\n",
      "After 1096 training step(s),cross entropy on all data is 0.0148673\n",
      "After 1097 training step(s),cross entropy on all data is 0.0148464\n",
      "After 1098 training step(s),cross entropy on all data is 0.0148275\n",
      "After 1099 training step(s),cross entropy on all data is 0.0148106\n",
      "After 1100 training step(s),cross entropy on all data is 0.0147953\n",
      "After 1101 training step(s),cross entropy on all data is 0.0147816\n",
      "After 1102 training step(s),cross entropy on all data is 0.0147692\n",
      "After 1103 training step(s),cross entropy on all data is 0.0147581\n",
      "After 1104 training step(s),cross entropy on all data is 0.014748\n",
      "After 1105 training step(s),cross entropy on all data is 0.0147339\n",
      "After 1106 training step(s),cross entropy on all data is 0.0147211\n",
      "After 1107 training step(s),cross entropy on all data is 0.0147096\n",
      "After 1108 training step(s),cross entropy on all data is 0.0146993\n",
      "After 1109 training step(s),cross entropy on all data is 0.01469\n",
      "After 1110 training step(s),cross entropy on all data is 0.0146816\n",
      "After 1111 training step(s),cross entropy on all data is 0.0146686\n",
      "After 1112 training step(s),cross entropy on all data is 0.0146515\n",
      "After 1113 training step(s),cross entropy on all data is 0.0146306\n",
      "After 1114 training step(s),cross entropy on all data is 0.0146117\n",
      "After 1115 training step(s),cross entropy on all data is 0.0145947\n",
      "After 1116 training step(s),cross entropy on all data is 0.0145833\n",
      "After 1117 training step(s),cross entropy on all data is 0.0145731\n",
      "After 1118 training step(s),cross entropy on all data is 0.0145639\n",
      "After 1119 training step(s),cross entropy on all data is 0.0145556\n",
      "After 1120 training step(s),cross entropy on all data is 0.0145481\n",
      "After 1121 training step(s),cross entropy on all data is 0.0145375\n",
      "After 1122 training step(s),cross entropy on all data is 0.0145279\n",
      "After 1123 training step(s),cross entropy on all data is 0.0145193\n",
      "After 1124 training step(s),cross entropy on all data is 0.0145116\n",
      "After 1125 training step(s),cross entropy on all data is 0.0145046\n",
      "After 1126 training step(s),cross entropy on all data is 0.0144983\n",
      "After 1127 training step(s),cross entropy on all data is 0.0144886\n",
      "After 1128 training step(s),cross entropy on all data is 0.0144799\n",
      "After 1129 training step(s),cross entropy on all data is 0.0144679\n",
      "After 1130 training step(s),cross entropy on all data is 0.0144572\n",
      "After 1131 training step(s),cross entropy on all data is 0.0144475\n",
      "After 1132 training step(s),cross entropy on all data is 0.0144388\n",
      "After 1133 training step(s),cross entropy on all data is 0.014431\n",
      "After 1134 training step(s),cross entropy on all data is 0.0144239\n",
      "After 1135 training step(s),cross entropy on all data is 0.0144175\n",
      "After 1136 training step(s),cross entropy on all data is 0.0144118\n",
      "After 1137 training step(s),cross entropy on all data is 0.0144027\n",
      "After 1138 training step(s),cross entropy on all data is 0.0143945\n",
      "After 1139 training step(s),cross entropy on all data is 0.0143872\n",
      "After 1140 training step(s),cross entropy on all data is 0.0143805\n",
      "After 1141 training step(s),cross entropy on all data is 0.0143746\n",
      "After 1142 training step(s),cross entropy on all data is 0.0143692\n",
      "After 1143 training step(s),cross entropy on all data is 0.0143603\n",
      "After 1144 training step(s),cross entropy on all data is 0.0143523\n",
      "After 1145 training step(s),cross entropy on all data is 0.014341\n",
      "After 1146 training step(s),cross entropy on all data is 0.0143309\n",
      "After 1147 training step(s),cross entropy on all data is 0.0143217\n",
      "After 1148 training step(s),cross entropy on all data is 0.0143135\n",
      "After 1149 training step(s),cross entropy on all data is 0.014306\n",
      "After 1150 training step(s),cross entropy on all data is 0.0142993\n",
      "After 1151 training step(s),cross entropy on all data is 0.0142933\n",
      "After 1152 training step(s),cross entropy on all data is 0.0142879\n",
      "After 1153 training step(s),cross entropy on all data is 0.0142791\n",
      "After 1154 training step(s),cross entropy on all data is 0.0142711\n",
      "After 1155 training step(s),cross entropy on all data is 0.014264\n",
      "After 1156 training step(s),cross entropy on all data is 0.0142575\n",
      "After 1157 training step(s),cross entropy on all data is 0.0142517\n",
      "After 1158 training step(s),cross entropy on all data is 0.0142465\n",
      "After 1159 training step(s),cross entropy on all data is 0.0142378\n",
      "After 1160 training step(s),cross entropy on all data is 0.0142299\n",
      "After 1161 training step(s),cross entropy on all data is 0.0142187\n",
      "After 1162 training step(s),cross entropy on all data is 0.0142086\n",
      "After 1163 training step(s),cross entropy on all data is 0.0141995\n",
      "After 1164 training step(s),cross entropy on all data is 0.0141913\n",
      "After 1165 training step(s),cross entropy on all data is 0.0141839\n",
      "After 1166 training step(s),cross entropy on all data is 0.0141773\n",
      "After 1167 training step(s),cross entropy on all data is 0.0141713\n",
      "After 1168 training step(s),cross entropy on all data is 0.0141659\n",
      "After 1169 training step(s),cross entropy on all data is 0.0141571\n",
      "After 1170 training step(s),cross entropy on all data is 0.0141492\n",
      "After 1171 training step(s),cross entropy on all data is 0.0141421\n",
      "After 1172 training step(s),cross entropy on all data is 0.0141356\n",
      "After 1173 training step(s),cross entropy on all data is 0.0141299\n",
      "After 1174 training step(s),cross entropy on all data is 0.0141246\n",
      "After 1175 training step(s),cross entropy on all data is 0.0141159\n",
      "After 1176 training step(s),cross entropy on all data is 0.014108\n",
      "After 1177 training step(s),cross entropy on all data is 0.0140968\n",
      "After 1178 training step(s),cross entropy on all data is 0.0140867\n",
      "After 1179 training step(s),cross entropy on all data is 0.0140776\n",
      "After 1180 training step(s),cross entropy on all data is 0.0140694\n",
      "After 1181 training step(s),cross entropy on all data is 0.014062\n",
      "After 1182 training step(s),cross entropy on all data is 0.0140553\n",
      "After 1183 training step(s),cross entropy on all data is 0.0140493\n",
      "After 1184 training step(s),cross entropy on all data is 0.014044\n",
      "After 1185 training step(s),cross entropy on all data is 0.0140351\n",
      "After 1186 training step(s),cross entropy on all data is 0.0140272\n",
      "After 1187 training step(s),cross entropy on all data is 0.01402\n",
      "After 1188 training step(s),cross entropy on all data is 0.0140136\n",
      "After 1189 training step(s),cross entropy on all data is 0.0140078\n",
      "After 1190 training step(s),cross entropy on all data is 0.0140026\n",
      "After 1191 training step(s),cross entropy on all data is 0.0139938\n",
      "After 1192 training step(s),cross entropy on all data is 0.0139859\n",
      "After 1193 training step(s),cross entropy on all data is 0.0139746\n",
      "After 1194 training step(s),cross entropy on all data is 0.0139645\n",
      "After 1195 training step(s),cross entropy on all data is 0.0139553\n",
      "After 1196 training step(s),cross entropy on all data is 0.0139471\n",
      "After 1197 training step(s),cross entropy on all data is 0.0139397\n",
      "After 1198 training step(s),cross entropy on all data is 0.013933\n",
      "After 1199 training step(s),cross entropy on all data is 0.013927\n",
      "After 1200 training step(s),cross entropy on all data is 0.0139216\n",
      "After 1201 training step(s),cross entropy on all data is 0.0139128\n",
      "After 1202 training step(s),cross entropy on all data is 0.0139048\n",
      "After 1203 training step(s),cross entropy on all data is 0.0138976\n",
      "After 1204 training step(s),cross entropy on all data is 0.0138911\n",
      "After 1205 training step(s),cross entropy on all data is 0.0138853\n",
      "After 1206 training step(s),cross entropy on all data is 0.0138801\n",
      "After 1207 training step(s),cross entropy on all data is 0.0138713\n",
      "After 1208 training step(s),cross entropy on all data is 0.0138633\n",
      "After 1209 training step(s),cross entropy on all data is 0.013852\n",
      "After 1210 training step(s),cross entropy on all data is 0.0138418\n",
      "After 1211 training step(s),cross entropy on all data is 0.0138327\n",
      "After 1212 training step(s),cross entropy on all data is 0.0138244\n",
      "After 1213 training step(s),cross entropy on all data is 0.013817\n",
      "After 1214 training step(s),cross entropy on all data is 0.0138103\n",
      "After 1215 training step(s),cross entropy on all data is 0.0138043\n",
      "After 1216 training step(s),cross entropy on all data is 0.0137988\n",
      "After 1217 training step(s),cross entropy on all data is 0.01379\n",
      "After 1218 training step(s),cross entropy on all data is 0.013782\n",
      "After 1219 training step(s),cross entropy on all data is 0.0137748\n",
      "After 1220 training step(s),cross entropy on all data is 0.0137683\n",
      "After 1221 training step(s),cross entropy on all data is 0.0137624\n",
      "After 1222 training step(s),cross entropy on all data is 0.0137572\n",
      "After 1223 training step(s),cross entropy on all data is 0.0137483\n",
      "After 1224 training step(s),cross entropy on all data is 0.0137404\n",
      "After 1225 training step(s),cross entropy on all data is 0.013729\n",
      "After 1226 training step(s),cross entropy on all data is 0.0137188\n",
      "After 1227 training step(s),cross entropy on all data is 0.0137096\n",
      "After 1228 training step(s),cross entropy on all data is 0.0137013\n",
      "After 1229 training step(s),cross entropy on all data is 0.0136939\n",
      "After 1230 training step(s),cross entropy on all data is 0.0136872\n",
      "After 1231 training step(s),cross entropy on all data is 0.0136811\n",
      "After 1232 training step(s),cross entropy on all data is 0.0136757\n",
      "After 1233 training step(s),cross entropy on all data is 0.0136667\n",
      "After 1234 training step(s),cross entropy on all data is 0.0136587\n",
      "After 1235 training step(s),cross entropy on all data is 0.0136515\n",
      "After 1236 training step(s),cross entropy on all data is 0.013645\n",
      "After 1237 training step(s),cross entropy on all data is 0.0136391\n",
      "After 1238 training step(s),cross entropy on all data is 0.0136339\n",
      "After 1239 training step(s),cross entropy on all data is 0.013625\n",
      "After 1240 training step(s),cross entropy on all data is 0.013617\n",
      "After 1241 training step(s),cross entropy on all data is 0.0136056\n",
      "After 1242 training step(s),cross entropy on all data is 0.0135954\n",
      "After 1243 training step(s),cross entropy on all data is 0.0135861\n",
      "After 1244 training step(s),cross entropy on all data is 0.0135778\n",
      "After 1245 training step(s),cross entropy on all data is 0.0135703\n",
      "After 1246 training step(s),cross entropy on all data is 0.0135636\n",
      "After 1247 training step(s),cross entropy on all data is 0.0135575\n",
      "After 1248 training step(s),cross entropy on all data is 0.0135521\n",
      "After 1249 training step(s),cross entropy on all data is 0.0135431\n",
      "After 1250 training step(s),cross entropy on all data is 0.0135351\n",
      "After 1251 training step(s),cross entropy on all data is 0.0135278\n",
      "After 1252 training step(s),cross entropy on all data is 0.0135213\n",
      "After 1253 training step(s),cross entropy on all data is 0.0135154\n",
      "After 1254 training step(s),cross entropy on all data is 0.0135101\n",
      "After 1255 training step(s),cross entropy on all data is 0.0135012\n",
      "After 1256 training step(s),cross entropy on all data is 0.0134932\n",
      "After 1257 training step(s),cross entropy on all data is 0.0134818\n",
      "After 1258 training step(s),cross entropy on all data is 0.0134715\n",
      "After 1259 training step(s),cross entropy on all data is 0.0134622\n",
      "After 1260 training step(s),cross entropy on all data is 0.0134539\n",
      "After 1261 training step(s),cross entropy on all data is 0.0134464\n",
      "After 1262 training step(s),cross entropy on all data is 0.0134396\n",
      "After 1263 training step(s),cross entropy on all data is 0.0134336\n",
      "After 1264 training step(s),cross entropy on all data is 0.0134281\n",
      "After 1265 training step(s),cross entropy on all data is 0.0134191\n",
      "After 1266 training step(s),cross entropy on all data is 0.013411\n",
      "After 1267 training step(s),cross entropy on all data is 0.0134038\n",
      "After 1268 training step(s),cross entropy on all data is 0.0133972\n",
      "After 1269 training step(s),cross entropy on all data is 0.0133913\n",
      "After 1270 training step(s),cross entropy on all data is 0.013386\n",
      "After 1271 training step(s),cross entropy on all data is 0.0133771\n",
      "After 1272 training step(s),cross entropy on all data is 0.013369\n",
      "After 1273 training step(s),cross entropy on all data is 0.0133576\n",
      "After 1274 training step(s),cross entropy on all data is 0.0133473\n",
      "After 1275 training step(s),cross entropy on all data is 0.013338\n",
      "After 1276 training step(s),cross entropy on all data is 0.0133296\n",
      "After 1277 training step(s),cross entropy on all data is 0.0133221\n",
      "After 1278 training step(s),cross entropy on all data is 0.0133153\n",
      "After 1279 training step(s),cross entropy on all data is 0.0133092\n",
      "After 1280 training step(s),cross entropy on all data is 0.0133037\n",
      "After 1281 training step(s),cross entropy on all data is 0.0132947\n",
      "After 1282 training step(s),cross entropy on all data is 0.0132866\n",
      "After 1283 training step(s),cross entropy on all data is 0.0132793\n",
      "After 1284 training step(s),cross entropy on all data is 0.0132727\n",
      "After 1285 training step(s),cross entropy on all data is 0.0132668\n",
      "After 1286 training step(s),cross entropy on all data is 0.0132615\n",
      "After 1287 training step(s),cross entropy on all data is 0.0132525\n",
      "After 1288 training step(s),cross entropy on all data is 0.0132445\n",
      "After 1289 training step(s),cross entropy on all data is 0.013233\n",
      "After 1290 training step(s),cross entropy on all data is 0.0132226\n",
      "After 1291 training step(s),cross entropy on all data is 0.0132133\n",
      "After 1292 training step(s),cross entropy on all data is 0.0132049\n",
      "After 1293 training step(s),cross entropy on all data is 0.0131974\n",
      "After 1294 training step(s),cross entropy on all data is 0.0131906\n",
      "After 1295 training step(s),cross entropy on all data is 0.0131845\n",
      "After 1296 training step(s),cross entropy on all data is 0.0131789\n",
      "After 1297 training step(s),cross entropy on all data is 0.0131699\n",
      "After 1298 training step(s),cross entropy on all data is 0.0131618\n",
      "After 1299 training step(s),cross entropy on all data is 0.0131545\n",
      "After 1300 training step(s),cross entropy on all data is 0.0131479\n",
      "After 1301 training step(s),cross entropy on all data is 0.013142\n",
      "After 1302 training step(s),cross entropy on all data is 0.0131366\n",
      "After 1303 training step(s),cross entropy on all data is 0.0131276\n",
      "After 1304 training step(s),cross entropy on all data is 0.0131195\n",
      "After 1305 training step(s),cross entropy on all data is 0.013108\n",
      "After 1306 training step(s),cross entropy on all data is 0.0130976\n",
      "After 1307 training step(s),cross entropy on all data is 0.0130883\n",
      "After 1308 training step(s),cross entropy on all data is 0.0130799\n",
      "After 1309 training step(s),cross entropy on all data is 0.0130723\n",
      "After 1310 training step(s),cross entropy on all data is 0.0130655\n",
      "After 1311 training step(s),cross entropy on all data is 0.0130594\n",
      "After 1312 training step(s),cross entropy on all data is 0.0130538\n",
      "After 1313 training step(s),cross entropy on all data is 0.0130448\n",
      "After 1314 training step(s),cross entropy on all data is 0.0130366\n",
      "After 1315 training step(s),cross entropy on all data is 0.0130293\n",
      "After 1316 training step(s),cross entropy on all data is 0.0130227\n",
      "After 1317 training step(s),cross entropy on all data is 0.0130167\n",
      "After 1318 training step(s),cross entropy on all data is 0.0130114\n",
      "After 1319 training step(s),cross entropy on all data is 0.0130024\n",
      "After 1320 training step(s),cross entropy on all data is 0.0129942\n",
      "After 1321 training step(s),cross entropy on all data is 0.0129827\n",
      "After 1322 training step(s),cross entropy on all data is 0.0129723\n",
      "After 1323 training step(s),cross entropy on all data is 0.0129629\n",
      "After 1324 training step(s),cross entropy on all data is 0.0129545\n",
      "After 1325 training step(s),cross entropy on all data is 0.0129469\n",
      "After 1326 training step(s),cross entropy on all data is 0.0129401\n",
      "After 1327 training step(s),cross entropy on all data is 0.0129339\n",
      "After 1328 training step(s),cross entropy on all data is 0.0129284\n",
      "After 1329 training step(s),cross entropy on all data is 0.0129193\n",
      "After 1330 training step(s),cross entropy on all data is 0.0129111\n",
      "After 1331 training step(s),cross entropy on all data is 0.0129038\n",
      "After 1332 training step(s),cross entropy on all data is 0.0128971\n",
      "After 1333 training step(s),cross entropy on all data is 0.0128912\n",
      "After 1334 training step(s),cross entropy on all data is 0.0128858\n",
      "After 1335 training step(s),cross entropy on all data is 0.0128768\n",
      "After 1336 training step(s),cross entropy on all data is 0.0128686\n",
      "After 1337 training step(s),cross entropy on all data is 0.012857\n",
      "After 1338 training step(s),cross entropy on all data is 0.0128466\n",
      "After 1339 training step(s),cross entropy on all data is 0.0128372\n",
      "After 1340 training step(s),cross entropy on all data is 0.0128288\n",
      "After 1341 training step(s),cross entropy on all data is 0.0128212\n",
      "After 1342 training step(s),cross entropy on all data is 0.0128143\n",
      "After 1343 training step(s),cross entropy on all data is 0.0128081\n",
      "After 1344 training step(s),cross entropy on all data is 0.0128026\n",
      "After 1345 training step(s),cross entropy on all data is 0.0127935\n",
      "After 1346 training step(s),cross entropy on all data is 0.0127853\n",
      "After 1347 training step(s),cross entropy on all data is 0.0127779\n",
      "After 1348 training step(s),cross entropy on all data is 0.0127713\n",
      "After 1349 training step(s),cross entropy on all data is 0.0127653\n",
      "After 1350 training step(s),cross entropy on all data is 0.0127599\n",
      "After 1351 training step(s),cross entropy on all data is 0.0127508\n",
      "After 1352 training step(s),cross entropy on all data is 0.0127427\n",
      "After 1353 training step(s),cross entropy on all data is 0.0127311\n",
      "After 1354 training step(s),cross entropy on all data is 0.0127206\n",
      "After 1355 training step(s),cross entropy on all data is 0.0127112\n",
      "After 1356 training step(s),cross entropy on all data is 0.0127027\n",
      "After 1357 training step(s),cross entropy on all data is 0.0126951\n",
      "After 1358 training step(s),cross entropy on all data is 0.0126882\n",
      "After 1359 training step(s),cross entropy on all data is 0.012682\n",
      "After 1360 training step(s),cross entropy on all data is 0.0126764\n",
      "After 1361 training step(s),cross entropy on all data is 0.0126673\n",
      "After 1362 training step(s),cross entropy on all data is 0.0126591\n",
      "After 1363 training step(s),cross entropy on all data is 0.0126517\n",
      "After 1364 training step(s),cross entropy on all data is 0.012645\n",
      "After 1365 training step(s),cross entropy on all data is 0.012639\n",
      "After 1366 training step(s),cross entropy on all data is 0.0126336\n",
      "After 1367 training step(s),cross entropy on all data is 0.0126246\n",
      "After 1368 training step(s),cross entropy on all data is 0.0126164\n",
      "After 1369 training step(s),cross entropy on all data is 0.0126047\n",
      "After 1370 training step(s),cross entropy on all data is 0.0125943\n",
      "After 1371 training step(s),cross entropy on all data is 0.0125848\n",
      "After 1372 training step(s),cross entropy on all data is 0.0125763\n",
      "After 1373 training step(s),cross entropy on all data is 0.0125687\n",
      "After 1374 training step(s),cross entropy on all data is 0.0125618\n",
      "After 1375 training step(s),cross entropy on all data is 0.0125556\n",
      "After 1376 training step(s),cross entropy on all data is 0.01255\n",
      "After 1377 training step(s),cross entropy on all data is 0.0125408\n",
      "After 1378 training step(s),cross entropy on all data is 0.0125326\n",
      "After 1379 training step(s),cross entropy on all data is 0.0125252\n",
      "After 1380 training step(s),cross entropy on all data is 0.0125185\n",
      "After 1381 training step(s),cross entropy on all data is 0.0125125\n",
      "After 1382 training step(s),cross entropy on all data is 0.0125071\n",
      "After 1383 training step(s),cross entropy on all data is 0.012498\n",
      "After 1384 training step(s),cross entropy on all data is 0.0124898\n",
      "After 1385 training step(s),cross entropy on all data is 0.0124781\n",
      "After 1386 training step(s),cross entropy on all data is 0.0124676\n",
      "After 1387 training step(s),cross entropy on all data is 0.0124582\n",
      "After 1388 training step(s),cross entropy on all data is 0.0124496\n",
      "After 1389 training step(s),cross entropy on all data is 0.012442\n",
      "After 1390 training step(s),cross entropy on all data is 0.0124351\n",
      "After 1391 training step(s),cross entropy on all data is 0.0124288\n",
      "After 1392 training step(s),cross entropy on all data is 0.0124232\n",
      "After 1393 training step(s),cross entropy on all data is 0.0124141\n",
      "After 1394 training step(s),cross entropy on all data is 0.0124058\n",
      "After 1395 training step(s),cross entropy on all data is 0.0123984\n",
      "After 1396 training step(s),cross entropy on all data is 0.0123917\n",
      "After 1397 training step(s),cross entropy on all data is 0.0123857\n",
      "After 1398 training step(s),cross entropy on all data is 0.0123802\n",
      "After 1399 training step(s),cross entropy on all data is 0.0123711\n",
      "After 1400 training step(s),cross entropy on all data is 0.0123629\n",
      "After 1401 training step(s),cross entropy on all data is 0.0123512\n",
      "After 1402 training step(s),cross entropy on all data is 0.0123407\n",
      "After 1403 training step(s),cross entropy on all data is 0.0123312\n",
      "After 1404 training step(s),cross entropy on all data is 0.0123227\n",
      "After 1405 training step(s),cross entropy on all data is 0.012315\n",
      "After 1406 training step(s),cross entropy on all data is 0.012308\n",
      "After 1407 training step(s),cross entropy on all data is 0.0123018\n",
      "After 1408 training step(s),cross entropy on all data is 0.0122962\n",
      "After 1409 training step(s),cross entropy on all data is 0.012287\n",
      "After 1410 training step(s),cross entropy on all data is 0.0122787\n",
      "After 1411 training step(s),cross entropy on all data is 0.0122713\n",
      "After 1412 training step(s),cross entropy on all data is 0.0122646\n",
      "After 1413 training step(s),cross entropy on all data is 0.0122585\n",
      "After 1414 training step(s),cross entropy on all data is 0.0122531\n",
      "After 1415 training step(s),cross entropy on all data is 0.0122439\n",
      "After 1416 training step(s),cross entropy on all data is 0.0122357\n",
      "After 1417 training step(s),cross entropy on all data is 0.012224\n",
      "After 1418 training step(s),cross entropy on all data is 0.0122134\n",
      "After 1419 training step(s),cross entropy on all data is 0.0122039\n",
      "After 1420 training step(s),cross entropy on all data is 0.0121954\n",
      "After 1421 training step(s),cross entropy on all data is 0.0121877\n",
      "After 1422 training step(s),cross entropy on all data is 0.0121807\n",
      "After 1423 training step(s),cross entropy on all data is 0.0121745\n",
      "After 1424 training step(s),cross entropy on all data is 0.0121689\n",
      "After 1425 training step(s),cross entropy on all data is 0.0121597\n",
      "After 1426 training step(s),cross entropy on all data is 0.0121514\n",
      "After 1427 training step(s),cross entropy on all data is 0.0121439\n",
      "After 1428 training step(s),cross entropy on all data is 0.0121372\n",
      "After 1429 training step(s),cross entropy on all data is 0.0121311\n",
      "After 1430 training step(s),cross entropy on all data is 0.0121257\n",
      "After 1431 training step(s),cross entropy on all data is 0.0121165\n",
      "After 1432 training step(s),cross entropy on all data is 0.0121083\n",
      "After 1433 training step(s),cross entropy on all data is 0.0120965\n",
      "After 1434 training step(s),cross entropy on all data is 0.0120859\n",
      "After 1435 training step(s),cross entropy on all data is 0.0120764\n",
      "After 1436 training step(s),cross entropy on all data is 0.0120678\n",
      "After 1437 training step(s),cross entropy on all data is 0.0120601\n",
      "After 1438 training step(s),cross entropy on all data is 0.0120532\n",
      "After 1439 training step(s),cross entropy on all data is 0.0120469\n",
      "After 1440 training step(s),cross entropy on all data is 0.0120413\n",
      "After 1441 training step(s),cross entropy on all data is 0.012032\n",
      "After 1442 training step(s),cross entropy on all data is 0.0120237\n",
      "After 1443 training step(s),cross entropy on all data is 0.0120163\n",
      "After 1444 training step(s),cross entropy on all data is 0.0120095\n",
      "After 1445 training step(s),cross entropy on all data is 0.0120034\n",
      "After 1446 training step(s),cross entropy on all data is 0.011998\n",
      "After 1447 training step(s),cross entropy on all data is 0.0119888\n",
      "After 1448 training step(s),cross entropy on all data is 0.0119805\n",
      "After 1449 training step(s),cross entropy on all data is 0.0119688\n",
      "After 1450 training step(s),cross entropy on all data is 0.0119582\n",
      "After 1451 training step(s),cross entropy on all data is 0.0119486\n",
      "After 1452 training step(s),cross entropy on all data is 0.01194\n",
      "After 1453 training step(s),cross entropy on all data is 0.0119323\n",
      "After 1454 training step(s),cross entropy on all data is 0.0119253\n",
      "After 1455 training step(s),cross entropy on all data is 0.0119191\n",
      "After 1456 training step(s),cross entropy on all data is 0.0119134\n",
      "After 1457 training step(s),cross entropy on all data is 0.0119042\n",
      "After 1458 training step(s),cross entropy on all data is 0.0118958\n",
      "After 1459 training step(s),cross entropy on all data is 0.0118883\n",
      "After 1460 training step(s),cross entropy on all data is 0.0118816\n",
      "After 1461 training step(s),cross entropy on all data is 0.0118755\n",
      "After 1462 training step(s),cross entropy on all data is 0.01187\n",
      "After 1463 training step(s),cross entropy on all data is 0.0118608\n",
      "After 1464 training step(s),cross entropy on all data is 0.0118525\n",
      "After 1465 training step(s),cross entropy on all data is 0.0118408\n",
      "After 1466 training step(s),cross entropy on all data is 0.0118301\n",
      "After 1467 training step(s),cross entropy on all data is 0.0118206\n",
      "After 1468 training step(s),cross entropy on all data is 0.011812\n",
      "After 1469 training step(s),cross entropy on all data is 0.0118042\n",
      "After 1470 training step(s),cross entropy on all data is 0.0117972\n",
      "After 1471 training step(s),cross entropy on all data is 0.011791\n",
      "After 1472 training step(s),cross entropy on all data is 0.0117853\n",
      "After 1473 training step(s),cross entropy on all data is 0.011776\n",
      "After 1474 training step(s),cross entropy on all data is 0.0117677\n",
      "After 1475 training step(s),cross entropy on all data is 0.0117602\n",
      "After 1476 training step(s),cross entropy on all data is 0.0117534\n",
      "After 1477 training step(s),cross entropy on all data is 0.0117473\n",
      "After 1478 training step(s),cross entropy on all data is 0.0117418\n",
      "After 1479 training step(s),cross entropy on all data is 0.0117326\n",
      "After 1480 training step(s),cross entropy on all data is 0.0117243\n",
      "After 1481 training step(s),cross entropy on all data is 0.0117125\n",
      "After 1482 training step(s),cross entropy on all data is 0.0117019\n",
      "After 1483 training step(s),cross entropy on all data is 0.0116923\n",
      "After 1484 training step(s),cross entropy on all data is 0.0116837\n",
      "After 1485 training step(s),cross entropy on all data is 0.0116759\n",
      "After 1486 training step(s),cross entropy on all data is 0.0116689\n",
      "After 1487 training step(s),cross entropy on all data is 0.0116626\n",
      "After 1488 training step(s),cross entropy on all data is 0.0116569\n",
      "After 1489 training step(s),cross entropy on all data is 0.0116477\n",
      "After 1490 training step(s),cross entropy on all data is 0.0116393\n",
      "After 1491 training step(s),cross entropy on all data is 0.0116318\n",
      "After 1492 training step(s),cross entropy on all data is 0.011625\n",
      "After 1493 training step(s),cross entropy on all data is 0.0116189\n",
      "After 1494 training step(s),cross entropy on all data is 0.0116134\n",
      "After 1495 training step(s),cross entropy on all data is 0.0116042\n",
      "After 1496 training step(s),cross entropy on all data is 0.0115958\n",
      "After 1497 training step(s),cross entropy on all data is 0.011584\n",
      "After 1498 training step(s),cross entropy on all data is 0.0115734\n",
      "After 1499 training step(s),cross entropy on all data is 0.0115638\n",
      "After 1500 training step(s),cross entropy on all data is 0.0115551\n",
      "After 1501 training step(s),cross entropy on all data is 0.0115473\n",
      "After 1502 training step(s),cross entropy on all data is 0.0115403\n",
      "After 1503 training step(s),cross entropy on all data is 0.011534\n",
      "After 1504 training step(s),cross entropy on all data is 0.0115284\n",
      "After 1505 training step(s),cross entropy on all data is 0.0115191\n",
      "After 1506 training step(s),cross entropy on all data is 0.0115107\n",
      "After 1507 training step(s),cross entropy on all data is 0.0115031\n",
      "After 1508 training step(s),cross entropy on all data is 0.0114964\n",
      "After 1509 training step(s),cross entropy on all data is 0.0114902\n",
      "After 1510 training step(s),cross entropy on all data is 0.0114847\n",
      "After 1511 training step(s),cross entropy on all data is 0.0114755\n",
      "After 1512 training step(s),cross entropy on all data is 0.0114672\n",
      "After 1513 training step(s),cross entropy on all data is 0.0114553\n",
      "After 1514 training step(s),cross entropy on all data is 0.0114446\n",
      "After 1515 training step(s),cross entropy on all data is 0.011435\n",
      "After 1516 training step(s),cross entropy on all data is 0.0114264\n",
      "After 1517 training step(s),cross entropy on all data is 0.0114186\n",
      "After 1518 training step(s),cross entropy on all data is 0.0114116\n",
      "After 1519 training step(s),cross entropy on all data is 0.0114052\n",
      "After 1520 training step(s),cross entropy on all data is 0.0113996\n",
      "After 1521 training step(s),cross entropy on all data is 0.0113902\n",
      "After 1522 training step(s),cross entropy on all data is 0.0113819\n",
      "After 1523 training step(s),cross entropy on all data is 0.0113743\n",
      "After 1524 training step(s),cross entropy on all data is 0.0113675\n",
      "After 1525 training step(s),cross entropy on all data is 0.0113614\n",
      "After 1526 training step(s),cross entropy on all data is 0.0113559\n",
      "After 1527 training step(s),cross entropy on all data is 0.0113466\n",
      "After 1528 training step(s),cross entropy on all data is 0.0113382\n",
      "After 1529 training step(s),cross entropy on all data is 0.0113264\n",
      "After 1530 training step(s),cross entropy on all data is 0.0113157\n",
      "After 1531 training step(s),cross entropy on all data is 0.0113061\n",
      "After 1532 training step(s),cross entropy on all data is 0.0112974\n",
      "After 1533 training step(s),cross entropy on all data is 0.0112896\n",
      "After 1534 training step(s),cross entropy on all data is 0.0112826\n",
      "After 1535 training step(s),cross entropy on all data is 0.0112762\n",
      "After 1536 training step(s),cross entropy on all data is 0.0112705\n",
      "After 1537 training step(s),cross entropy on all data is 0.0112612\n",
      "After 1538 training step(s),cross entropy on all data is 0.0112528\n",
      "After 1539 training step(s),cross entropy on all data is 0.0112452\n",
      "After 1540 training step(s),cross entropy on all data is 0.0112384\n",
      "After 1541 training step(s),cross entropy on all data is 0.0112323\n",
      "After 1542 training step(s),cross entropy on all data is 0.0112268\n",
      "After 1543 training step(s),cross entropy on all data is 0.0112175\n",
      "After 1544 training step(s),cross entropy on all data is 0.0112091\n",
      "After 1545 training step(s),cross entropy on all data is 0.0111972\n",
      "After 1546 training step(s),cross entropy on all data is 0.0111865\n",
      "After 1547 training step(s),cross entropy on all data is 0.0111769\n",
      "After 1548 training step(s),cross entropy on all data is 0.0111682\n",
      "After 1549 training step(s),cross entropy on all data is 0.0111604\n",
      "After 1550 training step(s),cross entropy on all data is 0.0111534\n",
      "After 1551 training step(s),cross entropy on all data is 0.011147\n",
      "After 1552 training step(s),cross entropy on all data is 0.0111413\n",
      "After 1553 training step(s),cross entropy on all data is 0.011132\n",
      "After 1554 training step(s),cross entropy on all data is 0.0111236\n",
      "After 1555 training step(s),cross entropy on all data is 0.011116\n",
      "After 1556 training step(s),cross entropy on all data is 0.0111092\n",
      "After 1557 training step(s),cross entropy on all data is 0.011103\n",
      "After 1558 training step(s),cross entropy on all data is 0.0110975\n",
      "After 1559 training step(s),cross entropy on all data is 0.0110882\n",
      "After 1560 training step(s),cross entropy on all data is 0.0110798\n",
      "After 1561 training step(s),cross entropy on all data is 0.0110679\n",
      "After 1562 training step(s),cross entropy on all data is 0.0110572\n",
      "After 1563 training step(s),cross entropy on all data is 0.0110475\n",
      "After 1564 training step(s),cross entropy on all data is 0.0110388\n",
      "After 1565 training step(s),cross entropy on all data is 0.011031\n",
      "After 1566 training step(s),cross entropy on all data is 0.011024\n",
      "After 1567 training step(s),cross entropy on all data is 0.0110176\n",
      "After 1568 training step(s),cross entropy on all data is 0.0110119\n",
      "After 1569 training step(s),cross entropy on all data is 0.0110025\n",
      "After 1570 training step(s),cross entropy on all data is 0.0109941\n",
      "After 1571 training step(s),cross entropy on all data is 0.0109865\n",
      "After 1572 training step(s),cross entropy on all data is 0.0109797\n",
      "After 1573 training step(s),cross entropy on all data is 0.0109735\n",
      "After 1574 training step(s),cross entropy on all data is 0.010968\n",
      "After 1575 training step(s),cross entropy on all data is 0.0109587\n",
      "After 1576 training step(s),cross entropy on all data is 0.0109503\n",
      "After 1577 training step(s),cross entropy on all data is 0.0109384\n",
      "After 1578 training step(s),cross entropy on all data is 0.0109276\n",
      "After 1579 training step(s),cross entropy on all data is 0.010918\n",
      "After 1580 training step(s),cross entropy on all data is 0.0109093\n",
      "After 1581 training step(s),cross entropy on all data is 0.0109014\n",
      "After 1582 training step(s),cross entropy on all data is 0.0108944\n",
      "After 1583 training step(s),cross entropy on all data is 0.010888\n",
      "After 1584 training step(s),cross entropy on all data is 0.0108823\n",
      "After 1585 training step(s),cross entropy on all data is 0.0108729\n",
      "After 1586 training step(s),cross entropy on all data is 0.0108645\n",
      "After 1587 training step(s),cross entropy on all data is 0.0108569\n",
      "After 1588 training step(s),cross entropy on all data is 0.01085\n",
      "After 1589 training step(s),cross entropy on all data is 0.0108439\n",
      "After 1590 training step(s),cross entropy on all data is 0.0108383\n",
      "After 1591 training step(s),cross entropy on all data is 0.010829\n",
      "After 1592 training step(s),cross entropy on all data is 0.0108206\n",
      "After 1593 training step(s),cross entropy on all data is 0.0108087\n",
      "After 1594 training step(s),cross entropy on all data is 0.0107979\n",
      "After 1595 training step(s),cross entropy on all data is 0.0107882\n",
      "After 1596 training step(s),cross entropy on all data is 0.0107795\n",
      "After 1597 training step(s),cross entropy on all data is 0.0107717\n",
      "After 1598 training step(s),cross entropy on all data is 0.0107646\n",
      "After 1599 training step(s),cross entropy on all data is 0.0107582\n",
      "After 1600 training step(s),cross entropy on all data is 0.0107525\n",
      "After 1601 training step(s),cross entropy on all data is 0.0107431\n",
      "After 1602 training step(s),cross entropy on all data is 0.0107347\n",
      "After 1603 training step(s),cross entropy on all data is 0.0107271\n",
      "After 1604 training step(s),cross entropy on all data is 0.0107202\n",
      "After 1605 training step(s),cross entropy on all data is 0.0107141\n",
      "After 1606 training step(s),cross entropy on all data is 0.0107085\n",
      "After 1607 training step(s),cross entropy on all data is 0.0106992\n",
      "After 1608 training step(s),cross entropy on all data is 0.0106908\n",
      "After 1609 training step(s),cross entropy on all data is 0.0106788\n",
      "After 1610 training step(s),cross entropy on all data is 0.010668\n",
      "After 1611 training step(s),cross entropy on all data is 0.0106583\n",
      "After 1612 training step(s),cross entropy on all data is 0.0106496\n",
      "After 1613 training step(s),cross entropy on all data is 0.0106418\n",
      "After 1614 training step(s),cross entropy on all data is 0.0106347\n",
      "After 1615 training step(s),cross entropy on all data is 0.0106283\n",
      "After 1616 training step(s),cross entropy on all data is 0.0106226\n",
      "After 1617 training step(s),cross entropy on all data is 0.0106132\n",
      "After 1618 training step(s),cross entropy on all data is 0.0106047\n",
      "After 1619 training step(s),cross entropy on all data is 0.0105971\n",
      "After 1620 training step(s),cross entropy on all data is 0.0105902\n",
      "After 1621 training step(s),cross entropy on all data is 0.0105841\n",
      "After 1622 training step(s),cross entropy on all data is 0.0105785\n",
      "After 1623 training step(s),cross entropy on all data is 0.0105692\n",
      "After 1624 training step(s),cross entropy on all data is 0.0105607\n",
      "After 1625 training step(s),cross entropy on all data is 0.0105488\n",
      "After 1626 training step(s),cross entropy on all data is 0.010538\n",
      "After 1627 training step(s),cross entropy on all data is 0.0105283\n",
      "After 1628 training step(s),cross entropy on all data is 0.0105196\n",
      "After 1629 training step(s),cross entropy on all data is 0.0105117\n",
      "After 1630 training step(s),cross entropy on all data is 0.0105046\n",
      "After 1631 training step(s),cross entropy on all data is 0.0104982\n",
      "After 1632 training step(s),cross entropy on all data is 0.0104925\n",
      "After 1633 training step(s),cross entropy on all data is 0.0104831\n",
      "After 1634 training step(s),cross entropy on all data is 0.0104746\n",
      "After 1635 training step(s),cross entropy on all data is 0.010467\n",
      "After 1636 training step(s),cross entropy on all data is 0.0104601\n",
      "After 1637 training step(s),cross entropy on all data is 0.0104539\n",
      "After 1638 training step(s),cross entropy on all data is 0.0104484\n",
      "After 1639 training step(s),cross entropy on all data is 0.010439\n",
      "After 1640 training step(s),cross entropy on all data is 0.0104313\n",
      "After 1641 training step(s),cross entropy on all data is 0.0104263\n",
      "After 1642 training step(s),cross entropy on all data is 0.0104217\n",
      "After 1643 training step(s),cross entropy on all data is 0.0104177\n",
      "After 1644 training step(s),cross entropy on all data is 0.010414\n",
      "After 1645 training step(s),cross entropy on all data is 0.0104107\n",
      "After 1646 training step(s),cross entropy on all data is 0.0104077\n",
      "After 1647 training step(s),cross entropy on all data is 0.010405\n",
      "After 1648 training step(s),cross entropy on all data is 0.0104026\n",
      "After 1649 training step(s),cross entropy on all data is 0.0103975\n",
      "After 1650 training step(s),cross entropy on all data is 0.0103929\n",
      "After 1651 training step(s),cross entropy on all data is 0.0103887\n",
      "After 1652 training step(s),cross entropy on all data is 0.010385\n",
      "After 1653 training step(s),cross entropy on all data is 0.0103817\n",
      "After 1654 training step(s),cross entropy on all data is 0.0103786\n",
      "After 1655 training step(s),cross entropy on all data is 0.0103731\n",
      "After 1656 training step(s),cross entropy on all data is 0.010368\n",
      "After 1657 training step(s),cross entropy on all data is 0.0103635\n",
      "After 1658 training step(s),cross entropy on all data is 0.0103594\n",
      "After 1659 training step(s),cross entropy on all data is 0.0103558\n",
      "After 1660 training step(s),cross entropy on all data is 0.0103524\n",
      "After 1661 training step(s),cross entropy on all data is 0.0103495\n",
      "After 1662 training step(s),cross entropy on all data is 0.0103468\n",
      "After 1663 training step(s),cross entropy on all data is 0.0103444\n",
      "After 1664 training step(s),cross entropy on all data is 0.0103422\n",
      "After 1665 training step(s),cross entropy on all data is 0.0103373\n",
      "After 1666 training step(s),cross entropy on all data is 0.0103329\n",
      "After 1667 training step(s),cross entropy on all data is 0.0103289\n",
      "After 1668 training step(s),cross entropy on all data is 0.0103254\n",
      "After 1669 training step(s),cross entropy on all data is 0.0103221\n",
      "After 1670 training step(s),cross entropy on all data is 0.0103192\n",
      "After 1671 training step(s),cross entropy on all data is 0.0103138\n",
      "After 1672 training step(s),cross entropy on all data is 0.0103088\n",
      "After 1673 training step(s),cross entropy on all data is 0.0103044\n",
      "After 1674 training step(s),cross entropy on all data is 0.0103004\n",
      "After 1675 training step(s),cross entropy on all data is 0.0102968\n",
      "After 1676 training step(s),cross entropy on all data is 0.0102935\n",
      "After 1677 training step(s),cross entropy on all data is 0.0102906\n",
      "After 1678 training step(s),cross entropy on all data is 0.010288\n",
      "After 1679 training step(s),cross entropy on all data is 0.0102856\n",
      "After 1680 training step(s),cross entropy on all data is 0.0102835\n",
      "After 1681 training step(s),cross entropy on all data is 0.0102786\n",
      "After 1682 training step(s),cross entropy on all data is 0.0102742\n",
      "After 1683 training step(s),cross entropy on all data is 0.0102702\n",
      "After 1684 training step(s),cross entropy on all data is 0.0102667\n",
      "After 1685 training step(s),cross entropy on all data is 0.0102635\n",
      "After 1686 training step(s),cross entropy on all data is 0.0102606\n",
      "After 1687 training step(s),cross entropy on all data is 0.0102551\n",
      "After 1688 training step(s),cross entropy on all data is 0.0102502\n",
      "After 1689 training step(s),cross entropy on all data is 0.0102457\n",
      "After 1690 training step(s),cross entropy on all data is 0.0102417\n",
      "After 1691 training step(s),cross entropy on all data is 0.0102381\n",
      "After 1692 training step(s),cross entropy on all data is 0.0102349\n",
      "After 1693 training step(s),cross entropy on all data is 0.010232\n",
      "After 1694 training step(s),cross entropy on all data is 0.0102293\n",
      "After 1695 training step(s),cross entropy on all data is 0.010227\n",
      "After 1696 training step(s),cross entropy on all data is 0.0102248\n",
      "After 1697 training step(s),cross entropy on all data is 0.0102199\n",
      "After 1698 training step(s),cross entropy on all data is 0.0102155\n",
      "After 1699 training step(s),cross entropy on all data is 0.0102116\n",
      "After 1700 training step(s),cross entropy on all data is 0.010208\n",
      "After 1701 training step(s),cross entropy on all data is 0.0102048\n",
      "After 1702 training step(s),cross entropy on all data is 0.0102019\n",
      "After 1703 training step(s),cross entropy on all data is 0.0101964\n",
      "After 1704 training step(s),cross entropy on all data is 0.0101915\n",
      "After 1705 training step(s),cross entropy on all data is 0.010187\n",
      "After 1706 training step(s),cross entropy on all data is 0.010183\n",
      "After 1707 training step(s),cross entropy on all data is 0.0101794\n",
      "After 1708 training step(s),cross entropy on all data is 0.0101761\n",
      "After 1709 training step(s),cross entropy on all data is 0.0101732\n",
      "After 1710 training step(s),cross entropy on all data is 0.0101706\n",
      "After 1711 training step(s),cross entropy on all data is 0.0101682\n",
      "After 1712 training step(s),cross entropy on all data is 0.010166\n",
      "After 1713 training step(s),cross entropy on all data is 0.0101612\n",
      "After 1714 training step(s),cross entropy on all data is 0.0101567\n",
      "After 1715 training step(s),cross entropy on all data is 0.0101528\n",
      "After 1716 training step(s),cross entropy on all data is 0.0101492\n",
      "After 1717 training step(s),cross entropy on all data is 0.010146\n",
      "After 1718 training step(s),cross entropy on all data is 0.0101431\n",
      "After 1719 training step(s),cross entropy on all data is 0.0101376\n",
      "After 1720 training step(s),cross entropy on all data is 0.0101326\n",
      "After 1721 training step(s),cross entropy on all data is 0.0101281\n",
      "After 1722 training step(s),cross entropy on all data is 0.0101241\n",
      "After 1723 training step(s),cross entropy on all data is 0.0101205\n",
      "After 1724 training step(s),cross entropy on all data is 0.0101172\n",
      "After 1725 training step(s),cross entropy on all data is 0.0101143\n",
      "After 1726 training step(s),cross entropy on all data is 0.0101116\n",
      "After 1727 training step(s),cross entropy on all data is 0.0101092\n",
      "After 1728 training step(s),cross entropy on all data is 0.0101071\n",
      "After 1729 training step(s),cross entropy on all data is 0.0101022\n",
      "After 1730 training step(s),cross entropy on all data is 0.0100977\n",
      "After 1731 training step(s),cross entropy on all data is 0.0100938\n",
      "After 1732 training step(s),cross entropy on all data is 0.0100902\n",
      "After 1733 training step(s),cross entropy on all data is 0.0100869\n",
      "After 1734 training step(s),cross entropy on all data is 0.010084\n",
      "After 1735 training step(s),cross entropy on all data is 0.0100785\n",
      "After 1736 training step(s),cross entropy on all data is 0.0100735\n",
      "After 1737 training step(s),cross entropy on all data is 0.010069\n",
      "After 1738 training step(s),cross entropy on all data is 0.010065\n",
      "After 1739 training step(s),cross entropy on all data is 0.0100613\n",
      "After 1740 training step(s),cross entropy on all data is 0.0100581\n",
      "After 1741 training step(s),cross entropy on all data is 0.0100551\n",
      "After 1742 training step(s),cross entropy on all data is 0.0100524\n",
      "After 1743 training step(s),cross entropy on all data is 0.0100501\n",
      "After 1744 training step(s),cross entropy on all data is 0.0100479\n",
      "After 1745 training step(s),cross entropy on all data is 0.010043\n",
      "After 1746 training step(s),cross entropy on all data is 0.0100385\n",
      "After 1747 training step(s),cross entropy on all data is 0.0100345\n",
      "After 1748 training step(s),cross entropy on all data is 0.0100309\n",
      "After 1749 training step(s),cross entropy on all data is 0.0100277\n",
      "After 1750 training step(s),cross entropy on all data is 0.0100248\n",
      "After 1751 training step(s),cross entropy on all data is 0.0100192\n",
      "After 1752 training step(s),cross entropy on all data is 0.0100142\n",
      "After 1753 training step(s),cross entropy on all data is 0.0100097\n",
      "After 1754 training step(s),cross entropy on all data is 0.0100056\n",
      "After 1755 training step(s),cross entropy on all data is 0.010002\n",
      "After 1756 training step(s),cross entropy on all data is 0.00999871\n",
      "After 1757 training step(s),cross entropy on all data is 0.00999574\n",
      "After 1758 training step(s),cross entropy on all data is 0.00999308\n",
      "After 1759 training step(s),cross entropy on all data is 0.00999067\n",
      "After 1760 training step(s),cross entropy on all data is 0.00998851\n",
      "After 1761 training step(s),cross entropy on all data is 0.00998356\n",
      "After 1762 training step(s),cross entropy on all data is 0.00997911\n",
      "After 1763 training step(s),cross entropy on all data is 0.0099751\n",
      "After 1764 training step(s),cross entropy on all data is 0.00997149\n",
      "After 1765 training step(s),cross entropy on all data is 0.00996823\n",
      "After 1766 training step(s),cross entropy on all data is 0.0099653\n",
      "After 1767 training step(s),cross entropy on all data is 0.00995973\n",
      "After 1768 training step(s),cross entropy on all data is 0.00995471\n",
      "After 1769 training step(s),cross entropy on all data is 0.00995019\n",
      "After 1770 training step(s),cross entropy on all data is 0.00994612\n",
      "After 1771 training step(s),cross entropy on all data is 0.00994246\n",
      "After 1772 training step(s),cross entropy on all data is 0.00993916\n",
      "After 1773 training step(s),cross entropy on all data is 0.00993618\n",
      "After 1774 training step(s),cross entropy on all data is 0.00993351\n",
      "After 1775 training step(s),cross entropy on all data is 0.0099311\n",
      "After 1776 training step(s),cross entropy on all data is 0.00992893\n",
      "After 1777 training step(s),cross entropy on all data is 0.00992397\n",
      "After 1778 training step(s),cross entropy on all data is 0.0099195\n",
      "After 1779 training step(s),cross entropy on all data is 0.00991547\n",
      "After 1780 training step(s),cross entropy on all data is 0.00991185\n",
      "After 1781 training step(s),cross entropy on all data is 0.00990859\n",
      "After 1782 training step(s),cross entropy on all data is 0.00990565\n",
      "After 1783 training step(s),cross entropy on all data is 0.00990005\n",
      "After 1784 training step(s),cross entropy on all data is 0.00989502\n",
      "After 1785 training step(s),cross entropy on all data is 0.00989048\n",
      "After 1786 training step(s),cross entropy on all data is 0.0098864\n",
      "After 1787 training step(s),cross entropy on all data is 0.00988272\n",
      "After 1788 training step(s),cross entropy on all data is 0.00987941\n",
      "After 1789 training step(s),cross entropy on all data is 0.00987643\n",
      "After 1790 training step(s),cross entropy on all data is 0.00987375\n",
      "After 1791 training step(s),cross entropy on all data is 0.00987133\n",
      "After 1792 training step(s),cross entropy on all data is 0.00986915\n",
      "After 1793 training step(s),cross entropy on all data is 0.00986417\n",
      "After 1794 training step(s),cross entropy on all data is 0.00985969\n",
      "After 1795 training step(s),cross entropy on all data is 0.00985565\n",
      "After 1796 training step(s),cross entropy on all data is 0.00985202\n",
      "After 1797 training step(s),cross entropy on all data is 0.00984874\n",
      "After 1798 training step(s),cross entropy on all data is 0.0098458\n",
      "After 1799 training step(s),cross entropy on all data is 0.00984018\n",
      "After 1800 training step(s),cross entropy on all data is 0.00983513\n",
      "After 1801 training step(s),cross entropy on all data is 0.00983058\n",
      "After 1802 training step(s),cross entropy on all data is 0.00982649\n",
      "After 1803 training step(s),cross entropy on all data is 0.00982279\n",
      "After 1804 training step(s),cross entropy on all data is 0.00981947\n",
      "After 1805 training step(s),cross entropy on all data is 0.00981648\n",
      "After 1806 training step(s),cross entropy on all data is 0.00981379\n",
      "After 1807 training step(s),cross entropy on all data is 0.00981136\n",
      "After 1808 training step(s),cross entropy on all data is 0.00980918\n",
      "After 1809 training step(s),cross entropy on all data is 0.00980418\n",
      "After 1810 training step(s),cross entropy on all data is 0.00979969\n",
      "After 1811 training step(s),cross entropy on all data is 0.00979564\n",
      "After 1812 training step(s),cross entropy on all data is 0.00979199\n",
      "After 1813 training step(s),cross entropy on all data is 0.00978871\n",
      "After 1814 training step(s),cross entropy on all data is 0.00978575\n",
      "After 1815 training step(s),cross entropy on all data is 0.00978012\n",
      "After 1816 training step(s),cross entropy on all data is 0.00977505\n",
      "After 1817 training step(s),cross entropy on all data is 0.00977048\n",
      "After 1818 training step(s),cross entropy on all data is 0.00976638\n",
      "After 1819 training step(s),cross entropy on all data is 0.00976267\n",
      "After 1820 training step(s),cross entropy on all data is 0.00975934\n",
      "After 1821 training step(s),cross entropy on all data is 0.00975634\n",
      "After 1822 training step(s),cross entropy on all data is 0.00975364\n",
      "After 1823 training step(s),cross entropy on all data is 0.00975121\n",
      "After 1824 training step(s),cross entropy on all data is 0.00974902\n",
      "After 1825 training step(s),cross entropy on all data is 0.009744\n",
      "After 1826 training step(s),cross entropy on all data is 0.00973949\n",
      "After 1827 training step(s),cross entropy on all data is 0.00973543\n",
      "After 1828 training step(s),cross entropy on all data is 0.00973177\n",
      "After 1829 training step(s),cross entropy on all data is 0.00972848\n",
      "After 1830 training step(s),cross entropy on all data is 0.00972551\n",
      "After 1831 training step(s),cross entropy on all data is 0.00971987\n",
      "After 1832 training step(s),cross entropy on all data is 0.00971478\n",
      "After 1833 training step(s),cross entropy on all data is 0.0097102\n",
      "After 1834 training step(s),cross entropy on all data is 0.00970608\n",
      "After 1835 training step(s),cross entropy on all data is 0.00970236\n",
      "After 1836 training step(s),cross entropy on all data is 0.00969902\n",
      "After 1837 training step(s),cross entropy on all data is 0.00969601\n",
      "After 1838 training step(s),cross entropy on all data is 0.0096933\n",
      "After 1839 training step(s),cross entropy on all data is 0.00969086\n",
      "After 1840 training step(s),cross entropy on all data is 0.00968866\n",
      "After 1841 training step(s),cross entropy on all data is 0.00968364\n",
      "After 1842 training step(s),cross entropy on all data is 0.00967911\n",
      "After 1843 training step(s),cross entropy on all data is 0.00967504\n",
      "After 1844 training step(s),cross entropy on all data is 0.00967137\n",
      "After 1845 training step(s),cross entropy on all data is 0.00966807\n",
      "After 1846 training step(s),cross entropy on all data is 0.00966509\n",
      "After 1847 training step(s),cross entropy on all data is 0.00965942\n",
      "After 1848 training step(s),cross entropy on all data is 0.00965432\n",
      "After 1849 training step(s),cross entropy on all data is 0.00964973\n",
      "After 1850 training step(s),cross entropy on all data is 0.00964559\n",
      "After 1851 training step(s),cross entropy on all data is 0.00964187\n",
      "After 1852 training step(s),cross entropy on all data is 0.00963852\n",
      "After 1853 training step(s),cross entropy on all data is 0.0096355\n",
      "After 1854 training step(s),cross entropy on all data is 0.00963278\n",
      "After 1855 training step(s),cross entropy on all data is 0.00963033\n",
      "After 1856 training step(s),cross entropy on all data is 0.00962812\n",
      "After 1857 training step(s),cross entropy on all data is 0.00962308\n",
      "After 1858 training step(s),cross entropy on all data is 0.00961855\n",
      "After 1859 training step(s),cross entropy on all data is 0.00961446\n",
      "After 1860 training step(s),cross entropy on all data is 0.00961078\n",
      "After 1861 training step(s),cross entropy on all data is 0.00960747\n",
      "After 1862 training step(s),cross entropy on all data is 0.00960448\n",
      "After 1863 training step(s),cross entropy on all data is 0.0095988\n",
      "After 1864 training step(s),cross entropy on all data is 0.00959368\n",
      "After 1865 training step(s),cross entropy on all data is 0.00958908\n",
      "After 1866 training step(s),cross entropy on all data is 0.00958493\n",
      "After 1867 training step(s),cross entropy on all data is 0.00958119\n",
      "After 1868 training step(s),cross entropy on all data is 0.00957783\n",
      "After 1869 training step(s),cross entropy on all data is 0.0095748\n",
      "After 1870 training step(s),cross entropy on all data is 0.00957207\n",
      "After 1871 training step(s),cross entropy on all data is 0.00956962\n",
      "After 1872 training step(s),cross entropy on all data is 0.0095674\n",
      "After 1873 training step(s),cross entropy on all data is 0.00956235\n",
      "After 1874 training step(s),cross entropy on all data is 0.0095578\n",
      "After 1875 training step(s),cross entropy on all data is 0.0095537\n",
      "After 1876 training step(s),cross entropy on all data is 0.00955001\n",
      "After 1877 training step(s),cross entropy on all data is 0.00954669\n",
      "After 1878 training step(s),cross entropy on all data is 0.00954369\n",
      "After 1879 training step(s),cross entropy on all data is 0.00953799\n",
      "After 1880 training step(s),cross entropy on all data is 0.00953286\n",
      "After 1881 training step(s),cross entropy on all data is 0.00952824\n",
      "After 1882 training step(s),cross entropy on all data is 0.00952408\n",
      "After 1883 training step(s),cross entropy on all data is 0.00952033\n",
      "After 1884 training step(s),cross entropy on all data is 0.00951696\n",
      "After 1885 training step(s),cross entropy on all data is 0.00951392\n",
      "After 1886 training step(s),cross entropy on all data is 0.00951119\n",
      "After 1887 training step(s),cross entropy on all data is 0.00950872\n",
      "After 1888 training step(s),cross entropy on all data is 0.00950651\n",
      "After 1889 training step(s),cross entropy on all data is 0.00950144\n",
      "After 1890 training step(s),cross entropy on all data is 0.00949687\n",
      "After 1891 training step(s),cross entropy on all data is 0.00949276\n",
      "After 1892 training step(s),cross entropy on all data is 0.00948906\n",
      "After 1893 training step(s),cross entropy on all data is 0.00948573\n",
      "After 1894 training step(s),cross entropy on all data is 0.00948273\n",
      "After 1895 training step(s),cross entropy on all data is 0.00947701\n",
      "After 1896 training step(s),cross entropy on all data is 0.00947187\n",
      "After 1897 training step(s),cross entropy on all data is 0.00946723\n",
      "After 1898 training step(s),cross entropy on all data is 0.00946306\n",
      "After 1899 training step(s),cross entropy on all data is 0.0094593\n",
      "After 1900 training step(s),cross entropy on all data is 0.00945592\n",
      "After 1901 training step(s),cross entropy on all data is 0.00945287\n",
      "After 1902 training step(s),cross entropy on all data is 0.00945013\n",
      "After 1903 training step(s),cross entropy on all data is 0.00944766\n",
      "After 1904 training step(s),cross entropy on all data is 0.00944543\n",
      "After 1905 training step(s),cross entropy on all data is 0.00944035\n",
      "After 1906 training step(s),cross entropy on all data is 0.00943577\n",
      "After 1907 training step(s),cross entropy on all data is 0.00943165\n",
      "After 1908 training step(s),cross entropy on all data is 0.00942794\n",
      "After 1909 training step(s),cross entropy on all data is 0.0094246\n",
      "After 1910 training step(s),cross entropy on all data is 0.00942159\n",
      "After 1911 training step(s),cross entropy on all data is 0.00941586\n",
      "After 1912 training step(s),cross entropy on all data is 0.0094107\n",
      "After 1913 training step(s),cross entropy on all data is 0.00940605\n",
      "After 1914 training step(s),cross entropy on all data is 0.00940187\n",
      "After 1915 training step(s),cross entropy on all data is 0.0093981\n",
      "After 1916 training step(s),cross entropy on all data is 0.0093947\n",
      "After 1917 training step(s),cross entropy on all data is 0.00939165\n",
      "After 1918 training step(s),cross entropy on all data is 0.0093889\n",
      "After 1919 training step(s),cross entropy on all data is 0.00938642\n",
      "After 1920 training step(s),cross entropy on all data is 0.00938419\n",
      "After 1921 training step(s),cross entropy on all data is 0.00937909\n",
      "After 1922 training step(s),cross entropy on all data is 0.0093745\n",
      "After 1923 training step(s),cross entropy on all data is 0.00937037\n",
      "After 1924 training step(s),cross entropy on all data is 0.00936665\n",
      "After 1925 training step(s),cross entropy on all data is 0.0093633\n",
      "After 1926 training step(s),cross entropy on all data is 0.00936028\n",
      "After 1927 training step(s),cross entropy on all data is 0.00935453\n",
      "After 1928 training step(s),cross entropy on all data is 0.00934936\n",
      "After 1929 training step(s),cross entropy on all data is 0.0093447\n",
      "After 1930 training step(s),cross entropy on all data is 0.0093405\n",
      "After 1931 training step(s),cross entropy on all data is 0.00933672\n",
      "After 1932 training step(s),cross entropy on all data is 0.00933332\n",
      "After 1933 training step(s),cross entropy on all data is 0.00933025\n",
      "After 1934 training step(s),cross entropy on all data is 0.0093275\n",
      "After 1935 training step(s),cross entropy on all data is 0.00932501\n",
      "After 1936 training step(s),cross entropy on all data is 0.00932278\n",
      "After 1937 training step(s),cross entropy on all data is 0.00931766\n",
      "After 1938 training step(s),cross entropy on all data is 0.00931306\n",
      "After 1939 training step(s),cross entropy on all data is 0.00930892\n",
      "After 1940 training step(s),cross entropy on all data is 0.00930519\n",
      "After 1941 training step(s),cross entropy on all data is 0.00930183\n",
      "After 1942 training step(s),cross entropy on all data is 0.0092988\n",
      "After 1943 training step(s),cross entropy on all data is 0.00929304\n",
      "After 1944 training step(s),cross entropy on all data is 0.00928785\n",
      "After 1945 training step(s),cross entropy on all data is 0.00928317\n",
      "After 1946 training step(s),cross entropy on all data is 0.00927896\n",
      "After 1947 training step(s),cross entropy on all data is 0.00927517\n",
      "After 1948 training step(s),cross entropy on all data is 0.00927176\n",
      "After 1949 training step(s),cross entropy on all data is 0.00926869\n",
      "After 1950 training step(s),cross entropy on all data is 0.00926592\n",
      "After 1951 training step(s),cross entropy on all data is 0.00926343\n",
      "After 1952 training step(s),cross entropy on all data is 0.00926119\n",
      "After 1953 training step(s),cross entropy on all data is 0.00925607\n",
      "After 1954 training step(s),cross entropy on all data is 0.00925145\n",
      "After 1955 training step(s),cross entropy on all data is 0.0092473\n",
      "After 1956 training step(s),cross entropy on all data is 0.00924356\n",
      "After 1957 training step(s),cross entropy on all data is 0.00924019\n",
      "After 1958 training step(s),cross entropy on all data is 0.00923716\n",
      "After 1959 training step(s),cross entropy on all data is 0.00923138\n",
      "After 1960 training step(s),cross entropy on all data is 0.00922617\n",
      "After 1961 training step(s),cross entropy on all data is 0.00922149\n",
      "After 1962 training step(s),cross entropy on all data is 0.00921727\n",
      "After 1963 training step(s),cross entropy on all data is 0.00921347\n",
      "After 1964 training step(s),cross entropy on all data is 0.00921004\n",
      "After 1965 training step(s),cross entropy on all data is 0.00920696\n",
      "After 1966 training step(s),cross entropy on all data is 0.00920419\n",
      "After 1967 training step(s),cross entropy on all data is 0.00920169\n",
      "After 1968 training step(s),cross entropy on all data is 0.00919944\n",
      "After 1969 training step(s),cross entropy on all data is 0.00919431\n",
      "After 1970 training step(s),cross entropy on all data is 0.00918968\n",
      "After 1971 training step(s),cross entropy on all data is 0.00918552\n",
      "After 1972 training step(s),cross entropy on all data is 0.00918177\n",
      "After 1973 training step(s),cross entropy on all data is 0.00917839\n",
      "After 1974 training step(s),cross entropy on all data is 0.00917535\n",
      "After 1975 training step(s),cross entropy on all data is 0.00916955\n",
      "After 1976 training step(s),cross entropy on all data is 0.00916433\n",
      "After 1977 training step(s),cross entropy on all data is 0.00915964\n",
      "After 1978 training step(s),cross entropy on all data is 0.0091554\n",
      "After 1979 training step(s),cross entropy on all data is 0.0091516\n",
      "After 1980 training step(s),cross entropy on all data is 0.00914817\n",
      "After 1981 training step(s),cross entropy on all data is 0.00914508\n",
      "After 1982 training step(s),cross entropy on all data is 0.0091423\n",
      "After 1983 training step(s),cross entropy on all data is 0.00913979\n",
      "After 1984 training step(s),cross entropy on all data is 0.00913754\n",
      "After 1985 training step(s),cross entropy on all data is 0.00913239\n",
      "After 1986 training step(s),cross entropy on all data is 0.00912775\n",
      "After 1987 training step(s),cross entropy on all data is 0.00912357\n",
      "After 1988 training step(s),cross entropy on all data is 0.00911982\n",
      "After 1989 training step(s),cross entropy on all data is 0.00911643\n",
      "After 1990 training step(s),cross entropy on all data is 0.00911338\n",
      "After 1991 training step(s),cross entropy on all data is 0.00910757\n",
      "After 1992 training step(s),cross entropy on all data is 0.00910234\n",
      "After 1993 training step(s),cross entropy on all data is 0.00909763\n",
      "After 1994 training step(s),cross entropy on all data is 0.00909339\n",
      "After 1995 training step(s),cross entropy on all data is 0.00908957\n",
      "After 1996 training step(s),cross entropy on all data is 0.00908613\n",
      "After 1997 training step(s),cross entropy on all data is 0.00908303\n",
      "After 1998 training step(s),cross entropy on all data is 0.00908025\n",
      "After 1999 training step(s),cross entropy on all data is 0.00907774\n",
      "After 2000 training step(s),cross entropy on all data is 0.00907547\n",
      "After 2001 training step(s),cross entropy on all data is 0.00907031\n",
      "After 2002 training step(s),cross entropy on all data is 0.00906566\n",
      "After 2003 training step(s),cross entropy on all data is 0.00906148\n",
      "After 2004 training step(s),cross entropy on all data is 0.00905771\n",
      "After 2005 training step(s),cross entropy on all data is 0.00905432\n",
      "After 2006 training step(s),cross entropy on all data is 0.00905126\n",
      "After 2007 training step(s),cross entropy on all data is 0.00904544\n",
      "After 2008 training step(s),cross entropy on all data is 0.00904019\n",
      "After 2009 training step(s),cross entropy on all data is 0.00903547\n",
      "After 2010 training step(s),cross entropy on all data is 0.00903122\n",
      "After 2011 training step(s),cross entropy on all data is 0.00902739\n",
      "After 2012 training step(s),cross entropy on all data is 0.00902394\n",
      "After 2013 training step(s),cross entropy on all data is 0.00902084\n",
      "After 2014 training step(s),cross entropy on all data is 0.00901804\n",
      "After 2015 training step(s),cross entropy on all data is 0.00901552\n",
      "After 2016 training step(s),cross entropy on all data is 0.00901325\n",
      "After 2017 training step(s),cross entropy on all data is 0.00900808\n",
      "After 2018 training step(s),cross entropy on all data is 0.00900342\n",
      "After 2019 training step(s),cross entropy on all data is 0.00899923\n",
      "After 2020 training step(s),cross entropy on all data is 0.00899545\n",
      "After 2021 training step(s),cross entropy on all data is 0.00899205\n",
      "After 2022 training step(s),cross entropy on all data is 0.00898898\n",
      "After 2023 training step(s),cross entropy on all data is 0.00898314\n",
      "After 2024 training step(s),cross entropy on all data is 0.00897789\n",
      "After 2025 training step(s),cross entropy on all data is 0.00897315\n",
      "After 2026 training step(s),cross entropy on all data is 0.00896889\n",
      "After 2027 training step(s),cross entropy on all data is 0.00896505\n",
      "After 2028 training step(s),cross entropy on all data is 0.00896159\n",
      "After 2029 training step(s),cross entropy on all data is 0.00895848\n",
      "After 2030 training step(s),cross entropy on all data is 0.00895568\n",
      "After 2031 training step(s),cross entropy on all data is 0.00895316\n",
      "After 2032 training step(s),cross entropy on all data is 0.00895088\n",
      "After 2033 training step(s),cross entropy on all data is 0.0089457\n",
      "After 2034 training step(s),cross entropy on all data is 0.00894103\n",
      "After 2035 training step(s),cross entropy on all data is 0.00893682\n",
      "After 2036 training step(s),cross entropy on all data is 0.00893303\n",
      "After 2037 training step(s),cross entropy on all data is 0.00892963\n",
      "After 2038 training step(s),cross entropy on all data is 0.00892656\n",
      "After 2039 training step(s),cross entropy on all data is 0.0089207\n",
      "After 2040 training step(s),cross entropy on all data is 0.00891543\n",
      "After 2041 training step(s),cross entropy on all data is 0.00891068\n",
      "After 2042 training step(s),cross entropy on all data is 0.00890641\n",
      "After 2043 training step(s),cross entropy on all data is 0.00890256\n",
      "After 2044 training step(s),cross entropy on all data is 0.0088991\n",
      "After 2045 training step(s),cross entropy on all data is 0.00889598\n",
      "After 2046 training step(s),cross entropy on all data is 0.00889317\n",
      "After 2047 training step(s),cross entropy on all data is 0.00889064\n",
      "After 2048 training step(s),cross entropy on all data is 0.00888836\n",
      "After 2049 training step(s),cross entropy on all data is 0.00888316\n",
      "After 2050 training step(s),cross entropy on all data is 0.00887848\n",
      "After 2051 training step(s),cross entropy on all data is 0.00887427\n",
      "After 2052 training step(s),cross entropy on all data is 0.00887047\n",
      "After 2053 training step(s),cross entropy on all data is 0.00886705\n",
      "After 2054 training step(s),cross entropy on all data is 0.00886398\n",
      "After 2055 training step(s),cross entropy on all data is 0.00885811\n",
      "After 2056 training step(s),cross entropy on all data is 0.00885283\n",
      "After 2057 training step(s),cross entropy on all data is 0.00884807\n",
      "After 2058 training step(s),cross entropy on all data is 0.00884379\n",
      "After 2059 training step(s),cross entropy on all data is 0.00883993\n",
      "After 2060 training step(s),cross entropy on all data is 0.00883646\n",
      "After 2061 training step(s),cross entropy on all data is 0.00883333\n",
      "After 2062 training step(s),cross entropy on all data is 0.00883051\n",
      "After 2063 training step(s),cross entropy on all data is 0.00882798\n",
      "After 2064 training step(s),cross entropy on all data is 0.0088257\n",
      "After 2065 training step(s),cross entropy on all data is 0.00882048\n",
      "After 2066 training step(s),cross entropy on all data is 0.00881579\n",
      "After 2067 training step(s),cross entropy on all data is 0.00881157\n",
      "After 2068 training step(s),cross entropy on all data is 0.00880777\n",
      "After 2069 training step(s),cross entropy on all data is 0.00880434\n",
      "After 2070 training step(s),cross entropy on all data is 0.00880126\n",
      "After 2071 training step(s),cross entropy on all data is 0.00879538\n",
      "After 2072 training step(s),cross entropy on all data is 0.00879008\n",
      "After 2073 training step(s),cross entropy on all data is 0.00878531\n",
      "After 2074 training step(s),cross entropy on all data is 0.00878102\n",
      "After 2075 training step(s),cross entropy on all data is 0.00877715\n",
      "After 2076 training step(s),cross entropy on all data is 0.00877367\n",
      "After 2077 training step(s),cross entropy on all data is 0.00877054\n",
      "After 2078 training step(s),cross entropy on all data is 0.00876772\n",
      "After 2079 training step(s),cross entropy on all data is 0.00876518\n",
      "After 2080 training step(s),cross entropy on all data is 0.00876289\n",
      "After 2081 training step(s),cross entropy on all data is 0.00875767\n",
      "After 2082 training step(s),cross entropy on all data is 0.00875297\n",
      "After 2083 training step(s),cross entropy on all data is 0.00874873\n",
      "After 2084 training step(s),cross entropy on all data is 0.00874492\n",
      "After 2085 training step(s),cross entropy on all data is 0.00874149\n",
      "After 2086 training step(s),cross entropy on all data is 0.0087384\n",
      "After 2087 training step(s),cross entropy on all data is 0.0087325\n",
      "After 2088 training step(s),cross entropy on all data is 0.00872719\n",
      "After 2089 training step(s),cross entropy on all data is 0.00872242\n",
      "After 2090 training step(s),cross entropy on all data is 0.00871811\n",
      "After 2091 training step(s),cross entropy on all data is 0.00871424\n",
      "After 2092 training step(s),cross entropy on all data is 0.00871075\n",
      "After 2093 training step(s),cross entropy on all data is 0.00870761\n",
      "After 2094 training step(s),cross entropy on all data is 0.00870478\n",
      "After 2095 training step(s),cross entropy on all data is 0.00870223\n",
      "After 2096 training step(s),cross entropy on all data is 0.00869994\n",
      "After 2097 training step(s),cross entropy on all data is 0.00869471\n",
      "After 2098 training step(s),cross entropy on all data is 0.00868999\n",
      "After 2099 training step(s),cross entropy on all data is 0.00868575\n",
      "After 2100 training step(s),cross entropy on all data is 0.00868193\n",
      "After 2101 training step(s),cross entropy on all data is 0.00867849\n",
      "After 2102 training step(s),cross entropy on all data is 0.0086754\n",
      "After 2103 training step(s),cross entropy on all data is 0.00866949\n",
      "After 2104 training step(s),cross entropy on all data is 0.00866417\n",
      "After 2105 training step(s),cross entropy on all data is 0.00865938\n",
      "After 2106 training step(s),cross entropy on all data is 0.00865507\n",
      "After 2107 training step(s),cross entropy on all data is 0.00865118\n",
      "After 2108 training step(s),cross entropy on all data is 0.00864768\n",
      "After 2109 training step(s),cross entropy on all data is 0.00864454\n",
      "After 2110 training step(s),cross entropy on all data is 0.0086417\n",
      "After 2111 training step(s),cross entropy on all data is 0.00863915\n",
      "After 2112 training step(s),cross entropy on all data is 0.00863685\n",
      "After 2113 training step(s),cross entropy on all data is 0.00863161\n",
      "After 2114 training step(s),cross entropy on all data is 0.00862688\n",
      "After 2115 training step(s),cross entropy on all data is 0.00862264\n",
      "After 2116 training step(s),cross entropy on all data is 0.00861881\n",
      "After 2117 training step(s),cross entropy on all data is 0.00861536\n",
      "After 2118 training step(s),cross entropy on all data is 0.00861226\n",
      "After 2119 training step(s),cross entropy on all data is 0.00860634\n",
      "After 2120 training step(s),cross entropy on all data is 0.00860101\n",
      "After 2121 training step(s),cross entropy on all data is 0.00859621\n",
      "After 2122 training step(s),cross entropy on all data is 0.00859188\n",
      "After 2123 training step(s),cross entropy on all data is 0.00858799\n",
      "After 2124 training step(s),cross entropy on all data is 0.00858449\n",
      "After 2125 training step(s),cross entropy on all data is 0.00858133\n",
      "After 2126 training step(s),cross entropy on all data is 0.00857849\n",
      "After 2127 training step(s),cross entropy on all data is 0.00857593\n",
      "After 2128 training step(s),cross entropy on all data is 0.00857363\n",
      "After 2129 training step(s),cross entropy on all data is 0.00856837\n",
      "After 2130 training step(s),cross entropy on all data is 0.00856364\n",
      "After 2131 training step(s),cross entropy on all data is 0.00855938\n",
      "After 2132 training step(s),cross entropy on all data is 0.00855555\n",
      "After 2133 training step(s),cross entropy on all data is 0.0085521\n",
      "After 2134 training step(s),cross entropy on all data is 0.00854899\n",
      "After 2135 training step(s),cross entropy on all data is 0.00854305\n",
      "After 2136 training step(s),cross entropy on all data is 0.00853771\n",
      "After 2137 training step(s),cross entropy on all data is 0.0085329\n",
      "After 2138 training step(s),cross entropy on all data is 0.00852857\n",
      "After 2139 training step(s),cross entropy on all data is 0.00852467\n",
      "After 2140 training step(s),cross entropy on all data is 0.00852116\n",
      "After 2141 training step(s),cross entropy on all data is 0.008518\n",
      "After 2142 training step(s),cross entropy on all data is 0.00851515\n",
      "After 2143 training step(s),cross entropy on all data is 0.00851258\n",
      "After 2144 training step(s),cross entropy on all data is 0.00851027\n",
      "After 2145 training step(s),cross entropy on all data is 0.00850501\n",
      "After 2146 training step(s),cross entropy on all data is 0.00850027\n",
      "After 2147 training step(s),cross entropy on all data is 0.00849601\n",
      "After 2148 training step(s),cross entropy on all data is 0.00849216\n",
      "After 2149 training step(s),cross entropy on all data is 0.0084887\n",
      "After 2150 training step(s),cross entropy on all data is 0.00848558\n",
      "After 2151 training step(s),cross entropy on all data is 0.00847964\n",
      "After 2152 training step(s),cross entropy on all data is 0.00847429\n",
      "After 2153 training step(s),cross entropy on all data is 0.00846947\n",
      "After 2154 training step(s),cross entropy on all data is 0.00846513\n",
      "After 2155 training step(s),cross entropy on all data is 0.00846122\n",
      "After 2156 training step(s),cross entropy on all data is 0.0084577\n",
      "After 2157 training step(s),cross entropy on all data is 0.00845453\n",
      "After 2158 training step(s),cross entropy on all data is 0.00845168\n",
      "After 2159 training step(s),cross entropy on all data is 0.00844911\n",
      "After 2160 training step(s),cross entropy on all data is 0.0084468\n",
      "After 2161 training step(s),cross entropy on all data is 0.00844152\n",
      "After 2162 training step(s),cross entropy on all data is 0.00843677\n",
      "After 2163 training step(s),cross entropy on all data is 0.0084325\n",
      "After 2164 training step(s),cross entropy on all data is 0.00842865\n",
      "After 2165 training step(s),cross entropy on all data is 0.00842518\n",
      "After 2166 training step(s),cross entropy on all data is 0.00842206\n",
      "After 2167 training step(s),cross entropy on all data is 0.0084161\n",
      "After 2168 training step(s),cross entropy on all data is 0.00841074\n",
      "After 2169 training step(s),cross entropy on all data is 0.00840591\n",
      "After 2170 training step(s),cross entropy on all data is 0.00840156\n",
      "After 2171 training step(s),cross entropy on all data is 0.00839764\n",
      "After 2172 training step(s),cross entropy on all data is 0.00839411\n",
      "After 2173 training step(s),cross entropy on all data is 0.00839094\n",
      "After 2174 training step(s),cross entropy on all data is 0.00838808\n",
      "After 2175 training step(s),cross entropy on all data is 0.00838551\n",
      "After 2176 training step(s),cross entropy on all data is 0.00838319\n",
      "After 2177 training step(s),cross entropy on all data is 0.0083779\n",
      "After 2178 training step(s),cross entropy on all data is 0.00837314\n",
      "After 2179 training step(s),cross entropy on all data is 0.00836886\n",
      "After 2180 training step(s),cross entropy on all data is 0.008365\n",
      "After 2181 training step(s),cross entropy on all data is 0.00836153\n",
      "After 2182 training step(s),cross entropy on all data is 0.0083584\n",
      "After 2183 training step(s),cross entropy on all data is 0.00835243\n",
      "After 2184 training step(s),cross entropy on all data is 0.00834706\n",
      "After 2185 training step(s),cross entropy on all data is 0.00834222\n",
      "After 2186 training step(s),cross entropy on all data is 0.00833786\n",
      "After 2187 training step(s),cross entropy on all data is 0.00833394\n",
      "After 2188 training step(s),cross entropy on all data is 0.0083304\n",
      "After 2189 training step(s),cross entropy on all data is 0.00832722\n",
      "After 2190 training step(s),cross entropy on all data is 0.00832436\n",
      "After 2191 training step(s),cross entropy on all data is 0.00832178\n",
      "After 2192 training step(s),cross entropy on all data is 0.00831946\n",
      "After 2193 training step(s),cross entropy on all data is 0.00831416\n",
      "After 2194 training step(s),cross entropy on all data is 0.00830939\n",
      "After 2195 training step(s),cross entropy on all data is 0.0083051\n",
      "After 2196 training step(s),cross entropy on all data is 0.00830124\n",
      "After 2197 training step(s),cross entropy on all data is 0.00829776\n",
      "After 2198 training step(s),cross entropy on all data is 0.00829462\n",
      "After 2199 training step(s),cross entropy on all data is 0.00828864\n",
      "After 2200 training step(s),cross entropy on all data is 0.00828326\n",
      "After 2201 training step(s),cross entropy on all data is 0.00827841\n",
      "After 2202 training step(s),cross entropy on all data is 0.00827404\n",
      "After 2203 training step(s),cross entropy on all data is 0.00827011\n",
      "After 2204 training step(s),cross entropy on all data is 0.00826657\n",
      "After 2205 training step(s),cross entropy on all data is 0.00826338\n",
      "After 2206 training step(s),cross entropy on all data is 0.00826052\n",
      "After 2207 training step(s),cross entropy on all data is 0.00825793\n",
      "After 2208 training step(s),cross entropy on all data is 0.0082556\n",
      "After 2209 training step(s),cross entropy on all data is 0.0082503\n",
      "After 2210 training step(s),cross entropy on all data is 0.00824552\n",
      "After 2211 training step(s),cross entropy on all data is 0.00824122\n",
      "After 2212 training step(s),cross entropy on all data is 0.00823735\n",
      "After 2213 training step(s),cross entropy on all data is 0.00823387\n",
      "After 2214 training step(s),cross entropy on all data is 0.00823073\n",
      "After 2215 training step(s),cross entropy on all data is 0.00822473\n",
      "After 2216 training step(s),cross entropy on all data is 0.00821934\n",
      "After 2217 training step(s),cross entropy on all data is 0.00821448\n",
      "After 2218 training step(s),cross entropy on all data is 0.00821011\n",
      "After 2219 training step(s),cross entropy on all data is 0.00820617\n",
      "After 2220 training step(s),cross entropy on all data is 0.00820262\n",
      "After 2221 training step(s),cross entropy on all data is 0.00819943\n",
      "After 2222 training step(s),cross entropy on all data is 0.00819655\n",
      "After 2223 training step(s),cross entropy on all data is 0.00819396\n",
      "After 2224 training step(s),cross entropy on all data is 0.00819163\n",
      "After 2225 training step(s),cross entropy on all data is 0.00818632\n",
      "After 2226 training step(s),cross entropy on all data is 0.00818154\n",
      "After 2227 training step(s),cross entropy on all data is 0.00817723\n",
      "After 2228 training step(s),cross entropy on all data is 0.00817335\n",
      "After 2229 training step(s),cross entropy on all data is 0.00816986\n",
      "After 2230 training step(s),cross entropy on all data is 0.00816671\n",
      "After 2231 training step(s),cross entropy on all data is 0.00816071\n",
      "After 2232 training step(s),cross entropy on all data is 0.00815531\n",
      "After 2233 training step(s),cross entropy on all data is 0.00815044\n",
      "After 2234 training step(s),cross entropy on all data is 0.00814606\n",
      "After 2235 training step(s),cross entropy on all data is 0.00814211\n",
      "After 2236 training step(s),cross entropy on all data is 0.00813856\n",
      "After 2237 training step(s),cross entropy on all data is 0.00813536\n",
      "After 2238 training step(s),cross entropy on all data is 0.00813248\n",
      "After 2239 training step(s),cross entropy on all data is 0.00812989\n",
      "After 2240 training step(s),cross entropy on all data is 0.00812755\n",
      "After 2241 training step(s),cross entropy on all data is 0.00812223\n",
      "After 2242 training step(s),cross entropy on all data is 0.00811744\n",
      "After 2243 training step(s),cross entropy on all data is 0.00811312\n",
      "After 2244 training step(s),cross entropy on all data is 0.00810923\n",
      "After 2245 training step(s),cross entropy on all data is 0.00810574\n",
      "After 2246 training step(s),cross entropy on all data is 0.00810259\n",
      "After 2247 training step(s),cross entropy on all data is 0.00809657\n",
      "After 2248 training step(s),cross entropy on all data is 0.00809116\n",
      "After 2249 training step(s),cross entropy on all data is 0.00808628\n",
      "After 2250 training step(s),cross entropy on all data is 0.00808189\n",
      "After 2251 training step(s),cross entropy on all data is 0.00807794\n",
      "After 2252 training step(s),cross entropy on all data is 0.00807438\n",
      "After 2253 training step(s),cross entropy on all data is 0.00807117\n",
      "After 2254 training step(s),cross entropy on all data is 0.00806829\n",
      "After 2255 training step(s),cross entropy on all data is 0.00806569\n",
      "After 2256 training step(s),cross entropy on all data is 0.00806335\n",
      "After 2257 training step(s),cross entropy on all data is 0.00805802\n",
      "After 2258 training step(s),cross entropy on all data is 0.00805322\n",
      "After 2259 training step(s),cross entropy on all data is 0.0080489\n",
      "After 2260 training step(s),cross entropy on all data is 0.008045\n",
      "After 2261 training step(s),cross entropy on all data is 0.0080415\n",
      "After 2262 training step(s),cross entropy on all data is 0.00803834\n",
      "After 2263 training step(s),cross entropy on all data is 0.00803232\n",
      "After 2264 training step(s),cross entropy on all data is 0.0080269\n",
      "After 2265 training step(s),cross entropy on all data is 0.00802201\n",
      "After 2266 training step(s),cross entropy on all data is 0.00801761\n",
      "After 2267 training step(s),cross entropy on all data is 0.00801365\n",
      "After 2268 training step(s),cross entropy on all data is 0.00801009\n",
      "After 2269 training step(s),cross entropy on all data is 0.00800688\n",
      "After 2270 training step(s),cross entropy on all data is 0.00800399\n",
      "After 2271 training step(s),cross entropy on all data is 0.00800139\n",
      "After 2272 training step(s),cross entropy on all data is 0.00799904\n",
      "After 2273 training step(s),cross entropy on all data is 0.0079937\n",
      "After 2274 training step(s),cross entropy on all data is 0.00798889\n",
      "After 2275 training step(s),cross entropy on all data is 0.00798538\n",
      "After 2276 training step(s),cross entropy on all data is 0.00798348\n",
      "After 2277 training step(s),cross entropy on all data is 0.00798176\n",
      "After 2278 training step(s),cross entropy on all data is 0.00798022\n",
      "After 2279 training step(s),cross entropy on all data is 0.00797719\n",
      "After 2280 training step(s),cross entropy on all data is 0.00797446\n",
      "After 2281 training step(s),cross entropy on all data is 0.007972\n",
      "After 2282 training step(s),cross entropy on all data is 0.00796979\n",
      "After 2283 training step(s),cross entropy on all data is 0.0079678\n",
      "After 2284 training step(s),cross entropy on all data is 0.00796601\n",
      "After 2285 training step(s),cross entropy on all data is 0.00796439\n",
      "After 2286 training step(s),cross entropy on all data is 0.00796294\n",
      "After 2287 training step(s),cross entropy on all data is 0.00796163\n",
      "After 2288 training step(s),cross entropy on all data is 0.00796045\n",
      "After 2289 training step(s),cross entropy on all data is 0.00795939\n",
      "After 2290 training step(s),cross entropy on all data is 0.00795843\n",
      "After 2291 training step(s),cross entropy on all data is 0.00795757\n",
      "After 2292 training step(s),cross entropy on all data is 0.0079568\n",
      "After 2293 training step(s),cross entropy on all data is 0.0079561\n",
      "After 2294 training step(s),cross entropy on all data is 0.00795547\n",
      "After 2295 training step(s),cross entropy on all data is 0.00795326\n",
      "After 2296 training step(s),cross entropy on all data is 0.00795127\n",
      "After 2297 training step(s),cross entropy on all data is 0.00794947\n",
      "After 2298 training step(s),cross entropy on all data is 0.00794785\n",
      "After 2299 training step(s),cross entropy on all data is 0.0079464\n",
      "After 2300 training step(s),cross entropy on all data is 0.00794509\n",
      "After 2301 training step(s),cross entropy on all data is 0.00794391\n",
      "After 2302 training step(s),cross entropy on all data is 0.00794285\n",
      "After 2303 training step(s),cross entropy on all data is 0.00794189\n",
      "After 2304 training step(s),cross entropy on all data is 0.00794103\n",
      "After 2305 training step(s),cross entropy on all data is 0.00794026\n",
      "After 2306 training step(s),cross entropy on all data is 0.00793956\n",
      "After 2307 training step(s),cross entropy on all data is 0.00793893\n",
      "After 2308 training step(s),cross entropy on all data is 0.00793836\n",
      "After 2309 training step(s),cross entropy on all data is 0.00793785\n",
      "After 2310 training step(s),cross entropy on all data is 0.00793739\n",
      "After 2311 training step(s),cross entropy on all data is 0.00793532\n",
      "After 2312 training step(s),cross entropy on all data is 0.00793346\n",
      "After 2313 training step(s),cross entropy on all data is 0.00793178\n",
      "After 2314 training step(s),cross entropy on all data is 0.00793027\n",
      "After 2315 training step(s),cross entropy on all data is 0.00792891\n",
      "After 2316 training step(s),cross entropy on all data is 0.00792768\n",
      "After 2317 training step(s),cross entropy on all data is 0.00792658\n",
      "After 2318 training step(s),cross entropy on all data is 0.00792559\n",
      "After 2319 training step(s),cross entropy on all data is 0.00792469\n",
      "After 2320 training step(s),cross entropy on all data is 0.00792389\n",
      "After 2321 training step(s),cross entropy on all data is 0.00792316\n",
      "After 2322 training step(s),cross entropy on all data is 0.00792251\n",
      "After 2323 training step(s),cross entropy on all data is 0.00792192\n",
      "After 2324 training step(s),cross entropy on all data is 0.00792139\n",
      "After 2325 training step(s),cross entropy on all data is 0.00792091\n",
      "After 2326 training step(s),cross entropy on all data is 0.00792048\n",
      "After 2327 training step(s),cross entropy on all data is 0.00791843\n",
      "After 2328 training step(s),cross entropy on all data is 0.00791658\n",
      "After 2329 training step(s),cross entropy on all data is 0.00791492\n",
      "After 2330 training step(s),cross entropy on all data is 0.00791342\n",
      "After 2331 training step(s),cross entropy on all data is 0.00791208\n",
      "After 2332 training step(s),cross entropy on all data is 0.00791086\n",
      "After 2333 training step(s),cross entropy on all data is 0.00790977\n",
      "After 2334 training step(s),cross entropy on all data is 0.00790878\n",
      "After 2335 training step(s),cross entropy on all data is 0.0079079\n",
      "After 2336 training step(s),cross entropy on all data is 0.0079071\n",
      "After 2337 training step(s),cross entropy on all data is 0.00790638\n",
      "After 2338 training step(s),cross entropy on all data is 0.00790573\n",
      "After 2339 training step(s),cross entropy on all data is 0.00790515\n",
      "After 2340 training step(s),cross entropy on all data is 0.00790462\n",
      "After 2341 training step(s),cross entropy on all data is 0.00790415\n",
      "After 2342 training step(s),cross entropy on all data is 0.00790373\n",
      "After 2343 training step(s),cross entropy on all data is 0.00790167\n",
      "After 2344 training step(s),cross entropy on all data is 0.00789982\n",
      "After 2345 training step(s),cross entropy on all data is 0.00789815\n",
      "After 2346 training step(s),cross entropy on all data is 0.00789665\n",
      "After 2347 training step(s),cross entropy on all data is 0.0078953\n",
      "After 2348 training step(s),cross entropy on all data is 0.00789408\n",
      "After 2349 training step(s),cross entropy on all data is 0.00789298\n",
      "After 2350 training step(s),cross entropy on all data is 0.00789199\n",
      "After 2351 training step(s),cross entropy on all data is 0.00789111\n",
      "After 2352 training step(s),cross entropy on all data is 0.00789031\n",
      "After 2353 training step(s),cross entropy on all data is 0.00788958\n",
      "After 2354 training step(s),cross entropy on all data is 0.00788894\n",
      "After 2355 training step(s),cross entropy on all data is 0.00788835\n",
      "After 2356 training step(s),cross entropy on all data is 0.00788783\n",
      "After 2357 training step(s),cross entropy on all data is 0.00788735\n",
      "After 2358 training step(s),cross entropy on all data is 0.00788693\n",
      "After 2359 training step(s),cross entropy on all data is 0.00788486\n",
      "After 2360 training step(s),cross entropy on all data is 0.007883\n",
      "After 2361 training step(s),cross entropy on all data is 0.00788132\n",
      "After 2362 training step(s),cross entropy on all data is 0.00787981\n",
      "After 2363 training step(s),cross entropy on all data is 0.00787846\n",
      "After 2364 training step(s),cross entropy on all data is 0.00787723\n",
      "After 2365 training step(s),cross entropy on all data is 0.00787613\n",
      "After 2366 training step(s),cross entropy on all data is 0.00787514\n",
      "After 2367 training step(s),cross entropy on all data is 0.00787425\n",
      "After 2368 training step(s),cross entropy on all data is 0.00787344\n",
      "After 2369 training step(s),cross entropy on all data is 0.00787272\n",
      "After 2370 training step(s),cross entropy on all data is 0.00787207\n",
      "After 2371 training step(s),cross entropy on all data is 0.00787148\n",
      "After 2372 training step(s),cross entropy on all data is 0.00787095\n",
      "After 2373 training step(s),cross entropy on all data is 0.00787047\n",
      "After 2374 training step(s),cross entropy on all data is 0.00787005\n",
      "After 2375 training step(s),cross entropy on all data is 0.00786797\n",
      "After 2376 training step(s),cross entropy on all data is 0.0078661\n",
      "After 2377 training step(s),cross entropy on all data is 0.00786442\n",
      "After 2378 training step(s),cross entropy on all data is 0.0078629\n",
      "After 2379 training step(s),cross entropy on all data is 0.00786154\n",
      "After 2380 training step(s),cross entropy on all data is 0.00786031\n",
      "After 2381 training step(s),cross entropy on all data is 0.0078592\n",
      "After 2382 training step(s),cross entropy on all data is 0.0078582\n",
      "After 2383 training step(s),cross entropy on all data is 0.0078573\n",
      "After 2384 training step(s),cross entropy on all data is 0.0078565\n",
      "After 2385 training step(s),cross entropy on all data is 0.00785577\n",
      "After 2386 training step(s),cross entropy on all data is 0.00785512\n",
      "After 2387 training step(s),cross entropy on all data is 0.00785452\n",
      "After 2388 training step(s),cross entropy on all data is 0.00785399\n",
      "After 2389 training step(s),cross entropy on all data is 0.00785351\n",
      "After 2390 training step(s),cross entropy on all data is 0.00785308\n",
      "After 2391 training step(s),cross entropy on all data is 0.007851\n",
      "After 2392 training step(s),cross entropy on all data is 0.00784912\n",
      "After 2393 training step(s),cross entropy on all data is 0.00784742\n",
      "After 2394 training step(s),cross entropy on all data is 0.0078459\n",
      "After 2395 training step(s),cross entropy on all data is 0.00784453\n",
      "After 2396 training step(s),cross entropy on all data is 0.00784329\n",
      "After 2397 training step(s),cross entropy on all data is 0.00784218\n",
      "After 2398 training step(s),cross entropy on all data is 0.00784118\n",
      "After 2399 training step(s),cross entropy on all data is 0.00784028\n",
      "After 2400 training step(s),cross entropy on all data is 0.00783947\n",
      "After 2401 training step(s),cross entropy on all data is 0.00783874\n",
      "After 2402 training step(s),cross entropy on all data is 0.00783808\n",
      "After 2403 training step(s),cross entropy on all data is 0.00783748\n",
      "After 2404 training step(s),cross entropy on all data is 0.00783695\n",
      "After 2405 training step(s),cross entropy on all data is 0.00783647\n",
      "After 2406 training step(s),cross entropy on all data is 0.00783604\n",
      "After 2407 training step(s),cross entropy on all data is 0.00783394\n",
      "After 2408 training step(s),cross entropy on all data is 0.00783205\n",
      "After 2409 training step(s),cross entropy on all data is 0.00783035\n",
      "After 2410 training step(s),cross entropy on all data is 0.00782882\n",
      "After 2411 training step(s),cross entropy on all data is 0.00782744\n",
      "After 2412 training step(s),cross entropy on all data is 0.0078262\n",
      "After 2413 training step(s),cross entropy on all data is 0.00782508\n",
      "After 2414 training step(s),cross entropy on all data is 0.00782407\n",
      "After 2415 training step(s),cross entropy on all data is 0.00782317\n",
      "After 2416 training step(s),cross entropy on all data is 0.00782235\n",
      "After 2417 training step(s),cross entropy on all data is 0.00782162\n",
      "After 2418 training step(s),cross entropy on all data is 0.00782095\n",
      "After 2419 training step(s),cross entropy on all data is 0.00782036\n",
      "After 2420 training step(s),cross entropy on all data is 0.00781982\n",
      "After 2421 training step(s),cross entropy on all data is 0.00781934\n",
      "After 2422 training step(s),cross entropy on all data is 0.0078189\n",
      "After 2423 training step(s),cross entropy on all data is 0.0078168\n",
      "After 2424 training step(s),cross entropy on all data is 0.0078149\n",
      "After 2425 training step(s),cross entropy on all data is 0.00781319\n",
      "After 2426 training step(s),cross entropy on all data is 0.00781165\n",
      "After 2427 training step(s),cross entropy on all data is 0.00781027\n",
      "After 2428 training step(s),cross entropy on all data is 0.00780902\n",
      "After 2429 training step(s),cross entropy on all data is 0.0078079\n",
      "After 2430 training step(s),cross entropy on all data is 0.00780688\n",
      "After 2431 training step(s),cross entropy on all data is 0.00780597\n",
      "After 2432 training step(s),cross entropy on all data is 0.00780515\n",
      "After 2433 training step(s),cross entropy on all data is 0.00780441\n",
      "After 2434 training step(s),cross entropy on all data is 0.00780375\n",
      "After 2435 training step(s),cross entropy on all data is 0.00780315\n",
      "After 2436 training step(s),cross entropy on all data is 0.00780261\n",
      "After 2437 training step(s),cross entropy on all data is 0.00780212\n",
      "After 2438 training step(s),cross entropy on all data is 0.00780169\n",
      "After 2439 training step(s),cross entropy on all data is 0.00779957\n",
      "After 2440 training step(s),cross entropy on all data is 0.00779766\n",
      "After 2441 training step(s),cross entropy on all data is 0.00779595\n",
      "After 2442 training step(s),cross entropy on all data is 0.0077944\n",
      "After 2443 training step(s),cross entropy on all data is 0.00779301\n",
      "After 2444 training step(s),cross entropy on all data is 0.00779175\n",
      "After 2445 training step(s),cross entropy on all data is 0.00779063\n",
      "After 2446 training step(s),cross entropy on all data is 0.00778961\n",
      "After 2447 training step(s),cross entropy on all data is 0.00778869\n",
      "After 2448 training step(s),cross entropy on all data is 0.00778787\n",
      "After 2449 training step(s),cross entropy on all data is 0.00778713\n",
      "After 2450 training step(s),cross entropy on all data is 0.00778646\n",
      "After 2451 training step(s),cross entropy on all data is 0.00778586\n",
      "After 2452 training step(s),cross entropy on all data is 0.00778531\n",
      "After 2453 training step(s),cross entropy on all data is 0.00778483\n",
      "After 2454 training step(s),cross entropy on all data is 0.00778439\n",
      "After 2455 training step(s),cross entropy on all data is 0.00778226\n",
      "After 2456 training step(s),cross entropy on all data is 0.00778034\n",
      "After 2457 training step(s),cross entropy on all data is 0.00777862\n",
      "After 2458 training step(s),cross entropy on all data is 0.00777706\n",
      "After 2459 training step(s),cross entropy on all data is 0.00777566\n",
      "After 2460 training step(s),cross entropy on all data is 0.00777441\n",
      "After 2461 training step(s),cross entropy on all data is 0.00777327\n",
      "After 2462 training step(s),cross entropy on all data is 0.00777225\n",
      "After 2463 training step(s),cross entropy on all data is 0.00777133\n",
      "After 2464 training step(s),cross entropy on all data is 0.0077705\n",
      "After 2465 training step(s),cross entropy on all data is 0.00776976\n",
      "After 2466 training step(s),cross entropy on all data is 0.00776908\n",
      "After 2467 training step(s),cross entropy on all data is 0.00776848\n",
      "After 2468 training step(s),cross entropy on all data is 0.00776794\n",
      "After 2469 training step(s),cross entropy on all data is 0.00776745\n",
      "After 2470 training step(s),cross entropy on all data is 0.007767\n",
      "After 2471 training step(s),cross entropy on all data is 0.00776486\n",
      "After 2472 training step(s),cross entropy on all data is 0.00776294\n",
      "After 2473 training step(s),cross entropy on all data is 0.00776121\n",
      "After 2474 training step(s),cross entropy on all data is 0.00775964\n",
      "After 2475 training step(s),cross entropy on all data is 0.00775824\n",
      "After 2476 training step(s),cross entropy on all data is 0.00775697\n",
      "After 2477 training step(s),cross entropy on all data is 0.00775583\n",
      "After 2478 training step(s),cross entropy on all data is 0.00775481\n",
      "After 2479 training step(s),cross entropy on all data is 0.00775388\n",
      "After 2480 training step(s),cross entropy on all data is 0.00775305\n",
      "After 2481 training step(s),cross entropy on all data is 0.0077523\n",
      "After 2482 training step(s),cross entropy on all data is 0.00775163\n",
      "After 2483 training step(s),cross entropy on all data is 0.00775102\n",
      "After 2484 training step(s),cross entropy on all data is 0.00775047\n",
      "After 2485 training step(s),cross entropy on all data is 0.00774998\n",
      "After 2486 training step(s),cross entropy on all data is 0.00774954\n",
      "After 2487 training step(s),cross entropy on all data is 0.00774739\n",
      "After 2488 training step(s),cross entropy on all data is 0.00774545\n",
      "After 2489 training step(s),cross entropy on all data is 0.00774371\n",
      "After 2490 training step(s),cross entropy on all data is 0.00774214\n",
      "After 2491 training step(s),cross entropy on all data is 0.00774073\n",
      "After 2492 training step(s),cross entropy on all data is 0.00773946\n",
      "After 2493 training step(s),cross entropy on all data is 0.00773831\n",
      "After 2494 training step(s),cross entropy on all data is 0.00773728\n",
      "After 2495 training step(s),cross entropy on all data is 0.00773635\n",
      "After 2496 training step(s),cross entropy on all data is 0.00773552\n",
      "After 2497 training step(s),cross entropy on all data is 0.00773476\n",
      "After 2498 training step(s),cross entropy on all data is 0.00773409\n",
      "After 2499 training step(s),cross entropy on all data is 0.00773348\n",
      "After 2500 training step(s),cross entropy on all data is 0.00773293\n",
      "After 2501 training step(s),cross entropy on all data is 0.00773243\n",
      "After 2502 training step(s),cross entropy on all data is 0.00773199\n",
      "After 2503 training step(s),cross entropy on all data is 0.00772983\n",
      "After 2504 training step(s),cross entropy on all data is 0.00772788\n",
      "After 2505 training step(s),cross entropy on all data is 0.00772613\n",
      "After 2506 training step(s),cross entropy on all data is 0.00772456\n",
      "After 2507 training step(s),cross entropy on all data is 0.00772314\n",
      "After 2508 training step(s),cross entropy on all data is 0.00772186\n",
      "After 2509 training step(s),cross entropy on all data is 0.00772071\n",
      "After 2510 training step(s),cross entropy on all data is 0.00771967\n",
      "After 2511 training step(s),cross entropy on all data is 0.00771874\n",
      "After 2512 training step(s),cross entropy on all data is 0.0077179\n",
      "After 2513 training step(s),cross entropy on all data is 0.00771714\n",
      "After 2514 training step(s),cross entropy on all data is 0.00771646\n",
      "After 2515 training step(s),cross entropy on all data is 0.00771585\n",
      "After 2516 training step(s),cross entropy on all data is 0.0077153\n",
      "After 2517 training step(s),cross entropy on all data is 0.0077148\n",
      "After 2518 training step(s),cross entropy on all data is 0.00771435\n",
      "After 2519 training step(s),cross entropy on all data is 0.00771218\n",
      "After 2520 training step(s),cross entropy on all data is 0.00771023\n",
      "After 2521 training step(s),cross entropy on all data is 0.00770847\n",
      "After 2522 training step(s),cross entropy on all data is 0.00770689\n",
      "After 2523 training step(s),cross entropy on all data is 0.00770546\n",
      "After 2524 training step(s),cross entropy on all data is 0.00770418\n",
      "After 2525 training step(s),cross entropy on all data is 0.00770302\n",
      "After 2526 training step(s),cross entropy on all data is 0.00770198\n",
      "After 2527 training step(s),cross entropy on all data is 0.00770105\n",
      "After 2528 training step(s),cross entropy on all data is 0.0077002\n",
      "After 2529 training step(s),cross entropy on all data is 0.00769944\n",
      "After 2530 training step(s),cross entropy on all data is 0.00769876\n",
      "After 2531 training step(s),cross entropy on all data is 0.00769814\n",
      "After 2532 training step(s),cross entropy on all data is 0.00769759\n",
      "After 2533 training step(s),cross entropy on all data is 0.00769709\n",
      "After 2534 training step(s),cross entropy on all data is 0.00769664\n",
      "After 2535 training step(s),cross entropy on all data is 0.00769446\n",
      "After 2536 training step(s),cross entropy on all data is 0.0076925\n",
      "After 2537 training step(s),cross entropy on all data is 0.00769073\n",
      "After 2538 training step(s),cross entropy on all data is 0.00768914\n",
      "After 2539 training step(s),cross entropy on all data is 0.00768771\n",
      "After 2540 training step(s),cross entropy on all data is 0.00768642\n",
      "After 2541 training step(s),cross entropy on all data is 0.00768526\n",
      "After 2542 training step(s),cross entropy on all data is 0.00768421\n",
      "After 2543 training step(s),cross entropy on all data is 0.00768327\n",
      "After 2544 training step(s),cross entropy on all data is 0.00768242\n",
      "After 2545 training step(s),cross entropy on all data is 0.00768166\n",
      "After 2546 training step(s),cross entropy on all data is 0.00768097\n",
      "After 2547 training step(s),cross entropy on all data is 0.00768035\n",
      "After 2548 training step(s),cross entropy on all data is 0.0076798\n",
      "After 2549 training step(s),cross entropy on all data is 0.00767929\n",
      "After 2550 training step(s),cross entropy on all data is 0.00767884\n",
      "After 2551 training step(s),cross entropy on all data is 0.00767665\n",
      "After 2552 training step(s),cross entropy on all data is 0.00767468\n",
      "After 2553 training step(s),cross entropy on all data is 0.00767291\n",
      "After 2554 training step(s),cross entropy on all data is 0.00767131\n",
      "After 2555 training step(s),cross entropy on all data is 0.00766987\n",
      "After 2556 training step(s),cross entropy on all data is 0.00766858\n",
      "After 2557 training step(s),cross entropy on all data is 0.00766741\n",
      "After 2558 training step(s),cross entropy on all data is 0.00766636\n",
      "After 2559 training step(s),cross entropy on all data is 0.00766541\n",
      "After 2560 training step(s),cross entropy on all data is 0.00766456\n",
      "After 2561 training step(s),cross entropy on all data is 0.00766379\n",
      "After 2562 training step(s),cross entropy on all data is 0.0076631\n",
      "After 2563 training step(s),cross entropy on all data is 0.00766248\n",
      "After 2564 training step(s),cross entropy on all data is 0.00766192\n",
      "After 2565 training step(s),cross entropy on all data is 0.00766142\n",
      "After 2566 training step(s),cross entropy on all data is 0.00766096\n",
      "After 2567 training step(s),cross entropy on all data is 0.00765877\n",
      "After 2568 training step(s),cross entropy on all data is 0.00765679\n",
      "After 2569 training step(s),cross entropy on all data is 0.007655\n",
      "After 2570 training step(s),cross entropy on all data is 0.0076534\n",
      "After 2571 training step(s),cross entropy on all data is 0.00765195\n",
      "After 2572 training step(s),cross entropy on all data is 0.00765065\n",
      "After 2573 training step(s),cross entropy on all data is 0.00764948\n",
      "After 2574 training step(s),cross entropy on all data is 0.00764842\n",
      "After 2575 training step(s),cross entropy on all data is 0.00764747\n",
      "After 2576 training step(s),cross entropy on all data is 0.00764662\n",
      "After 2577 training step(s),cross entropy on all data is 0.00764585\n",
      "After 2578 training step(s),cross entropy on all data is 0.00764515\n",
      "After 2579 training step(s),cross entropy on all data is 0.00764453\n",
      "After 2580 training step(s),cross entropy on all data is 0.00764397\n",
      "After 2581 training step(s),cross entropy on all data is 0.00764346\n",
      "After 2582 training step(s),cross entropy on all data is 0.007643\n",
      "After 2583 training step(s),cross entropy on all data is 0.0076408\n",
      "After 2584 training step(s),cross entropy on all data is 0.00763881\n",
      "After 2585 training step(s),cross entropy on all data is 0.00763702\n",
      "After 2586 training step(s),cross entropy on all data is 0.0076354\n",
      "After 2587 training step(s),cross entropy on all data is 0.00763395\n",
      "After 2588 training step(s),cross entropy on all data is 0.00763264\n",
      "After 2589 training step(s),cross entropy on all data is 0.00763147\n",
      "After 2590 training step(s),cross entropy on all data is 0.00763041\n",
      "After 2591 training step(s),cross entropy on all data is 0.00762945\n",
      "After 2592 training step(s),cross entropy on all data is 0.0076286\n",
      "After 2593 training step(s),cross entropy on all data is 0.00762782\n",
      "After 2594 training step(s),cross entropy on all data is 0.00762712\n",
      "After 2595 training step(s),cross entropy on all data is 0.0076265\n",
      "After 2596 training step(s),cross entropy on all data is 0.00762593\n",
      "After 2597 training step(s),cross entropy on all data is 0.00762542\n",
      "After 2598 training step(s),cross entropy on all data is 0.00762497\n",
      "After 2599 training step(s),cross entropy on all data is 0.00762275\n",
      "After 2600 training step(s),cross entropy on all data is 0.00762075\n",
      "After 2601 training step(s),cross entropy on all data is 0.00761895\n",
      "After 2602 training step(s),cross entropy on all data is 0.00761733\n",
      "After 2603 training step(s),cross entropy on all data is 0.00761587\n",
      "After 2604 training step(s),cross entropy on all data is 0.00761456\n",
      "After 2605 training step(s),cross entropy on all data is 0.00761338\n",
      "After 2606 training step(s),cross entropy on all data is 0.00761231\n",
      "After 2607 training step(s),cross entropy on all data is 0.00761136\n",
      "After 2608 training step(s),cross entropy on all data is 0.00761049\n",
      "After 2609 training step(s),cross entropy on all data is 0.00760971\n",
      "After 2610 training step(s),cross entropy on all data is 0.00760901\n",
      "After 2611 training step(s),cross entropy on all data is 0.00760838\n",
      "After 2612 training step(s),cross entropy on all data is 0.00760782\n",
      "After 2613 training step(s),cross entropy on all data is 0.00760731\n",
      "After 2614 training step(s),cross entropy on all data is 0.00760685\n",
      "After 2615 training step(s),cross entropy on all data is 0.00760462\n",
      "After 2616 training step(s),cross entropy on all data is 0.00760261\n",
      "After 2617 training step(s),cross entropy on all data is 0.0076008\n",
      "After 2618 training step(s),cross entropy on all data is 0.00759918\n",
      "After 2619 training step(s),cross entropy on all data is 0.00759771\n",
      "After 2620 training step(s),cross entropy on all data is 0.00759639\n",
      "After 2621 training step(s),cross entropy on all data is 0.00759521\n",
      "After 2622 training step(s),cross entropy on all data is 0.00759414\n",
      "After 2623 training step(s),cross entropy on all data is 0.00759317\n",
      "After 2624 training step(s),cross entropy on all data is 0.00759231\n",
      "After 2625 training step(s),cross entropy on all data is 0.00759153\n",
      "After 2626 training step(s),cross entropy on all data is 0.00759082\n",
      "After 2627 training step(s),cross entropy on all data is 0.00759019\n",
      "After 2628 training step(s),cross entropy on all data is 0.00758962\n",
      "After 2629 training step(s),cross entropy on all data is 0.00758911\n",
      "After 2630 training step(s),cross entropy on all data is 0.00758865\n",
      "After 2631 training step(s),cross entropy on all data is 0.00758641\n",
      "After 2632 training step(s),cross entropy on all data is 0.00758439\n",
      "After 2633 training step(s),cross entropy on all data is 0.00758258\n",
      "After 2634 training step(s),cross entropy on all data is 0.00758094\n",
      "After 2635 training step(s),cross entropy on all data is 0.00757947\n",
      "After 2636 training step(s),cross entropy on all data is 0.00757815\n",
      "After 2637 training step(s),cross entropy on all data is 0.00757696\n",
      "After 2638 training step(s),cross entropy on all data is 0.00757588\n",
      "After 2639 training step(s),cross entropy on all data is 0.00757491\n",
      "After 2640 training step(s),cross entropy on all data is 0.00757404\n",
      "After 2641 training step(s),cross entropy on all data is 0.00757326\n",
      "After 2642 training step(s),cross entropy on all data is 0.00757255\n",
      "After 2643 training step(s),cross entropy on all data is 0.00757192\n",
      "After 2644 training step(s),cross entropy on all data is 0.00757135\n",
      "After 2645 training step(s),cross entropy on all data is 0.00757083\n",
      "After 2646 training step(s),cross entropy on all data is 0.00757037\n",
      "After 2647 training step(s),cross entropy on all data is 0.00756812\n",
      "After 2648 training step(s),cross entropy on all data is 0.00756609\n",
      "After 2649 training step(s),cross entropy on all data is 0.00756427\n",
      "After 2650 training step(s),cross entropy on all data is 0.00756263\n",
      "After 2651 training step(s),cross entropy on all data is 0.00756115\n",
      "After 2652 training step(s),cross entropy on all data is 0.00755982\n",
      "After 2653 training step(s),cross entropy on all data is 0.00755862\n",
      "After 2654 training step(s),cross entropy on all data is 0.00755755\n",
      "After 2655 training step(s),cross entropy on all data is 0.00755658\n",
      "After 2656 training step(s),cross entropy on all data is 0.0075557\n",
      "After 2657 training step(s),cross entropy on all data is 0.00755491\n",
      "After 2658 training step(s),cross entropy on all data is 0.0075542\n",
      "After 2659 training step(s),cross entropy on all data is 0.00755357\n",
      "After 2660 training step(s),cross entropy on all data is 0.00755299\n",
      "After 2661 training step(s),cross entropy on all data is 0.00755247\n",
      "After 2662 training step(s),cross entropy on all data is 0.00755201\n",
      "After 2663 training step(s),cross entropy on all data is 0.00754975\n",
      "After 2664 training step(s),cross entropy on all data is 0.00754772\n",
      "After 2665 training step(s),cross entropy on all data is 0.00754589\n",
      "After 2666 training step(s),cross entropy on all data is 0.00754424\n",
      "After 2667 training step(s),cross entropy on all data is 0.00754276\n",
      "After 2668 training step(s),cross entropy on all data is 0.00754142\n",
      "After 2669 training step(s),cross entropy on all data is 0.00754022\n",
      "After 2670 training step(s),cross entropy on all data is 0.00753913\n",
      "After 2671 training step(s),cross entropy on all data is 0.00753816\n",
      "After 2672 training step(s),cross entropy on all data is 0.00753728\n",
      "After 2673 training step(s),cross entropy on all data is 0.00753649\n",
      "After 2674 training step(s),cross entropy on all data is 0.00753578\n",
      "After 2675 training step(s),cross entropy on all data is 0.00753514\n",
      "After 2676 training step(s),cross entropy on all data is 0.00753456\n",
      "After 2677 training step(s),cross entropy on all data is 0.00753404\n",
      "After 2678 training step(s),cross entropy on all data is 0.00753357\n",
      "After 2679 training step(s),cross entropy on all data is 0.0075313\n",
      "After 2680 training step(s),cross entropy on all data is 0.00752926\n",
      "After 2681 training step(s),cross entropy on all data is 0.00752742\n",
      "After 2682 training step(s),cross entropy on all data is 0.00752577\n",
      "After 2683 training step(s),cross entropy on all data is 0.00752428\n",
      "After 2684 training step(s),cross entropy on all data is 0.00752294\n",
      "After 2685 training step(s),cross entropy on all data is 0.00752173\n",
      "After 2686 training step(s),cross entropy on all data is 0.00752064\n",
      "After 2687 training step(s),cross entropy on all data is 0.00751966\n",
      "After 2688 training step(s),cross entropy on all data is 0.00751878\n",
      "After 2689 training step(s),cross entropy on all data is 0.00751799\n",
      "After 2690 training step(s),cross entropy on all data is 0.00751727\n",
      "After 2691 training step(s),cross entropy on all data is 0.00751663\n",
      "After 2692 training step(s),cross entropy on all data is 0.00751605\n",
      "After 2693 training step(s),cross entropy on all data is 0.00751552\n",
      "After 2694 training step(s),cross entropy on all data is 0.00751505\n",
      "After 2695 training step(s),cross entropy on all data is 0.00751278\n",
      "After 2696 training step(s),cross entropy on all data is 0.00751073\n",
      "After 2697 training step(s),cross entropy on all data is 0.00750888\n",
      "After 2698 training step(s),cross entropy on all data is 0.00750722\n",
      "After 2699 training step(s),cross entropy on all data is 0.00750572\n",
      "After 2700 training step(s),cross entropy on all data is 0.00750438\n",
      "After 2701 training step(s),cross entropy on all data is 0.00750316\n",
      "After 2702 training step(s),cross entropy on all data is 0.00750207\n",
      "After 2703 training step(s),cross entropy on all data is 0.00750109\n",
      "After 2704 training step(s),cross entropy on all data is 0.0075002\n",
      "After 2705 training step(s),cross entropy on all data is 0.0074994\n",
      "After 2706 training step(s),cross entropy on all data is 0.00749869\n",
      "After 2707 training step(s),cross entropy on all data is 0.00749804\n",
      "After 2708 training step(s),cross entropy on all data is 0.00749746\n",
      "After 2709 training step(s),cross entropy on all data is 0.00749693\n",
      "After 2710 training step(s),cross entropy on all data is 0.00749646\n",
      "After 2711 training step(s),cross entropy on all data is 0.00749417\n",
      "After 2712 training step(s),cross entropy on all data is 0.00749212\n",
      "After 2713 training step(s),cross entropy on all data is 0.00749026\n",
      "After 2714 training step(s),cross entropy on all data is 0.00748859\n",
      "After 2715 training step(s),cross entropy on all data is 0.00748709\n",
      "After 2716 training step(s),cross entropy on all data is 0.00748574\n",
      "After 2717 training step(s),cross entropy on all data is 0.00748452\n",
      "After 2718 training step(s),cross entropy on all data is 0.00748342\n",
      "After 2719 training step(s),cross entropy on all data is 0.00748244\n",
      "After 2720 training step(s),cross entropy on all data is 0.00748155\n",
      "After 2721 training step(s),cross entropy on all data is 0.00748075\n",
      "After 2722 training step(s),cross entropy on all data is 0.00748002\n",
      "After 2723 training step(s),cross entropy on all data is 0.00747938\n",
      "After 2724 training step(s),cross entropy on all data is 0.00747879\n",
      "After 2725 training step(s),cross entropy on all data is 0.00747827\n",
      "After 2726 training step(s),cross entropy on all data is 0.00747779\n",
      "After 2727 training step(s),cross entropy on all data is 0.0074755\n",
      "After 2728 training step(s),cross entropy on all data is 0.00747343\n",
      "After 2729 training step(s),cross entropy on all data is 0.00747157\n",
      "After 2730 training step(s),cross entropy on all data is 0.00746989\n",
      "After 2731 training step(s),cross entropy on all data is 0.00746838\n",
      "After 2732 training step(s),cross entropy on all data is 0.00746702\n",
      "After 2733 training step(s),cross entropy on all data is 0.0074658\n",
      "After 2734 training step(s),cross entropy on all data is 0.0074647\n",
      "After 2735 training step(s),cross entropy on all data is 0.00746371\n",
      "After 2736 training step(s),cross entropy on all data is 0.00746282\n",
      "After 2737 training step(s),cross entropy on all data is 0.00746201\n",
      "After 2738 training step(s),cross entropy on all data is 0.00746129\n",
      "After 2739 training step(s),cross entropy on all data is 0.00746064\n",
      "After 2740 training step(s),cross entropy on all data is 0.00746005\n",
      "After 2741 training step(s),cross entropy on all data is 0.00745952\n",
      "After 2742 training step(s),cross entropy on all data is 0.00745904\n",
      "After 2743 training step(s),cross entropy on all data is 0.00745674\n",
      "After 2744 training step(s),cross entropy on all data is 0.00745466\n",
      "After 2745 training step(s),cross entropy on all data is 0.00745279\n",
      "After 2746 training step(s),cross entropy on all data is 0.00745111\n",
      "After 2747 training step(s),cross entropy on all data is 0.0074496\n",
      "After 2748 training step(s),cross entropy on all data is 0.00744823\n",
      "After 2749 training step(s),cross entropy on all data is 0.00744701\n",
      "After 2750 training step(s),cross entropy on all data is 0.0074459\n",
      "After 2751 training step(s),cross entropy on all data is 0.0074449\n",
      "After 2752 training step(s),cross entropy on all data is 0.00744401\n",
      "After 2753 training step(s),cross entropy on all data is 0.0074432\n",
      "After 2754 training step(s),cross entropy on all data is 0.00744247\n",
      "After 2755 training step(s),cross entropy on all data is 0.00744182\n",
      "After 2756 training step(s),cross entropy on all data is 0.00744123\n",
      "After 2757 training step(s),cross entropy on all data is 0.0074407\n",
      "After 2758 training step(s),cross entropy on all data is 0.00744022\n",
      "After 2759 training step(s),cross entropy on all data is 0.00743791\n",
      "After 2760 training step(s),cross entropy on all data is 0.00743582\n",
      "After 2761 training step(s),cross entropy on all data is 0.00743395\n",
      "After 2762 training step(s),cross entropy on all data is 0.00743226\n",
      "After 2763 training step(s),cross entropy on all data is 0.00743074\n",
      "After 2764 training step(s),cross entropy on all data is 0.00742937\n",
      "After 2765 training step(s),cross entropy on all data is 0.00742813\n",
      "After 2766 training step(s),cross entropy on all data is 0.00742702\n",
      "After 2767 training step(s),cross entropy on all data is 0.00742602\n",
      "After 2768 training step(s),cross entropy on all data is 0.00742512\n",
      "After 2769 training step(s),cross entropy on all data is 0.00742431\n",
      "After 2770 training step(s),cross entropy on all data is 0.00742358\n",
      "After 2771 training step(s),cross entropy on all data is 0.00742292\n",
      "After 2772 training step(s),cross entropy on all data is 0.00742233\n",
      "After 2773 training step(s),cross entropy on all data is 0.0074218\n",
      "After 2774 training step(s),cross entropy on all data is 0.00742132\n",
      "After 2775 training step(s),cross entropy on all data is 0.007419\n",
      "After 2776 training step(s),cross entropy on all data is 0.0074169\n",
      "After 2777 training step(s),cross entropy on all data is 0.00741502\n",
      "After 2778 training step(s),cross entropy on all data is 0.00741332\n",
      "After 2779 training step(s),cross entropy on all data is 0.0074118\n",
      "After 2780 training step(s),cross entropy on all data is 0.00741042\n",
      "After 2781 training step(s),cross entropy on all data is 0.00740918\n",
      "After 2782 training step(s),cross entropy on all data is 0.00740807\n",
      "After 2783 training step(s),cross entropy on all data is 0.00740707\n",
      "After 2784 training step(s),cross entropy on all data is 0.00740616\n",
      "After 2785 training step(s),cross entropy on all data is 0.00740535\n",
      "After 2786 training step(s),cross entropy on all data is 0.00740462\n",
      "After 2787 training step(s),cross entropy on all data is 0.00740396\n",
      "After 2788 training step(s),cross entropy on all data is 0.00740336\n",
      "After 2789 training step(s),cross entropy on all data is 0.00740283\n",
      "After 2790 training step(s),cross entropy on all data is 0.00740234\n",
      "After 2791 training step(s),cross entropy on all data is 0.00740001\n",
      "After 2792 training step(s),cross entropy on all data is 0.00739791\n",
      "After 2793 training step(s),cross entropy on all data is 0.00739602\n",
      "After 2794 training step(s),cross entropy on all data is 0.00739432\n",
      "After 2795 training step(s),cross entropy on all data is 0.00739278\n",
      "After 2796 training step(s),cross entropy on all data is 0.0073914\n",
      "After 2797 training step(s),cross entropy on all data is 0.00739016\n",
      "After 2798 training step(s),cross entropy on all data is 0.00738904\n",
      "After 2799 training step(s),cross entropy on all data is 0.00738803\n",
      "After 2800 training step(s),cross entropy on all data is 0.00738713\n",
      "After 2801 training step(s),cross entropy on all data is 0.00738631\n",
      "After 2802 training step(s),cross entropy on all data is 0.00738557\n",
      "After 2803 training step(s),cross entropy on all data is 0.00738491\n",
      "After 2804 training step(s),cross entropy on all data is 0.00738431\n",
      "After 2805 training step(s),cross entropy on all data is 0.00738378\n",
      "After 2806 training step(s),cross entropy on all data is 0.00738329\n",
      "After 2807 training step(s),cross entropy on all data is 0.00738095\n",
      "After 2808 training step(s),cross entropy on all data is 0.00737884\n",
      "After 2809 training step(s),cross entropy on all data is 0.00737695\n",
      "After 2810 training step(s),cross entropy on all data is 0.00737523\n",
      "After 2811 training step(s),cross entropy on all data is 0.0073737\n",
      "After 2812 training step(s),cross entropy on all data is 0.00737231\n",
      "After 2813 training step(s),cross entropy on all data is 0.00737106\n",
      "After 2814 training step(s),cross entropy on all data is 0.00736994\n",
      "After 2815 training step(s),cross entropy on all data is 0.00736893\n",
      "After 2816 training step(s),cross entropy on all data is 0.00736802\n",
      "After 2817 training step(s),cross entropy on all data is 0.0073672\n",
      "After 2818 training step(s),cross entropy on all data is 0.00736646\n",
      "After 2819 training step(s),cross entropy on all data is 0.00736579\n",
      "After 2820 training step(s),cross entropy on all data is 0.00736519\n",
      "After 2821 training step(s),cross entropy on all data is 0.00736465\n",
      "After 2822 training step(s),cross entropy on all data is 0.00736417\n",
      "After 2823 training step(s),cross entropy on all data is 0.00736182\n",
      "After 2824 training step(s),cross entropy on all data is 0.0073597\n",
      "After 2825 training step(s),cross entropy on all data is 0.0073578\n",
      "After 2826 training step(s),cross entropy on all data is 0.00735608\n",
      "After 2827 training step(s),cross entropy on all data is 0.00735453\n",
      "After 2828 training step(s),cross entropy on all data is 0.00735314\n",
      "After 2829 training step(s),cross entropy on all data is 0.00735189\n",
      "After 2830 training step(s),cross entropy on all data is 0.00735076\n",
      "After 2831 training step(s),cross entropy on all data is 0.00734975\n",
      "After 2832 training step(s),cross entropy on all data is 0.00734883\n",
      "After 2833 training step(s),cross entropy on all data is 0.00734801\n",
      "After 2834 training step(s),cross entropy on all data is 0.00734727\n",
      "After 2835 training step(s),cross entropy on all data is 0.0073466\n",
      "After 2836 training step(s),cross entropy on all data is 0.007346\n",
      "After 2837 training step(s),cross entropy on all data is 0.00734546\n",
      "After 2838 training step(s),cross entropy on all data is 0.00734497\n",
      "After 2839 training step(s),cross entropy on all data is 0.00734261\n",
      "After 2840 training step(s),cross entropy on all data is 0.00734048\n",
      "After 2841 training step(s),cross entropy on all data is 0.00733857\n",
      "After 2842 training step(s),cross entropy on all data is 0.00733685\n",
      "After 2843 training step(s),cross entropy on all data is 0.0073353\n",
      "After 2844 training step(s),cross entropy on all data is 0.0073339\n",
      "After 2845 training step(s),cross entropy on all data is 0.00733264\n",
      "After 2846 training step(s),cross entropy on all data is 0.00733151\n",
      "After 2847 training step(s),cross entropy on all data is 0.00733049\n",
      "After 2848 training step(s),cross entropy on all data is 0.00732957\n",
      "After 2849 training step(s),cross entropy on all data is 0.00732875\n",
      "After 2850 training step(s),cross entropy on all data is 0.007328\n",
      "After 2851 training step(s),cross entropy on all data is 0.00732733\n",
      "After 2852 training step(s),cross entropy on all data is 0.00732673\n",
      "After 2853 training step(s),cross entropy on all data is 0.00732619\n",
      "After 2854 training step(s),cross entropy on all data is 0.0073257\n",
      "After 2855 training step(s),cross entropy on all data is 0.00732333\n",
      "After 2856 training step(s),cross entropy on all data is 0.00732119\n",
      "After 2857 training step(s),cross entropy on all data is 0.00731927\n",
      "After 2858 training step(s),cross entropy on all data is 0.00731754\n",
      "After 2859 training step(s),cross entropy on all data is 0.00731599\n",
      "After 2860 training step(s),cross entropy on all data is 0.00731459\n",
      "After 2861 training step(s),cross entropy on all data is 0.00731332\n",
      "After 2862 training step(s),cross entropy on all data is 0.00731219\n",
      "After 2863 training step(s),cross entropy on all data is 0.00731116\n",
      "After 2864 training step(s),cross entropy on all data is 0.00731024\n",
      "After 2865 training step(s),cross entropy on all data is 0.00730941\n",
      "After 2866 training step(s),cross entropy on all data is 0.00730867\n",
      "After 2867 training step(s),cross entropy on all data is 0.00730799\n",
      "After 2868 training step(s),cross entropy on all data is 0.00730739\n",
      "After 2869 training step(s),cross entropy on all data is 0.00730684\n",
      "After 2870 training step(s),cross entropy on all data is 0.00730635\n",
      "After 2871 training step(s),cross entropy on all data is 0.00730397\n",
      "After 2872 training step(s),cross entropy on all data is 0.00730183\n",
      "After 2873 training step(s),cross entropy on all data is 0.0072999\n",
      "After 2874 training step(s),cross entropy on all data is 0.00729817\n",
      "After 2875 training step(s),cross entropy on all data is 0.00729661\n",
      "After 2876 training step(s),cross entropy on all data is 0.0072952\n",
      "After 2877 training step(s),cross entropy on all data is 0.00729393\n",
      "After 2878 training step(s),cross entropy on all data is 0.00729279\n",
      "After 2879 training step(s),cross entropy on all data is 0.00729176\n",
      "After 2880 training step(s),cross entropy on all data is 0.00729084\n",
      "After 2881 training step(s),cross entropy on all data is 0.00729\n",
      "After 2882 training step(s),cross entropy on all data is 0.00728926\n",
      "After 2883 training step(s),cross entropy on all data is 0.00728858\n",
      "After 2884 training step(s),cross entropy on all data is 0.00728797\n",
      "After 2885 training step(s),cross entropy on all data is 0.00728742\n",
      "After 2886 training step(s),cross entropy on all data is 0.00728693\n",
      "After 2887 training step(s),cross entropy on all data is 0.00728454\n",
      "After 2888 training step(s),cross entropy on all data is 0.00728239\n",
      "After 2889 training step(s),cross entropy on all data is 0.00728046\n",
      "After 2890 training step(s),cross entropy on all data is 0.00727872\n",
      "After 2891 training step(s),cross entropy on all data is 0.00727715\n",
      "After 2892 training step(s),cross entropy on all data is 0.00727574\n",
      "After 2893 training step(s),cross entropy on all data is 0.00727447\n",
      "After 2894 training step(s),cross entropy on all data is 0.00727332\n",
      "After 2895 training step(s),cross entropy on all data is 0.00727229\n",
      "After 2896 training step(s),cross entropy on all data is 0.00727136\n",
      "After 2897 training step(s),cross entropy on all data is 0.00727053\n",
      "After 2898 training step(s),cross entropy on all data is 0.00726977\n",
      "After 2899 training step(s),cross entropy on all data is 0.0072691\n",
      "After 2900 training step(s),cross entropy on all data is 0.00726849\n",
      "After 2901 training step(s),cross entropy on all data is 0.00726794\n",
      "After 2902 training step(s),cross entropy on all data is 0.00726744\n",
      "After 2903 training step(s),cross entropy on all data is 0.00726505\n",
      "After 2904 training step(s),cross entropy on all data is 0.00726289\n",
      "After 2905 training step(s),cross entropy on all data is 0.00726095\n",
      "After 2906 training step(s),cross entropy on all data is 0.0072592\n",
      "After 2907 training step(s),cross entropy on all data is 0.00725762\n",
      "After 2908 training step(s),cross entropy on all data is 0.00725621\n",
      "After 2909 training step(s),cross entropy on all data is 0.00725493\n",
      "After 2910 training step(s),cross entropy on all data is 0.00725378\n",
      "After 2911 training step(s),cross entropy on all data is 0.00725275\n",
      "After 2912 training step(s),cross entropy on all data is 0.00725181\n",
      "After 2913 training step(s),cross entropy on all data is 0.00725097\n",
      "After 2914 training step(s),cross entropy on all data is 0.00725022\n",
      "After 2915 training step(s),cross entropy on all data is 0.00724954\n",
      "After 2916 training step(s),cross entropy on all data is 0.00724893\n",
      "After 2917 training step(s),cross entropy on all data is 0.00724838\n",
      "After 2918 training step(s),cross entropy on all data is 0.00724788\n",
      "After 2919 training step(s),cross entropy on all data is 0.00724548\n",
      "After 2920 training step(s),cross entropy on all data is 0.00724331\n",
      "After 2921 training step(s),cross entropy on all data is 0.00724136\n",
      "After 2922 training step(s),cross entropy on all data is 0.00723961\n",
      "After 2923 training step(s),cross entropy on all data is 0.00723803\n",
      "After 2924 training step(s),cross entropy on all data is 0.0072366\n",
      "After 2925 training step(s),cross entropy on all data is 0.00723532\n",
      "After 2926 training step(s),cross entropy on all data is 0.00723417\n",
      "After 2927 training step(s),cross entropy on all data is 0.00723313\n",
      "After 2928 training step(s),cross entropy on all data is 0.0072322\n",
      "After 2929 training step(s),cross entropy on all data is 0.00723135\n",
      "After 2930 training step(s),cross entropy on all data is 0.0072306\n",
      "After 2931 training step(s),cross entropy on all data is 0.00722991\n",
      "After 2932 training step(s),cross entropy on all data is 0.0072293\n",
      "After 2933 training step(s),cross entropy on all data is 0.00722874\n",
      "After 2934 training step(s),cross entropy on all data is 0.00722825\n",
      "After 2935 training step(s),cross entropy on all data is 0.00722583\n",
      "After 2936 training step(s),cross entropy on all data is 0.00722366\n",
      "After 2937 training step(s),cross entropy on all data is 0.0072217\n",
      "After 2938 training step(s),cross entropy on all data is 0.00721994\n",
      "After 2939 training step(s),cross entropy on all data is 0.00721836\n",
      "After 2940 training step(s),cross entropy on all data is 0.00721693\n",
      "After 2941 training step(s),cross entropy on all data is 0.00721564\n",
      "After 2942 training step(s),cross entropy on all data is 0.00721449\n",
      "After 2943 training step(s),cross entropy on all data is 0.00721344\n",
      "After 2944 training step(s),cross entropy on all data is 0.0072125\n",
      "After 2945 training step(s),cross entropy on all data is 0.00721166\n",
      "After 2946 training step(s),cross entropy on all data is 0.0072109\n",
      "After 2947 training step(s),cross entropy on all data is 0.00721021\n",
      "After 2948 training step(s),cross entropy on all data is 0.0072096\n",
      "After 2949 training step(s),cross entropy on all data is 0.00720904\n",
      "After 2950 training step(s),cross entropy on all data is 0.00720854\n",
      "After 2951 training step(s),cross entropy on all data is 0.00720612\n",
      "After 2952 training step(s),cross entropy on all data is 0.00720394\n",
      "After 2953 training step(s),cross entropy on all data is 0.00720198\n",
      "After 2954 training step(s),cross entropy on all data is 0.00720021\n",
      "After 2955 training step(s),cross entropy on all data is 0.00719862\n",
      "After 2956 training step(s),cross entropy on all data is 0.00719718\n",
      "After 2957 training step(s),cross entropy on all data is 0.00719589\n",
      "After 2958 training step(s),cross entropy on all data is 0.00719473\n",
      "After 2959 training step(s),cross entropy on all data is 0.00719369\n",
      "After 2960 training step(s),cross entropy on all data is 0.00719274\n",
      "After 2961 training step(s),cross entropy on all data is 0.0071919\n",
      "After 2962 training step(s),cross entropy on all data is 0.00719113\n",
      "After 2963 training step(s),cross entropy on all data is 0.00719045\n",
      "After 2964 training step(s),cross entropy on all data is 0.00718983\n",
      "After 2965 training step(s),cross entropy on all data is 0.00718927\n",
      "After 2966 training step(s),cross entropy on all data is 0.00718877\n",
      "After 2967 training step(s),cross entropy on all data is 0.00718634\n",
      "After 2968 training step(s),cross entropy on all data is 0.00718415\n",
      "After 2969 training step(s),cross entropy on all data is 0.00718218\n",
      "After 2970 training step(s),cross entropy on all data is 0.00718041\n",
      "After 2971 training step(s),cross entropy on all data is 0.00717881\n",
      "After 2972 training step(s),cross entropy on all data is 0.00717737\n",
      "After 2973 training step(s),cross entropy on all data is 0.00717608\n",
      "After 2974 training step(s),cross entropy on all data is 0.00717491\n",
      "After 2975 training step(s),cross entropy on all data is 0.00717386\n",
      "After 2976 training step(s),cross entropy on all data is 0.00717292\n",
      "After 2977 training step(s),cross entropy on all data is 0.00717206\n",
      "After 2978 training step(s),cross entropy on all data is 0.0071713\n",
      "After 2979 training step(s),cross entropy on all data is 0.00717061\n",
      "After 2980 training step(s),cross entropy on all data is 0.00716999\n",
      "After 2981 training step(s),cross entropy on all data is 0.00716943\n",
      "After 2982 training step(s),cross entropy on all data is 0.00716892\n",
      "After 2983 training step(s),cross entropy on all data is 0.00716649\n",
      "After 2984 training step(s),cross entropy on all data is 0.00716429\n",
      "After 2985 training step(s),cross entropy on all data is 0.00716231\n",
      "After 2986 training step(s),cross entropy on all data is 0.00716053\n",
      "After 2987 training step(s),cross entropy on all data is 0.00715893\n",
      "After 2988 training step(s),cross entropy on all data is 0.00715749\n",
      "After 2989 training step(s),cross entropy on all data is 0.00715619\n",
      "After 2990 training step(s),cross entropy on all data is 0.00715502\n",
      "After 2991 training step(s),cross entropy on all data is 0.00715397\n",
      "After 2992 training step(s),cross entropy on all data is 0.00715302\n",
      "After 2993 training step(s),cross entropy on all data is 0.00715216\n",
      "After 2994 training step(s),cross entropy on all data is 0.00715139\n",
      "After 2995 training step(s),cross entropy on all data is 0.0071507\n",
      "After 2996 training step(s),cross entropy on all data is 0.00715008\n",
      "After 2997 training step(s),cross entropy on all data is 0.00714952\n",
      "After 2998 training step(s),cross entropy on all data is 0.00714901\n",
      "After 2999 training step(s),cross entropy on all data is 0.00714656\n",
      "After 3000 training step(s),cross entropy on all data is 0.00714436\n",
      "After 3001 training step(s),cross entropy on all data is 0.00714238\n",
      "After 3002 training step(s),cross entropy on all data is 0.00714059\n",
      "After 3003 training step(s),cross entropy on all data is 0.00713898\n",
      "After 3004 training step(s),cross entropy on all data is 0.00713753\n",
      "After 3005 training step(s),cross entropy on all data is 0.00713623\n",
      "After 3006 training step(s),cross entropy on all data is 0.00713506\n",
      "After 3007 training step(s),cross entropy on all data is 0.007134\n",
      "After 3008 training step(s),cross entropy on all data is 0.00713305\n",
      "After 3009 training step(s),cross entropy on all data is 0.00713219\n",
      "After 3010 training step(s),cross entropy on all data is 0.00713142\n",
      "After 3011 training step(s),cross entropy on all data is 0.00713073\n",
      "After 3012 training step(s),cross entropy on all data is 0.0071301\n",
      "After 3013 training step(s),cross entropy on all data is 0.00712954\n",
      "After 3014 training step(s),cross entropy on all data is 0.00712903\n",
      "After 3015 training step(s),cross entropy on all data is 0.00712657\n",
      "After 3016 training step(s),cross entropy on all data is 0.00712436\n",
      "After 3017 training step(s),cross entropy on all data is 0.00712237\n",
      "After 3018 training step(s),cross entropy on all data is 0.00712058\n",
      "After 3019 training step(s),cross entropy on all data is 0.00711897\n",
      "After 3020 training step(s),cross entropy on all data is 0.00711752\n",
      "After 3021 training step(s),cross entropy on all data is 0.00711621\n",
      "After 3022 training step(s),cross entropy on all data is 0.00711503\n",
      "After 3023 training step(s),cross entropy on all data is 0.00711397\n",
      "After 3024 training step(s),cross entropy on all data is 0.00711301\n",
      "After 3025 training step(s),cross entropy on all data is 0.00711215\n",
      "After 3026 training step(s),cross entropy on all data is 0.00711138\n",
      "After 3027 training step(s),cross entropy on all data is 0.00711068\n",
      "After 3028 training step(s),cross entropy on all data is 0.00711005\n",
      "After 3029 training step(s),cross entropy on all data is 0.00710949\n",
      "After 3030 training step(s),cross entropy on all data is 0.00710898\n",
      "After 3031 training step(s),cross entropy on all data is 0.00710652\n",
      "After 3032 training step(s),cross entropy on all data is 0.0071043\n",
      "After 3033 training step(s),cross entropy on all data is 0.0071023\n",
      "After 3034 training step(s),cross entropy on all data is 0.0071005\n",
      "After 3035 training step(s),cross entropy on all data is 0.00709889\n",
      "After 3036 training step(s),cross entropy on all data is 0.00709743\n",
      "After 3037 training step(s),cross entropy on all data is 0.00709611\n",
      "After 3038 training step(s),cross entropy on all data is 0.00709493\n",
      "After 3039 training step(s),cross entropy on all data is 0.00709387\n",
      "After 3040 training step(s),cross entropy on all data is 0.00709291\n",
      "After 3041 training step(s),cross entropy on all data is 0.00709205\n",
      "After 3042 training step(s),cross entropy on all data is 0.00709127\n",
      "After 3043 training step(s),cross entropy on all data is 0.00709057\n",
      "After 3044 training step(s),cross entropy on all data is 0.00708994\n",
      "After 3045 training step(s),cross entropy on all data is 0.00708937\n",
      "After 3046 training step(s),cross entropy on all data is 0.00708886\n",
      "After 3047 training step(s),cross entropy on all data is 0.00708639\n",
      "After 3048 training step(s),cross entropy on all data is 0.00708417\n",
      "After 3049 training step(s),cross entropy on all data is 0.00708216\n",
      "After 3050 training step(s),cross entropy on all data is 0.00708036\n",
      "After 3051 training step(s),cross entropy on all data is 0.00707874\n",
      "After 3052 training step(s),cross entropy on all data is 0.00707727\n",
      "After 3053 training step(s),cross entropy on all data is 0.00707596\n",
      "After 3054 training step(s),cross entropy on all data is 0.00707477\n",
      "After 3055 training step(s),cross entropy on all data is 0.0070737\n",
      "After 3056 training step(s),cross entropy on all data is 0.00707274\n",
      "After 3057 training step(s),cross entropy on all data is 0.00707187\n",
      "After 3058 training step(s),cross entropy on all data is 0.0070711\n",
      "After 3059 training step(s),cross entropy on all data is 0.00707039\n",
      "After 3060 training step(s),cross entropy on all data is 0.00706976\n",
      "After 3061 training step(s),cross entropy on all data is 0.00706919\n",
      "After 3062 training step(s),cross entropy on all data is 0.00706868\n",
      "After 3063 training step(s),cross entropy on all data is 0.0070662\n",
      "After 3064 training step(s),cross entropy on all data is 0.00706397\n",
      "After 3065 training step(s),cross entropy on all data is 0.00706196\n",
      "After 3066 training step(s),cross entropy on all data is 0.00706015\n",
      "After 3067 training step(s),cross entropy on all data is 0.00705852\n",
      "After 3068 training step(s),cross entropy on all data is 0.00705705\n",
      "After 3069 training step(s),cross entropy on all data is 0.00705573\n",
      "After 3070 training step(s),cross entropy on all data is 0.00705454\n",
      "After 3071 training step(s),cross entropy on all data is 0.00705347\n",
      "After 3072 training step(s),cross entropy on all data is 0.0070525\n",
      "After 3073 training step(s),cross entropy on all data is 0.00705163\n",
      "After 3074 training step(s),cross entropy on all data is 0.00705085\n",
      "After 3075 training step(s),cross entropy on all data is 0.00705015\n",
      "After 3076 training step(s),cross entropy on all data is 0.00704951\n",
      "After 3077 training step(s),cross entropy on all data is 0.00704894\n",
      "After 3078 training step(s),cross entropy on all data is 0.00704843\n",
      "After 3079 training step(s),cross entropy on all data is 0.00704594\n",
      "After 3080 training step(s),cross entropy on all data is 0.0070437\n",
      "After 3081 training step(s),cross entropy on all data is 0.00704168\n",
      "After 3082 training step(s),cross entropy on all data is 0.00703987\n",
      "After 3083 training step(s),cross entropy on all data is 0.00703823\n",
      "After 3084 training step(s),cross entropy on all data is 0.00703676\n",
      "After 3085 training step(s),cross entropy on all data is 0.00703544\n",
      "After 3086 training step(s),cross entropy on all data is 0.00703424\n",
      "After 3087 training step(s),cross entropy on all data is 0.00703317\n",
      "After 3088 training step(s),cross entropy on all data is 0.0070322\n",
      "After 3089 training step(s),cross entropy on all data is 0.00703133\n",
      "After 3090 training step(s),cross entropy on all data is 0.00703054\n",
      "After 3091 training step(s),cross entropy on all data is 0.00702984\n",
      "After 3092 training step(s),cross entropy on all data is 0.0070292\n",
      "After 3093 training step(s),cross entropy on all data is 0.00702863\n",
      "After 3094 training step(s),cross entropy on all data is 0.00702811\n",
      "After 3095 training step(s),cross entropy on all data is 0.00702562\n",
      "After 3096 training step(s),cross entropy on all data is 0.00702337\n",
      "After 3097 training step(s),cross entropy on all data is 0.00702135\n",
      "After 3098 training step(s),cross entropy on all data is 0.00701952\n",
      "After 3099 training step(s),cross entropy on all data is 0.00701788\n",
      "After 3100 training step(s),cross entropy on all data is 0.00701641\n",
      "After 3101 training step(s),cross entropy on all data is 0.00701508\n",
      "After 3102 training step(s),cross entropy on all data is 0.00701388\n",
      "After 3103 training step(s),cross entropy on all data is 0.0070128\n",
      "After 3104 training step(s),cross entropy on all data is 0.00701183\n",
      "After 3105 training step(s),cross entropy on all data is 0.00701096\n",
      "After 3106 training step(s),cross entropy on all data is 0.00701017\n",
      "After 3107 training step(s),cross entropy on all data is 0.00700946\n",
      "After 3108 training step(s),cross entropy on all data is 0.00700882\n",
      "After 3109 training step(s),cross entropy on all data is 0.00700825\n",
      "After 3110 training step(s),cross entropy on all data is 0.00700773\n",
      "After 3111 training step(s),cross entropy on all data is 0.00700523\n",
      "After 3112 training step(s),cross entropy on all data is 0.00700297\n",
      "After 3113 training step(s),cross entropy on all data is 0.00700094\n",
      "After 3114 training step(s),cross entropy on all data is 0.00699912\n",
      "After 3115 training step(s),cross entropy on all data is 0.00699747\n",
      "After 3116 training step(s),cross entropy on all data is 0.00699599\n",
      "After 3117 training step(s),cross entropy on all data is 0.00699466\n",
      "After 3118 training step(s),cross entropy on all data is 0.00699345\n",
      "After 3119 training step(s),cross entropy on all data is 0.00699237\n",
      "After 3120 training step(s),cross entropy on all data is 0.0069914\n",
      "After 3121 training step(s),cross entropy on all data is 0.00699052\n",
      "After 3122 training step(s),cross entropy on all data is 0.00698973\n",
      "After 3123 training step(s),cross entropy on all data is 0.00698902\n",
      "After 3124 training step(s),cross entropy on all data is 0.00698838\n",
      "After 3125 training step(s),cross entropy on all data is 0.0069878\n",
      "After 3126 training step(s),cross entropy on all data is 0.00698728\n",
      "After 3127 training step(s),cross entropy on all data is 0.00698477\n",
      "After 3128 training step(s),cross entropy on all data is 0.00698251\n",
      "After 3129 training step(s),cross entropy on all data is 0.00698048\n",
      "After 3130 training step(s),cross entropy on all data is 0.00697864\n",
      "After 3131 training step(s),cross entropy on all data is 0.00697699\n",
      "After 3132 training step(s),cross entropy on all data is 0.00697551\n",
      "After 3133 training step(s),cross entropy on all data is 0.00697417\n",
      "After 3134 training step(s),cross entropy on all data is 0.00697296\n",
      "After 3135 training step(s),cross entropy on all data is 0.00697188\n",
      "After 3136 training step(s),cross entropy on all data is 0.0069709\n",
      "After 3137 training step(s),cross entropy on all data is 0.00697002\n",
      "After 3138 training step(s),cross entropy on all data is 0.00696923\n",
      "After 3139 training step(s),cross entropy on all data is 0.00696852\n",
      "After 3140 training step(s),cross entropy on all data is 0.00696787\n",
      "After 3141 training step(s),cross entropy on all data is 0.00696729\n",
      "After 3142 training step(s),cross entropy on all data is 0.00696677\n",
      "After 3143 training step(s),cross entropy on all data is 0.00696426\n",
      "After 3144 training step(s),cross entropy on all data is 0.00696199\n",
      "After 3145 training step(s),cross entropy on all data is 0.00695994\n",
      "After 3146 training step(s),cross entropy on all data is 0.00695811\n",
      "After 3147 training step(s),cross entropy on all data is 0.00695645\n",
      "After 3148 training step(s),cross entropy on all data is 0.00695496\n",
      "After 3149 training step(s),cross entropy on all data is 0.00695362\n",
      "After 3150 training step(s),cross entropy on all data is 0.00695241\n",
      "After 3151 training step(s),cross entropy on all data is 0.00695132\n",
      "After 3152 training step(s),cross entropy on all data is 0.00695034\n",
      "After 3153 training step(s),cross entropy on all data is 0.00694946\n",
      "After 3154 training step(s),cross entropy on all data is 0.00694866\n",
      "After 3155 training step(s),cross entropy on all data is 0.00694795\n",
      "After 3156 training step(s),cross entropy on all data is 0.0069473\n",
      "After 3157 training step(s),cross entropy on all data is 0.00694672\n",
      "After 3158 training step(s),cross entropy on all data is 0.0069462\n",
      "After 3159 training step(s),cross entropy on all data is 0.00694367\n",
      "After 3160 training step(s),cross entropy on all data is 0.0069414\n",
      "After 3161 training step(s),cross entropy on all data is 0.00693935\n",
      "After 3162 training step(s),cross entropy on all data is 0.0069375\n",
      "After 3163 training step(s),cross entropy on all data is 0.00693584\n",
      "After 3164 training step(s),cross entropy on all data is 0.00693435\n",
      "After 3165 training step(s),cross entropy on all data is 0.006933\n",
      "After 3166 training step(s),cross entropy on all data is 0.00693179\n",
      "After 3167 training step(s),cross entropy on all data is 0.0069307\n",
      "After 3168 training step(s),cross entropy on all data is 0.00692971\n",
      "After 3169 training step(s),cross entropy on all data is 0.00692883\n",
      "After 3170 training step(s),cross entropy on all data is 0.00692803\n",
      "After 3171 training step(s),cross entropy on all data is 0.00692731\n",
      "After 3172 training step(s),cross entropy on all data is 0.00692667\n",
      "After 3173 training step(s),cross entropy on all data is 0.00692609\n",
      "After 3174 training step(s),cross entropy on all data is 0.00692556\n",
      "After 3175 training step(s),cross entropy on all data is 0.00692303\n",
      "After 3176 training step(s),cross entropy on all data is 0.00692075\n",
      "After 3177 training step(s),cross entropy on all data is 0.00691869\n",
      "After 3178 training step(s),cross entropy on all data is 0.00691684\n",
      "After 3179 training step(s),cross entropy on all data is 0.00691517\n",
      "After 3180 training step(s),cross entropy on all data is 0.00691368\n",
      "After 3181 training step(s),cross entropy on all data is 0.00691232\n",
      "After 3182 training step(s),cross entropy on all data is 0.00691111\n",
      "After 3183 training step(s),cross entropy on all data is 0.00691001\n",
      "After 3184 training step(s),cross entropy on all data is 0.00690903\n",
      "After 3185 training step(s),cross entropy on all data is 0.00690814\n",
      "After 3186 training step(s),cross entropy on all data is 0.00690734\n",
      "After 3187 training step(s),cross entropy on all data is 0.00690662\n",
      "After 3188 training step(s),cross entropy on all data is 0.00690597\n",
      "After 3189 training step(s),cross entropy on all data is 0.00690539\n",
      "After 3190 training step(s),cross entropy on all data is 0.00690486\n",
      "After 3191 training step(s),cross entropy on all data is 0.00690232\n",
      "After 3192 training step(s),cross entropy on all data is 0.00690003\n",
      "After 3193 training step(s),cross entropy on all data is 0.00689797\n",
      "After 3194 training step(s),cross entropy on all data is 0.00689611\n",
      "After 3195 training step(s),cross entropy on all data is 0.00689444\n",
      "After 3196 training step(s),cross entropy on all data is 0.00689294\n",
      "After 3197 training step(s),cross entropy on all data is 0.00689159\n",
      "After 3198 training step(s),cross entropy on all data is 0.00689036\n",
      "After 3199 training step(s),cross entropy on all data is 0.00688927\n",
      "After 3200 training step(s),cross entropy on all data is 0.00688828\n",
      "After 3201 training step(s),cross entropy on all data is 0.00688739\n",
      "After 3202 training step(s),cross entropy on all data is 0.00688659\n",
      "After 3203 training step(s),cross entropy on all data is 0.00688586\n",
      "After 3204 training step(s),cross entropy on all data is 0.00688521\n",
      "After 3205 training step(s),cross entropy on all data is 0.00688463\n",
      "After 3206 training step(s),cross entropy on all data is 0.0068841\n",
      "After 3207 training step(s),cross entropy on all data is 0.00688155\n",
      "After 3208 training step(s),cross entropy on all data is 0.00687926\n",
      "After 3209 training step(s),cross entropy on all data is 0.00687719\n",
      "After 3210 training step(s),cross entropy on all data is 0.00687533\n",
      "After 3211 training step(s),cross entropy on all data is 0.00687365\n",
      "After 3212 training step(s),cross entropy on all data is 0.00687214\n",
      "After 3213 training step(s),cross entropy on all data is 0.00687078\n",
      "After 3214 training step(s),cross entropy on all data is 0.00686956\n",
      "After 3215 training step(s),cross entropy on all data is 0.00686846\n",
      "After 3216 training step(s),cross entropy on all data is 0.00686747\n",
      "After 3217 training step(s),cross entropy on all data is 0.00686657\n",
      "After 3218 training step(s),cross entropy on all data is 0.00686577\n",
      "After 3219 training step(s),cross entropy on all data is 0.00686505\n",
      "After 3220 training step(s),cross entropy on all data is 0.00686439\n",
      "After 3221 training step(s),cross entropy on all data is 0.00686381\n",
      "After 3222 training step(s),cross entropy on all data is 0.00686328\n",
      "After 3223 training step(s),cross entropy on all data is 0.00686072\n",
      "After 3224 training step(s),cross entropy on all data is 0.00685842\n",
      "After 3225 training step(s),cross entropy on all data is 0.00685634\n",
      "After 3226 training step(s),cross entropy on all data is 0.00685448\n",
      "After 3227 training step(s),cross entropy on all data is 0.0068528\n",
      "After 3228 training step(s),cross entropy on all data is 0.00685128\n",
      "After 3229 training step(s),cross entropy on all data is 0.00684992\n",
      "After 3230 training step(s),cross entropy on all data is 0.00684869\n",
      "After 3231 training step(s),cross entropy on all data is 0.00684759\n",
      "After 3232 training step(s),cross entropy on all data is 0.0068466\n",
      "After 3233 training step(s),cross entropy on all data is 0.0068457\n",
      "After 3234 training step(s),cross entropy on all data is 0.00684489\n",
      "After 3235 training step(s),cross entropy on all data is 0.00684417\n",
      "After 3236 training step(s),cross entropy on all data is 0.00684351\n",
      "After 3237 training step(s),cross entropy on all data is 0.00684292\n",
      "After 3238 training step(s),cross entropy on all data is 0.00684239\n",
      "After 3239 training step(s),cross entropy on all data is 0.00683983\n",
      "After 3240 training step(s),cross entropy on all data is 0.00683752\n",
      "After 3241 training step(s),cross entropy on all data is 0.00683544\n",
      "After 3242 training step(s),cross entropy on all data is 0.00683357\n",
      "After 3243 training step(s),cross entropy on all data is 0.00683188\n",
      "After 3244 training step(s),cross entropy on all data is 0.00683036\n",
      "After 3245 training step(s),cross entropy on all data is 0.006829\n",
      "After 3246 training step(s),cross entropy on all data is 0.00682777\n",
      "After 3247 training step(s),cross entropy on all data is 0.00682666\n",
      "After 3248 training step(s),cross entropy on all data is 0.00682566\n",
      "After 3249 training step(s),cross entropy on all data is 0.00682476\n",
      "After 3250 training step(s),cross entropy on all data is 0.00682396\n",
      "After 3251 training step(s),cross entropy on all data is 0.00682323\n",
      "After 3252 training step(s),cross entropy on all data is 0.00682257\n",
      "After 3253 training step(s),cross entropy on all data is 0.00682198\n",
      "After 3254 training step(s),cross entropy on all data is 0.00682145\n",
      "After 3255 training step(s),cross entropy on all data is 0.00681888\n",
      "After 3256 training step(s),cross entropy on all data is 0.00681656\n",
      "After 3257 training step(s),cross entropy on all data is 0.00681447\n",
      "After 3258 training step(s),cross entropy on all data is 0.0068126\n",
      "After 3259 training step(s),cross entropy on all data is 0.00681091\n",
      "After 3260 training step(s),cross entropy on all data is 0.00680939\n",
      "After 3261 training step(s),cross entropy on all data is 0.00680802\n",
      "After 3262 training step(s),cross entropy on all data is 0.00680678\n",
      "After 3263 training step(s),cross entropy on all data is 0.00680567\n",
      "After 3264 training step(s),cross entropy on all data is 0.00680467\n",
      "After 3265 training step(s),cross entropy on all data is 0.00680377\n",
      "After 3266 training step(s),cross entropy on all data is 0.00680296\n",
      "After 3267 training step(s),cross entropy on all data is 0.00680223\n",
      "After 3268 training step(s),cross entropy on all data is 0.00680157\n",
      "After 3269 training step(s),cross entropy on all data is 0.00680098\n",
      "After 3270 training step(s),cross entropy on all data is 0.00680044\n",
      "After 3271 training step(s),cross entropy on all data is 0.00679786\n",
      "After 3272 training step(s),cross entropy on all data is 0.00679554\n",
      "After 3273 training step(s),cross entropy on all data is 0.00679345\n",
      "After 3274 training step(s),cross entropy on all data is 0.00679157\n",
      "After 3275 training step(s),cross entropy on all data is 0.00678987\n",
      "After 3276 training step(s),cross entropy on all data is 0.00678835\n",
      "After 3277 training step(s),cross entropy on all data is 0.00678697\n",
      "After 3278 training step(s),cross entropy on all data is 0.00678574\n",
      "After 3279 training step(s),cross entropy on all data is 0.00678462\n",
      "After 3280 training step(s),cross entropy on all data is 0.00678362\n",
      "After 3281 training step(s),cross entropy on all data is 0.00678271\n",
      "After 3282 training step(s),cross entropy on all data is 0.0067819\n",
      "After 3283 training step(s),cross entropy on all data is 0.00678117\n",
      "After 3284 training step(s),cross entropy on all data is 0.00678051\n",
      "After 3285 training step(s),cross entropy on all data is 0.00677991\n",
      "After 3286 training step(s),cross entropy on all data is 0.00677938\n",
      "After 3287 training step(s),cross entropy on all data is 0.00677679\n",
      "After 3288 training step(s),cross entropy on all data is 0.00677446\n",
      "After 3289 training step(s),cross entropy on all data is 0.00677237\n",
      "After 3290 training step(s),cross entropy on all data is 0.00677048\n",
      "After 3291 training step(s),cross entropy on all data is 0.00676878\n",
      "After 3292 training step(s),cross entropy on all data is 0.00676725\n",
      "After 3293 training step(s),cross entropy on all data is 0.00676587\n",
      "After 3294 training step(s),cross entropy on all data is 0.00676463\n",
      "After 3295 training step(s),cross entropy on all data is 0.00676351\n",
      "After 3296 training step(s),cross entropy on all data is 0.00676251\n",
      "After 3297 training step(s),cross entropy on all data is 0.0067616\n",
      "After 3298 training step(s),cross entropy on all data is 0.00676079\n",
      "After 3299 training step(s),cross entropy on all data is 0.00676005\n",
      "After 3300 training step(s),cross entropy on all data is 0.00675939\n",
      "After 3301 training step(s),cross entropy on all data is 0.00675879\n",
      "After 3302 training step(s),cross entropy on all data is 0.00675826\n",
      "After 3303 training step(s),cross entropy on all data is 0.00675567\n",
      "After 3304 training step(s),cross entropy on all data is 0.00675333\n",
      "After 3305 training step(s),cross entropy on all data is 0.00675123\n",
      "After 3306 training step(s),cross entropy on all data is 0.00674933\n",
      "After 3307 training step(s),cross entropy on all data is 0.00674763\n",
      "After 3308 training step(s),cross entropy on all data is 0.00674609\n",
      "After 3309 training step(s),cross entropy on all data is 0.00674471\n",
      "After 3310 training step(s),cross entropy on all data is 0.00674347\n",
      "After 3311 training step(s),cross entropy on all data is 0.00674235\n",
      "After 3312 training step(s),cross entropy on all data is 0.00674134\n",
      "After 3313 training step(s),cross entropy on all data is 0.00674043\n",
      "After 3314 training step(s),cross entropy on all data is 0.00673961\n",
      "After 3315 training step(s),cross entropy on all data is 0.00673888\n",
      "After 3316 training step(s),cross entropy on all data is 0.00673821\n",
      "After 3317 training step(s),cross entropy on all data is 0.00673762\n",
      "After 3318 training step(s),cross entropy on all data is 0.00673708\n",
      "After 3319 training step(s),cross entropy on all data is 0.00673448\n",
      "After 3320 training step(s),cross entropy on all data is 0.00673214\n",
      "After 3321 training step(s),cross entropy on all data is 0.00673003\n",
      "After 3322 training step(s),cross entropy on all data is 0.00672813\n",
      "After 3323 training step(s),cross entropy on all data is 0.00672642\n",
      "After 3324 training step(s),cross entropy on all data is 0.00672488\n",
      "After 3325 training step(s),cross entropy on all data is 0.0067235\n",
      "After 3326 training step(s),cross entropy on all data is 0.00672225\n",
      "After 3327 training step(s),cross entropy on all data is 0.00672113\n",
      "After 3328 training step(s),cross entropy on all data is 0.00672011\n",
      "After 3329 training step(s),cross entropy on all data is 0.0067192\n",
      "After 3330 training step(s),cross entropy on all data is 0.00671838\n",
      "After 3331 training step(s),cross entropy on all data is 0.00671765\n",
      "After 3332 training step(s),cross entropy on all data is 0.00671698\n",
      "After 3333 training step(s),cross entropy on all data is 0.00671638\n",
      "After 3334 training step(s),cross entropy on all data is 0.00671584\n",
      "After 3335 training step(s),cross entropy on all data is 0.00671324\n",
      "After 3336 training step(s),cross entropy on all data is 0.00671089\n",
      "After 3337 training step(s),cross entropy on all data is 0.00670877\n",
      "After 3338 training step(s),cross entropy on all data is 0.00670687\n",
      "After 3339 training step(s),cross entropy on all data is 0.00670516\n",
      "After 3340 training step(s),cross entropy on all data is 0.00670361\n",
      "After 3341 training step(s),cross entropy on all data is 0.00670222\n",
      "After 3342 training step(s),cross entropy on all data is 0.00670097\n",
      "After 3343 training step(s),cross entropy on all data is 0.00669985\n",
      "After 3344 training step(s),cross entropy on all data is 0.00669883\n",
      "After 3345 training step(s),cross entropy on all data is 0.00669792\n",
      "After 3346 training step(s),cross entropy on all data is 0.0066971\n",
      "After 3347 training step(s),cross entropy on all data is 0.00669636\n",
      "After 3348 training step(s),cross entropy on all data is 0.00669569\n",
      "After 3349 training step(s),cross entropy on all data is 0.00669509\n",
      "After 3350 training step(s),cross entropy on all data is 0.00669455\n",
      "After 3351 training step(s),cross entropy on all data is 0.00669194\n",
      "After 3352 training step(s),cross entropy on all data is 0.00668958\n",
      "After 3353 training step(s),cross entropy on all data is 0.00668746\n",
      "After 3354 training step(s),cross entropy on all data is 0.00668555\n",
      "After 3355 training step(s),cross entropy on all data is 0.00668384\n",
      "After 3356 training step(s),cross entropy on all data is 0.00668229\n",
      "After 3357 training step(s),cross entropy on all data is 0.0066809\n",
      "After 3358 training step(s),cross entropy on all data is 0.00667964\n",
      "After 3359 training step(s),cross entropy on all data is 0.00667851\n",
      "After 3360 training step(s),cross entropy on all data is 0.00667749\n",
      "After 3361 training step(s),cross entropy on all data is 0.00667658\n",
      "After 3362 training step(s),cross entropy on all data is 0.00667575\n",
      "After 3363 training step(s),cross entropy on all data is 0.00667501\n",
      "After 3364 training step(s),cross entropy on all data is 0.00667434\n",
      "After 3365 training step(s),cross entropy on all data is 0.00667374\n",
      "After 3366 training step(s),cross entropy on all data is 0.0066732\n",
      "After 3367 training step(s),cross entropy on all data is 0.00667058\n",
      "After 3368 training step(s),cross entropy on all data is 0.00666822\n",
      "After 3369 training step(s),cross entropy on all data is 0.00666609\n",
      "After 3370 training step(s),cross entropy on all data is 0.00666418\n",
      "After 3371 training step(s),cross entropy on all data is 0.00666246\n",
      "After 3372 training step(s),cross entropy on all data is 0.00666091\n",
      "After 3373 training step(s),cross entropy on all data is 0.00665951\n",
      "After 3374 training step(s),cross entropy on all data is 0.00665825\n",
      "After 3375 training step(s),cross entropy on all data is 0.00665712\n",
      "After 3376 training step(s),cross entropy on all data is 0.0066561\n",
      "After 3377 training step(s),cross entropy on all data is 0.00665518\n",
      "After 3378 training step(s),cross entropy on all data is 0.00665435\n",
      "After 3379 training step(s),cross entropy on all data is 0.00665361\n",
      "After 3380 training step(s),cross entropy on all data is 0.00665294\n",
      "After 3381 training step(s),cross entropy on all data is 0.00665234\n",
      "After 3382 training step(s),cross entropy on all data is 0.00665179\n",
      "After 3383 training step(s),cross entropy on all data is 0.00664917\n",
      "After 3384 training step(s),cross entropy on all data is 0.0066468\n",
      "After 3385 training step(s),cross entropy on all data is 0.00664467\n",
      "After 3386 training step(s),cross entropy on all data is 0.00664275\n",
      "After 3387 training step(s),cross entropy on all data is 0.00664102\n",
      "After 3388 training step(s),cross entropy on all data is 0.00663947\n",
      "After 3389 training step(s),cross entropy on all data is 0.00663807\n",
      "After 3390 training step(s),cross entropy on all data is 0.00663681\n",
      "After 3391 training step(s),cross entropy on all data is 0.00663567\n",
      "After 3392 training step(s),cross entropy on all data is 0.00663465\n",
      "After 3393 training step(s),cross entropy on all data is 0.00663373\n",
      "After 3394 training step(s),cross entropy on all data is 0.0066329\n",
      "After 3395 training step(s),cross entropy on all data is 0.00663216\n",
      "After 3396 training step(s),cross entropy on all data is 0.00663148\n",
      "After 3397 training step(s),cross entropy on all data is 0.00663088\n",
      "After 3398 training step(s),cross entropy on all data is 0.00663033\n",
      "After 3399 training step(s),cross entropy on all data is 0.0066277\n",
      "After 3400 training step(s),cross entropy on all data is 0.00662533\n",
      "After 3401 training step(s),cross entropy on all data is 0.00662319\n",
      "After 3402 training step(s),cross entropy on all data is 0.00662127\n",
      "After 3403 training step(s),cross entropy on all data is 0.00661954\n",
      "After 3404 training step(s),cross entropy on all data is 0.00661798\n",
      "After 3405 training step(s),cross entropy on all data is 0.00661657\n",
      "After 3406 training step(s),cross entropy on all data is 0.00661531\n",
      "After 3407 training step(s),cross entropy on all data is 0.00661417\n",
      "After 3408 training step(s),cross entropy on all data is 0.00661315\n",
      "After 3409 training step(s),cross entropy on all data is 0.00661222\n",
      "After 3410 training step(s),cross entropy on all data is 0.00661139\n",
      "After 3411 training step(s),cross entropy on all data is 0.00661065\n",
      "After 3412 training step(s),cross entropy on all data is 0.00660997\n",
      "After 3413 training step(s),cross entropy on all data is 0.00660937\n",
      "After 3414 training step(s),cross entropy on all data is 0.00660882\n",
      "After 3415 training step(s),cross entropy on all data is 0.00660618\n",
      "After 3416 training step(s),cross entropy on all data is 0.0066038\n",
      "After 3417 training step(s),cross entropy on all data is 0.00660166\n",
      "After 3418 training step(s),cross entropy on all data is 0.00659973\n",
      "After 3419 training step(s),cross entropy on all data is 0.00659799\n",
      "After 3420 training step(s),cross entropy on all data is 0.00659643\n",
      "After 3421 training step(s),cross entropy on all data is 0.00659502\n",
      "After 3422 training step(s),cross entropy on all data is 0.00659376\n",
      "After 3423 training step(s),cross entropy on all data is 0.00659262\n",
      "After 3424 training step(s),cross entropy on all data is 0.00659159\n",
      "After 3425 training step(s),cross entropy on all data is 0.00659066\n",
      "After 3426 training step(s),cross entropy on all data is 0.00658983\n",
      "After 3427 training step(s),cross entropy on all data is 0.00658908\n",
      "After 3428 training step(s),cross entropy on all data is 0.0065884\n",
      "After 3429 training step(s),cross entropy on all data is 0.0065878\n",
      "After 3430 training step(s),cross entropy on all data is 0.00658725\n",
      "After 3431 training step(s),cross entropy on all data is 0.0065846\n",
      "After 3432 training step(s),cross entropy on all data is 0.00658222\n",
      "After 3433 training step(s),cross entropy on all data is 0.00658007\n",
      "After 3434 training step(s),cross entropy on all data is 0.00657814\n",
      "After 3435 training step(s),cross entropy on all data is 0.0065764\n",
      "After 3436 training step(s),cross entropy on all data is 0.00657483\n",
      "After 3437 training step(s),cross entropy on all data is 0.00657342\n",
      "After 3438 training step(s),cross entropy on all data is 0.00657215\n",
      "After 3439 training step(s),cross entropy on all data is 0.00657101\n",
      "After 3440 training step(s),cross entropy on all data is 0.00656998\n",
      "After 3441 training step(s),cross entropy on all data is 0.00656905\n",
      "After 3442 training step(s),cross entropy on all data is 0.00656822\n",
      "After 3443 training step(s),cross entropy on all data is 0.00656746\n",
      "After 3444 training step(s),cross entropy on all data is 0.00656679\n",
      "After 3445 training step(s),cross entropy on all data is 0.00656618\n",
      "After 3446 training step(s),cross entropy on all data is 0.00656563\n",
      "After 3447 training step(s),cross entropy on all data is 0.00656297\n",
      "After 3448 training step(s),cross entropy on all data is 0.00656058\n",
      "After 3449 training step(s),cross entropy on all data is 0.00655843\n",
      "After 3450 training step(s),cross entropy on all data is 0.0065565\n",
      "After 3451 training step(s),cross entropy on all data is 0.00655475\n",
      "After 3452 training step(s),cross entropy on all data is 0.00655318\n",
      "After 3453 training step(s),cross entropy on all data is 0.00655177\n",
      "After 3454 training step(s),cross entropy on all data is 0.00655049\n",
      "After 3455 training step(s),cross entropy on all data is 0.00654935\n",
      "After 3456 training step(s),cross entropy on all data is 0.00654831\n",
      "After 3457 training step(s),cross entropy on all data is 0.00654738\n",
      "After 3458 training step(s),cross entropy on all data is 0.00654655\n",
      "After 3459 training step(s),cross entropy on all data is 0.00654579\n",
      "After 3460 training step(s),cross entropy on all data is 0.00654512\n",
      "After 3461 training step(s),cross entropy on all data is 0.0065445\n",
      "After 3462 training step(s),cross entropy on all data is 0.00654395\n",
      "After 3463 training step(s),cross entropy on all data is 0.00654129\n",
      "After 3464 training step(s),cross entropy on all data is 0.0065389\n",
      "After 3465 training step(s),cross entropy on all data is 0.00653674\n",
      "After 3466 training step(s),cross entropy on all data is 0.0065348\n",
      "After 3467 training step(s),cross entropy on all data is 0.00653305\n",
      "After 3468 training step(s),cross entropy on all data is 0.00653148\n",
      "After 3469 training step(s),cross entropy on all data is 0.00653006\n",
      "After 3470 training step(s),cross entropy on all data is 0.00652878\n",
      "After 3471 training step(s),cross entropy on all data is 0.00652763\n",
      "After 3472 training step(s),cross entropy on all data is 0.0065266\n",
      "After 3473 training step(s),cross entropy on all data is 0.00652567\n",
      "After 3474 training step(s),cross entropy on all data is 0.00652483\n",
      "After 3475 training step(s),cross entropy on all data is 0.00652407\n",
      "After 3476 training step(s),cross entropy on all data is 0.00652339\n",
      "After 3477 training step(s),cross entropy on all data is 0.00652278\n",
      "After 3478 training step(s),cross entropy on all data is 0.00652223\n",
      "After 3479 training step(s),cross entropy on all data is 0.00651956\n",
      "After 3480 training step(s),cross entropy on all data is 0.00651716\n",
      "After 3481 training step(s),cross entropy on all data is 0.006515\n",
      "After 3482 training step(s),cross entropy on all data is 0.00651305\n",
      "After 3483 training step(s),cross entropy on all data is 0.0065113\n",
      "After 3484 training step(s),cross entropy on all data is 0.00650972\n",
      "After 3485 training step(s),cross entropy on all data is 0.0065083\n",
      "After 3486 training step(s),cross entropy on all data is 0.00650702\n",
      "After 3487 training step(s),cross entropy on all data is 0.00650587\n",
      "After 3488 training step(s),cross entropy on all data is 0.00650483\n",
      "After 3489 training step(s),cross entropy on all data is 0.0065039\n",
      "After 3490 training step(s),cross entropy on all data is 0.00650306\n",
      "After 3491 training step(s),cross entropy on all data is 0.0065023\n",
      "After 3492 training step(s),cross entropy on all data is 0.00650162\n",
      "After 3493 training step(s),cross entropy on all data is 0.006501\n",
      "After 3494 training step(s),cross entropy on all data is 0.00650045\n",
      "After 3495 training step(s),cross entropy on all data is 0.00649778\n",
      "After 3496 training step(s),cross entropy on all data is 0.00649537\n",
      "After 3497 training step(s),cross entropy on all data is 0.0064932\n",
      "After 3498 training step(s),cross entropy on all data is 0.00649125\n",
      "After 3499 training step(s),cross entropy on all data is 0.00648949\n",
      "After 3500 training step(s),cross entropy on all data is 0.00648791\n",
      "After 3501 training step(s),cross entropy on all data is 0.00648649\n",
      "After 3502 training step(s),cross entropy on all data is 0.00648521\n",
      "After 3503 training step(s),cross entropy on all data is 0.00648405\n",
      "After 3504 training step(s),cross entropy on all data is 0.00648301\n",
      "After 3505 training step(s),cross entropy on all data is 0.00648208\n",
      "After 3506 training step(s),cross entropy on all data is 0.00648123\n",
      "After 3507 training step(s),cross entropy on all data is 0.00648047\n",
      "After 3508 training step(s),cross entropy on all data is 0.00647979\n",
      "After 3509 training step(s),cross entropy on all data is 0.00647917\n",
      "After 3510 training step(s),cross entropy on all data is 0.00647862\n",
      "After 3511 training step(s),cross entropy on all data is 0.00647594\n",
      "After 3512 training step(s),cross entropy on all data is 0.00647353\n",
      "After 3513 training step(s),cross entropy on all data is 0.00647136\n",
      "After 3514 training step(s),cross entropy on all data is 0.0064694\n",
      "After 3515 training step(s),cross entropy on all data is 0.00646764\n",
      "After 3516 training step(s),cross entropy on all data is 0.00646606\n",
      "After 3517 training step(s),cross entropy on all data is 0.00646463\n",
      "After 3518 training step(s),cross entropy on all data is 0.00646334\n",
      "After 3519 training step(s),cross entropy on all data is 0.00646219\n",
      "After 3520 training step(s),cross entropy on all data is 0.00646114\n",
      "After 3521 training step(s),cross entropy on all data is 0.00646021\n",
      "After 3522 training step(s),cross entropy on all data is 0.00645936\n",
      "After 3523 training step(s),cross entropy on all data is 0.0064586\n",
      "After 3524 training step(s),cross entropy on all data is 0.00645792\n",
      "After 3525 training step(s),cross entropy on all data is 0.0064573\n",
      "After 3526 training step(s),cross entropy on all data is 0.00645674\n",
      "After 3527 training step(s),cross entropy on all data is 0.00645406\n",
      "After 3528 training step(s),cross entropy on all data is 0.00645164\n",
      "After 3529 training step(s),cross entropy on all data is 0.00644946\n",
      "After 3530 training step(s),cross entropy on all data is 0.0064475\n",
      "After 3531 training step(s),cross entropy on all data is 0.00644574\n",
      "After 3532 training step(s),cross entropy on all data is 0.00644415\n",
      "After 3533 training step(s),cross entropy on all data is 0.00644272\n",
      "After 3534 training step(s),cross entropy on all data is 0.00644143\n",
      "After 3535 training step(s),cross entropy on all data is 0.00644027\n",
      "After 3536 training step(s),cross entropy on all data is 0.00643923\n",
      "After 3537 training step(s),cross entropy on all data is 0.00643829\n",
      "After 3538 training step(s),cross entropy on all data is 0.00643744\n",
      "After 3539 training step(s),cross entropy on all data is 0.00643668\n",
      "After 3540 training step(s),cross entropy on all data is 0.00643599\n",
      "After 3541 training step(s),cross entropy on all data is 0.00643537\n",
      "After 3542 training step(s),cross entropy on all data is 0.00643482\n",
      "After 3543 training step(s),cross entropy on all data is 0.00643212\n",
      "After 3544 training step(s),cross entropy on all data is 0.0064297\n",
      "After 3545 training step(s),cross entropy on all data is 0.00642752\n",
      "After 3546 training step(s),cross entropy on all data is 0.00642555\n",
      "After 3547 training step(s),cross entropy on all data is 0.00642378\n",
      "After 3548 training step(s),cross entropy on all data is 0.00642219\n",
      "After 3549 training step(s),cross entropy on all data is 0.00642076\n",
      "After 3550 training step(s),cross entropy on all data is 0.00641947\n",
      "After 3551 training step(s),cross entropy on all data is 0.0064183\n",
      "After 3552 training step(s),cross entropy on all data is 0.00641726\n",
      "After 3553 training step(s),cross entropy on all data is 0.00641632\n",
      "After 3554 training step(s),cross entropy on all data is 0.00641547\n",
      "After 3555 training step(s),cross entropy on all data is 0.0064147\n",
      "After 3556 training step(s),cross entropy on all data is 0.00641401\n",
      "After 3557 training step(s),cross entropy on all data is 0.0064134\n",
      "After 3558 training step(s),cross entropy on all data is 0.00641284\n",
      "After 3559 training step(s),cross entropy on all data is 0.00641014\n",
      "After 3560 training step(s),cross entropy on all data is 0.00640771\n",
      "After 3561 training step(s),cross entropy on all data is 0.00640552\n",
      "After 3562 training step(s),cross entropy on all data is 0.00640356\n",
      "After 3563 training step(s),cross entropy on all data is 0.00640178\n",
      "After 3564 training step(s),cross entropy on all data is 0.00640019\n",
      "After 3565 training step(s),cross entropy on all data is 0.00639875\n",
      "After 3566 training step(s),cross entropy on all data is 0.00639746\n",
      "After 3567 training step(s),cross entropy on all data is 0.00639629\n",
      "After 3568 training step(s),cross entropy on all data is 0.00639524\n",
      "After 3569 training step(s),cross entropy on all data is 0.0063943\n",
      "After 3570 training step(s),cross entropy on all data is 0.00639345\n",
      "After 3571 training step(s),cross entropy on all data is 0.00639268\n",
      "After 3572 training step(s),cross entropy on all data is 0.00639199\n",
      "After 3573 training step(s),cross entropy on all data is 0.00639137\n",
      "After 3574 training step(s),cross entropy on all data is 0.00639081\n",
      "After 3575 training step(s),cross entropy on all data is 0.00638811\n",
      "After 3576 training step(s),cross entropy on all data is 0.00638567\n",
      "After 3577 training step(s),cross entropy on all data is 0.00638348\n",
      "After 3578 training step(s),cross entropy on all data is 0.00638151\n",
      "After 3579 training step(s),cross entropy on all data is 0.00637973\n",
      "After 3580 training step(s),cross entropy on all data is 0.00637813\n",
      "After 3581 training step(s),cross entropy on all data is 0.00637669\n",
      "After 3582 training step(s),cross entropy on all data is 0.0063754\n",
      "After 3583 training step(s),cross entropy on all data is 0.00637423\n",
      "After 3584 training step(s),cross entropy on all data is 0.00637318\n",
      "After 3585 training step(s),cross entropy on all data is 0.00637223\n",
      "After 3586 training step(s),cross entropy on all data is 0.00637138\n",
      "After 3587 training step(s),cross entropy on all data is 0.00637061\n",
      "After 3588 training step(s),cross entropy on all data is 0.00636992\n",
      "After 3589 training step(s),cross entropy on all data is 0.0063693\n",
      "After 3590 training step(s),cross entropy on all data is 0.00636874\n",
      "After 3591 training step(s),cross entropy on all data is 0.00636603\n",
      "After 3592 training step(s),cross entropy on all data is 0.00636359\n",
      "After 3593 training step(s),cross entropy on all data is 0.00636139\n",
      "After 3594 training step(s),cross entropy on all data is 0.00635942\n",
      "After 3595 training step(s),cross entropy on all data is 0.00635764\n",
      "After 3596 training step(s),cross entropy on all data is 0.00635603\n",
      "After 3597 training step(s),cross entropy on all data is 0.00635459\n",
      "After 3598 training step(s),cross entropy on all data is 0.00635329\n",
      "After 3599 training step(s),cross entropy on all data is 0.00635212\n",
      "After 3600 training step(s),cross entropy on all data is 0.00635107\n",
      "After 3601 training step(s),cross entropy on all data is 0.00635012\n",
      "After 3602 training step(s),cross entropy on all data is 0.00634926\n",
      "After 3603 training step(s),cross entropy on all data is 0.0063485\n",
      "After 3604 training step(s),cross entropy on all data is 0.0063478\n",
      "After 3605 training step(s),cross entropy on all data is 0.00634718\n",
      "After 3606 training step(s),cross entropy on all data is 0.00634662\n",
      "After 3607 training step(s),cross entropy on all data is 0.0063439\n",
      "After 3608 training step(s),cross entropy on all data is 0.00634146\n",
      "After 3609 training step(s),cross entropy on all data is 0.00633926\n",
      "After 3610 training step(s),cross entropy on all data is 0.00633728\n",
      "After 3611 training step(s),cross entropy on all data is 0.00633549\n",
      "After 3612 training step(s),cross entropy on all data is 0.00633389\n",
      "After 3613 training step(s),cross entropy on all data is 0.00633244\n",
      "After 3614 training step(s),cross entropy on all data is 0.00633114\n",
      "After 3615 training step(s),cross entropy on all data is 0.00632996\n",
      "After 3616 training step(s),cross entropy on all data is 0.00632891\n",
      "After 3617 training step(s),cross entropy on all data is 0.00632796\n",
      "After 3618 training step(s),cross entropy on all data is 0.0063271\n",
      "After 3619 training step(s),cross entropy on all data is 0.00632633\n",
      "After 3620 training step(s),cross entropy on all data is 0.00632564\n",
      "After 3621 training step(s),cross entropy on all data is 0.00632501\n",
      "After 3622 training step(s),cross entropy on all data is 0.00632445\n",
      "After 3623 training step(s),cross entropy on all data is 0.00632173\n",
      "After 3624 training step(s),cross entropy on all data is 0.00631928\n",
      "After 3625 training step(s),cross entropy on all data is 0.00631707\n",
      "After 3626 training step(s),cross entropy on all data is 0.00631509\n",
      "After 3627 training step(s),cross entropy on all data is 0.0063133\n",
      "After 3628 training step(s),cross entropy on all data is 0.00631169\n",
      "After 3629 training step(s),cross entropy on all data is 0.00631024\n",
      "After 3630 training step(s),cross entropy on all data is 0.00630894\n",
      "After 3631 training step(s),cross entropy on all data is 0.00630776\n",
      "After 3632 training step(s),cross entropy on all data is 0.00630671\n",
      "After 3633 training step(s),cross entropy on all data is 0.00630575\n",
      "After 3634 training step(s),cross entropy on all data is 0.00630489\n",
      "After 3635 training step(s),cross entropy on all data is 0.00630412\n",
      "After 3636 training step(s),cross entropy on all data is 0.00630343\n",
      "After 3637 training step(s),cross entropy on all data is 0.0063028\n",
      "After 3638 training step(s),cross entropy on all data is 0.00630224\n",
      "After 3639 training step(s),cross entropy on all data is 0.00629951\n",
      "After 3640 training step(s),cross entropy on all data is 0.00629706\n",
      "After 3641 training step(s),cross entropy on all data is 0.00629485\n",
      "After 3642 training step(s),cross entropy on all data is 0.00629286\n",
      "After 3643 training step(s),cross entropy on all data is 0.00629107\n",
      "After 3644 training step(s),cross entropy on all data is 0.00628945\n",
      "After 3645 training step(s),cross entropy on all data is 0.006288\n",
      "After 3646 training step(s),cross entropy on all data is 0.00628669\n",
      "After 3647 training step(s),cross entropy on all data is 0.00628552\n",
      "After 3648 training step(s),cross entropy on all data is 0.00628446\n",
      "After 3649 training step(s),cross entropy on all data is 0.0062835\n",
      "After 3650 training step(s),cross entropy on all data is 0.00628264\n",
      "After 3651 training step(s),cross entropy on all data is 0.00628187\n",
      "After 3652 training step(s),cross entropy on all data is 0.00628117\n",
      "After 3653 training step(s),cross entropy on all data is 0.00628054\n",
      "After 3654 training step(s),cross entropy on all data is 0.00627998\n",
      "After 3655 training step(s),cross entropy on all data is 0.00627725\n",
      "After 3656 training step(s),cross entropy on all data is 0.00627479\n",
      "After 3657 training step(s),cross entropy on all data is 0.00627257\n",
      "After 3658 training step(s),cross entropy on all data is 0.00627058\n",
      "After 3659 training step(s),cross entropy on all data is 0.00626879\n",
      "After 3660 training step(s),cross entropy on all data is 0.00626717\n",
      "After 3661 training step(s),cross entropy on all data is 0.00626571\n",
      "After 3662 training step(s),cross entropy on all data is 0.0062644\n",
      "After 3663 training step(s),cross entropy on all data is 0.00626322\n",
      "After 3664 training step(s),cross entropy on all data is 0.00626216\n",
      "After 3665 training step(s),cross entropy on all data is 0.00626121\n",
      "After 3666 training step(s),cross entropy on all data is 0.00626034\n",
      "After 3667 training step(s),cross entropy on all data is 0.00625957\n",
      "After 3668 training step(s),cross entropy on all data is 0.00625887\n",
      "After 3669 training step(s),cross entropy on all data is 0.00625824\n",
      "After 3670 training step(s),cross entropy on all data is 0.00625768\n",
      "After 3671 training step(s),cross entropy on all data is 0.00625494\n",
      "After 3672 training step(s),cross entropy on all data is 0.00625248\n",
      "After 3673 training step(s),cross entropy on all data is 0.00625026\n",
      "After 3674 training step(s),cross entropy on all data is 0.00624826\n",
      "After 3675 training step(s),cross entropy on all data is 0.00624646\n",
      "After 3676 training step(s),cross entropy on all data is 0.00624484\n",
      "After 3677 training step(s),cross entropy on all data is 0.00624338\n",
      "After 3678 training step(s),cross entropy on all data is 0.00624207\n",
      "After 3679 training step(s),cross entropy on all data is 0.00624089\n",
      "After 3680 training step(s),cross entropy on all data is 0.00623982\n",
      "After 3681 training step(s),cross entropy on all data is 0.00623887\n",
      "After 3682 training step(s),cross entropy on all data is 0.006238\n",
      "After 3683 training step(s),cross entropy on all data is 0.00623723\n",
      "After 3684 training step(s),cross entropy on all data is 0.00623653\n",
      "After 3685 training step(s),cross entropy on all data is 0.0062359\n",
      "After 3686 training step(s),cross entropy on all data is 0.00623533\n",
      "After 3687 training step(s),cross entropy on all data is 0.00623259\n",
      "After 3688 training step(s),cross entropy on all data is 0.00623012\n",
      "After 3689 training step(s),cross entropy on all data is 0.0062279\n",
      "After 3690 training step(s),cross entropy on all data is 0.00622589\n",
      "After 3691 training step(s),cross entropy on all data is 0.00622409\n",
      "After 3692 training step(s),cross entropy on all data is 0.00622247\n",
      "After 3693 training step(s),cross entropy on all data is 0.00622101\n",
      "After 3694 training step(s),cross entropy on all data is 0.00621969\n",
      "After 3695 training step(s),cross entropy on all data is 0.00621851\n",
      "After 3696 training step(s),cross entropy on all data is 0.00621744\n",
      "After 3697 training step(s),cross entropy on all data is 0.00621648\n",
      "After 3698 training step(s),cross entropy on all data is 0.00621562\n",
      "After 3699 training step(s),cross entropy on all data is 0.00621484\n",
      "After 3700 training step(s),cross entropy on all data is 0.00621414\n",
      "After 3701 training step(s),cross entropy on all data is 0.00621351\n",
      "After 3702 training step(s),cross entropy on all data is 0.00621294\n",
      "After 3703 training step(s),cross entropy on all data is 0.00621019\n",
      "After 3704 training step(s),cross entropy on all data is 0.00620772\n",
      "After 3705 training step(s),cross entropy on all data is 0.00620549\n",
      "After 3706 training step(s),cross entropy on all data is 0.00620348\n",
      "After 3707 training step(s),cross entropy on all data is 0.00620168\n",
      "After 3708 training step(s),cross entropy on all data is 0.00620005\n",
      "After 3709 training step(s),cross entropy on all data is 0.00619859\n",
      "After 3710 training step(s),cross entropy on all data is 0.00619727\n",
      "After 3711 training step(s),cross entropy on all data is 0.00619608\n",
      "After 3712 training step(s),cross entropy on all data is 0.00619502\n",
      "After 3713 training step(s),cross entropy on all data is 0.00619406\n",
      "After 3714 training step(s),cross entropy on all data is 0.00619319\n",
      "After 3715 training step(s),cross entropy on all data is 0.00619241\n",
      "After 3716 training step(s),cross entropy on all data is 0.00619171\n",
      "After 3717 training step(s),cross entropy on all data is 0.00619107\n",
      "After 3718 training step(s),cross entropy on all data is 0.0061905\n",
      "After 3719 training step(s),cross entropy on all data is 0.00618775\n",
      "After 3720 training step(s),cross entropy on all data is 0.00618527\n",
      "After 3721 training step(s),cross entropy on all data is 0.00618304\n",
      "After 3722 training step(s),cross entropy on all data is 0.00618103\n",
      "After 3723 training step(s),cross entropy on all data is 0.00617922\n",
      "After 3724 training step(s),cross entropy on all data is 0.00617759\n",
      "After 3725 training step(s),cross entropy on all data is 0.00617613\n",
      "After 3726 training step(s),cross entropy on all data is 0.00617481\n",
      "After 3727 training step(s),cross entropy on all data is 0.00617362\n",
      "After 3728 training step(s),cross entropy on all data is 0.00617255\n",
      "After 3729 training step(s),cross entropy on all data is 0.00617159\n",
      "After 3730 training step(s),cross entropy on all data is 0.00617072\n",
      "After 3731 training step(s),cross entropy on all data is 0.00616994\n",
      "After 3732 training step(s),cross entropy on all data is 0.00616923\n",
      "After 3733 training step(s),cross entropy on all data is 0.0061686\n",
      "After 3734 training step(s),cross entropy on all data is 0.00616803\n",
      "After 3735 training step(s),cross entropy on all data is 0.00616527\n",
      "After 3736 training step(s),cross entropy on all data is 0.00616279\n",
      "After 3737 training step(s),cross entropy on all data is 0.00616055\n",
      "After 3738 training step(s),cross entropy on all data is 0.00615854\n",
      "After 3739 training step(s),cross entropy on all data is 0.00615673\n",
      "After 3740 training step(s),cross entropy on all data is 0.0061551\n",
      "After 3741 training step(s),cross entropy on all data is 0.00615363\n",
      "After 3742 training step(s),cross entropy on all data is 0.0061523\n",
      "After 3743 training step(s),cross entropy on all data is 0.00615111\n",
      "After 3744 training step(s),cross entropy on all data is 0.00615004\n",
      "After 3745 training step(s),cross entropy on all data is 0.00614908\n",
      "After 3746 training step(s),cross entropy on all data is 0.00614821\n",
      "After 3747 training step(s),cross entropy on all data is 0.00614742\n",
      "After 3748 training step(s),cross entropy on all data is 0.00614672\n",
      "After 3749 training step(s),cross entropy on all data is 0.00614608\n",
      "After 3750 training step(s),cross entropy on all data is 0.00614551\n",
      "After 3751 training step(s),cross entropy on all data is 0.00614275\n",
      "After 3752 training step(s),cross entropy on all data is 0.00614026\n",
      "After 3753 training step(s),cross entropy on all data is 0.00613802\n",
      "After 3754 training step(s),cross entropy on all data is 0.00613601\n",
      "After 3755 training step(s),cross entropy on all data is 0.00613419\n",
      "After 3756 training step(s),cross entropy on all data is 0.00613256\n",
      "After 3757 training step(s),cross entropy on all data is 0.00613108\n",
      "After 3758 training step(s),cross entropy on all data is 0.00612976\n",
      "After 3759 training step(s),cross entropy on all data is 0.00612856\n",
      "After 3760 training step(s),cross entropy on all data is 0.00612749\n",
      "After 3761 training step(s),cross entropy on all data is 0.00612652\n",
      "After 3762 training step(s),cross entropy on all data is 0.00612565\n",
      "After 3763 training step(s),cross entropy on all data is 0.00612487\n",
      "After 3764 training step(s),cross entropy on all data is 0.00612416\n",
      "After 3765 training step(s),cross entropy on all data is 0.00612353\n",
      "After 3766 training step(s),cross entropy on all data is 0.00612295\n",
      "After 3767 training step(s),cross entropy on all data is 0.00612018\n",
      "After 3768 training step(s),cross entropy on all data is 0.00611769\n",
      "After 3769 training step(s),cross entropy on all data is 0.00611545\n",
      "After 3770 training step(s),cross entropy on all data is 0.00611343\n",
      "After 3771 training step(s),cross entropy on all data is 0.00611161\n",
      "After 3772 training step(s),cross entropy on all data is 0.00610997\n",
      "After 3773 training step(s),cross entropy on all data is 0.0061085\n",
      "After 3774 training step(s),cross entropy on all data is 0.00610717\n",
      "After 3775 training step(s),cross entropy on all data is 0.00610598\n",
      "After 3776 training step(s),cross entropy on all data is 0.0061049\n",
      "After 3777 training step(s),cross entropy on all data is 0.00610393\n",
      "After 3778 training step(s),cross entropy on all data is 0.00610306\n",
      "After 3779 training step(s),cross entropy on all data is 0.00610227\n",
      "After 3780 training step(s),cross entropy on all data is 0.00610156\n",
      "After 3781 training step(s),cross entropy on all data is 0.00610093\n",
      "After 3782 training step(s),cross entropy on all data is 0.00610035\n",
      "After 3783 training step(s),cross entropy on all data is 0.00609758\n",
      "After 3784 training step(s),cross entropy on all data is 0.00609508\n",
      "After 3785 training step(s),cross entropy on all data is 0.00609284\n",
      "After 3786 training step(s),cross entropy on all data is 0.00609081\n",
      "After 3787 training step(s),cross entropy on all data is 0.00608899\n",
      "After 3788 training step(s),cross entropy on all data is 0.00608735\n",
      "After 3789 training step(s),cross entropy on all data is 0.00608587\n",
      "After 3790 training step(s),cross entropy on all data is 0.00608454\n",
      "After 3791 training step(s),cross entropy on all data is 0.00608335\n",
      "After 3792 training step(s),cross entropy on all data is 0.00608227\n",
      "After 3793 training step(s),cross entropy on all data is 0.0060813\n",
      "After 3794 training step(s),cross entropy on all data is 0.00608042\n",
      "After 3795 training step(s),cross entropy on all data is 0.00607964\n",
      "After 3796 training step(s),cross entropy on all data is 0.00607893\n",
      "After 3797 training step(s),cross entropy on all data is 0.00607829\n",
      "After 3798 training step(s),cross entropy on all data is 0.00607772\n",
      "After 3799 training step(s),cross entropy on all data is 0.00607494\n",
      "After 3800 training step(s),cross entropy on all data is 0.00607244\n",
      "After 3801 training step(s),cross entropy on all data is 0.00607019\n",
      "After 3802 training step(s),cross entropy on all data is 0.00606816\n",
      "After 3803 training step(s),cross entropy on all data is 0.00606633\n",
      "After 3804 training step(s),cross entropy on all data is 0.00606469\n",
      "After 3805 training step(s),cross entropy on all data is 0.00606321\n",
      "After 3806 training step(s),cross entropy on all data is 0.00606188\n",
      "After 3807 training step(s),cross entropy on all data is 0.00606068\n",
      "After 3808 training step(s),cross entropy on all data is 0.0060596\n",
      "After 3809 training step(s),cross entropy on all data is 0.00605863\n",
      "After 3810 training step(s),cross entropy on all data is 0.00605775\n",
      "After 3811 training step(s),cross entropy on all data is 0.00605696\n",
      "After 3812 training step(s),cross entropy on all data is 0.00605625\n",
      "After 3813 training step(s),cross entropy on all data is 0.00605561\n",
      "After 3814 training step(s),cross entropy on all data is 0.00605504\n",
      "After 3815 training step(s),cross entropy on all data is 0.00605225\n",
      "After 3816 training step(s),cross entropy on all data is 0.00604975\n",
      "After 3817 training step(s),cross entropy on all data is 0.0060475\n",
      "After 3818 training step(s),cross entropy on all data is 0.00604546\n",
      "After 3819 training step(s),cross entropy on all data is 0.00604364\n",
      "After 3820 training step(s),cross entropy on all data is 0.00604199\n",
      "After 3821 training step(s),cross entropy on all data is 0.00604051\n",
      "After 3822 training step(s),cross entropy on all data is 0.00603917\n",
      "After 3823 training step(s),cross entropy on all data is 0.00603797\n",
      "After 3824 training step(s),cross entropy on all data is 0.00603689\n",
      "After 3825 training step(s),cross entropy on all data is 0.00603592\n",
      "After 3826 training step(s),cross entropy on all data is 0.00603504\n",
      "After 3827 training step(s),cross entropy on all data is 0.00603425\n",
      "After 3828 training step(s),cross entropy on all data is 0.00603354\n",
      "After 3829 training step(s),cross entropy on all data is 0.0060329\n",
      "After 3830 training step(s),cross entropy on all data is 0.00603232\n",
      "After 3831 training step(s),cross entropy on all data is 0.00602953\n",
      "After 3832 training step(s),cross entropy on all data is 0.00602703\n",
      "After 3833 training step(s),cross entropy on all data is 0.00602477\n",
      "After 3834 training step(s),cross entropy on all data is 0.00602273\n",
      "After 3835 training step(s),cross entropy on all data is 0.0060209\n",
      "After 3836 training step(s),cross entropy on all data is 0.00601925\n",
      "After 3837 training step(s),cross entropy on all data is 0.00601777\n",
      "After 3838 training step(s),cross entropy on all data is 0.00601643\n",
      "After 3839 training step(s),cross entropy on all data is 0.00601523\n",
      "After 3840 training step(s),cross entropy on all data is 0.00601414\n",
      "After 3841 training step(s),cross entropy on all data is 0.00601317\n",
      "After 3842 training step(s),cross entropy on all data is 0.00601229\n",
      "After 3843 training step(s),cross entropy on all data is 0.0060115\n",
      "After 3844 training step(s),cross entropy on all data is 0.00601079\n",
      "After 3845 training step(s),cross entropy on all data is 0.00601014\n",
      "After 3846 training step(s),cross entropy on all data is 0.00600957\n",
      "After 3847 training step(s),cross entropy on all data is 0.00600677\n",
      "After 3848 training step(s),cross entropy on all data is 0.00600426\n",
      "After 3849 training step(s),cross entropy on all data is 0.006002\n",
      "After 3850 training step(s),cross entropy on all data is 0.00599996\n",
      "After 3851 training step(s),cross entropy on all data is 0.00599813\n",
      "After 3852 training step(s),cross entropy on all data is 0.00599647\n",
      "After 3853 training step(s),cross entropy on all data is 0.00599499\n",
      "After 3854 training step(s),cross entropy on all data is 0.00599365\n",
      "After 3855 training step(s),cross entropy on all data is 0.00599244\n",
      "After 3856 training step(s),cross entropy on all data is 0.00599136\n",
      "After 3857 training step(s),cross entropy on all data is 0.00599038\n",
      "After 3858 training step(s),cross entropy on all data is 0.0059895\n",
      "After 3859 training step(s),cross entropy on all data is 0.00598871\n",
      "After 3860 training step(s),cross entropy on all data is 0.005988\n",
      "After 3861 training step(s),cross entropy on all data is 0.00598735\n",
      "After 3862 training step(s),cross entropy on all data is 0.00598678\n",
      "After 3863 training step(s),cross entropy on all data is 0.00598398\n",
      "After 3864 training step(s),cross entropy on all data is 0.00598146\n",
      "After 3865 training step(s),cross entropy on all data is 0.00597919\n",
      "After 3866 training step(s),cross entropy on all data is 0.00597715\n",
      "After 3867 training step(s),cross entropy on all data is 0.00597532\n",
      "After 3868 training step(s),cross entropy on all data is 0.00597366\n",
      "After 3869 training step(s),cross entropy on all data is 0.00597217\n",
      "After 3870 training step(s),cross entropy on all data is 0.00597083\n",
      "After 3871 training step(s),cross entropy on all data is 0.00596962\n",
      "After 3872 training step(s),cross entropy on all data is 0.00596854\n",
      "After 3873 training step(s),cross entropy on all data is 0.00596756\n",
      "After 3874 training step(s),cross entropy on all data is 0.00596668\n",
      "After 3875 training step(s),cross entropy on all data is 0.00596588\n",
      "After 3876 training step(s),cross entropy on all data is 0.00596517\n",
      "After 3877 training step(s),cross entropy on all data is 0.00596453\n",
      "After 3878 training step(s),cross entropy on all data is 0.00596395\n",
      "After 3879 training step(s),cross entropy on all data is 0.00596115\n",
      "After 3880 training step(s),cross entropy on all data is 0.00595862\n",
      "After 3881 training step(s),cross entropy on all data is 0.00595635\n",
      "After 3882 training step(s),cross entropy on all data is 0.00595431\n",
      "After 3883 training step(s),cross entropy on all data is 0.00595247\n",
      "After 3884 training step(s),cross entropy on all data is 0.00595081\n",
      "After 3885 training step(s),cross entropy on all data is 0.00594932\n",
      "After 3886 training step(s),cross entropy on all data is 0.00594798\n",
      "After 3887 training step(s),cross entropy on all data is 0.00594677\n",
      "After 3888 training step(s),cross entropy on all data is 0.00594568\n",
      "After 3889 training step(s),cross entropy on all data is 0.0059447\n",
      "After 3890 training step(s),cross entropy on all data is 0.00594382\n",
      "After 3891 training step(s),cross entropy on all data is 0.00594302\n",
      "After 3892 training step(s),cross entropy on all data is 0.00594231\n",
      "After 3893 training step(s),cross entropy on all data is 0.00594166\n",
      "After 3894 training step(s),cross entropy on all data is 0.00594108\n",
      "After 3895 training step(s),cross entropy on all data is 0.00593828\n",
      "After 3896 training step(s),cross entropy on all data is 0.00593575\n",
      "After 3897 training step(s),cross entropy on all data is 0.00593348\n",
      "After 3898 training step(s),cross entropy on all data is 0.00593143\n",
      "After 3899 training step(s),cross entropy on all data is 0.00592959\n",
      "After 3900 training step(s),cross entropy on all data is 0.00592793\n",
      "After 3901 training step(s),cross entropy on all data is 0.00592643\n",
      "After 3902 training step(s),cross entropy on all data is 0.00592509\n",
      "After 3903 training step(s),cross entropy on all data is 0.00592388\n",
      "After 3904 training step(s),cross entropy on all data is 0.00592279\n",
      "After 3905 training step(s),cross entropy on all data is 0.0059218\n",
      "After 3906 training step(s),cross entropy on all data is 0.00592092\n",
      "After 3907 training step(s),cross entropy on all data is 0.00592012\n",
      "After 3908 training step(s),cross entropy on all data is 0.00591941\n",
      "After 3909 training step(s),cross entropy on all data is 0.00591876\n",
      "After 3910 training step(s),cross entropy on all data is 0.00591818\n",
      "After 3911 training step(s),cross entropy on all data is 0.00591537\n",
      "After 3912 training step(s),cross entropy on all data is 0.00591284\n",
      "After 3913 training step(s),cross entropy on all data is 0.00591056\n",
      "After 3914 training step(s),cross entropy on all data is 0.00590851\n",
      "After 3915 training step(s),cross entropy on all data is 0.00590667\n",
      "After 3916 training step(s),cross entropy on all data is 0.00590501\n",
      "After 3917 training step(s),cross entropy on all data is 0.00590351\n",
      "After 3918 training step(s),cross entropy on all data is 0.00590216\n",
      "After 3919 training step(s),cross entropy on all data is 0.00590095\n",
      "After 3920 training step(s),cross entropy on all data is 0.00589986\n",
      "After 3921 training step(s),cross entropy on all data is 0.00589887\n",
      "After 3922 training step(s),cross entropy on all data is 0.00589799\n",
      "After 3923 training step(s),cross entropy on all data is 0.00589719\n",
      "After 3924 training step(s),cross entropy on all data is 0.00589647\n",
      "After 3925 training step(s),cross entropy on all data is 0.00589583\n",
      "After 3926 training step(s),cross entropy on all data is 0.00589524\n",
      "After 3927 training step(s),cross entropy on all data is 0.00589243\n",
      "After 3928 training step(s),cross entropy on all data is 0.0058899\n",
      "After 3929 training step(s),cross entropy on all data is 0.00588762\n",
      "After 3930 training step(s),cross entropy on all data is 0.00588556\n",
      "After 3931 training step(s),cross entropy on all data is 0.00588371\n",
      "After 3932 training step(s),cross entropy on all data is 0.00588205\n",
      "After 3933 training step(s),cross entropy on all data is 0.00588055\n",
      "After 3934 training step(s),cross entropy on all data is 0.0058792\n",
      "After 3935 training step(s),cross entropy on all data is 0.00587799\n",
      "After 3936 training step(s),cross entropy on all data is 0.00587689\n",
      "After 3937 training step(s),cross entropy on all data is 0.00587591\n",
      "After 3938 training step(s),cross entropy on all data is 0.00587502\n",
      "After 3939 training step(s),cross entropy on all data is 0.00587422\n",
      "After 3940 training step(s),cross entropy on all data is 0.0058735\n",
      "After 3941 training step(s),cross entropy on all data is 0.00587286\n",
      "After 3942 training step(s),cross entropy on all data is 0.00587227\n",
      "After 3943 training step(s),cross entropy on all data is 0.00586946\n",
      "After 3944 training step(s),cross entropy on all data is 0.00586692\n",
      "After 3945 training step(s),cross entropy on all data is 0.00586463\n",
      "After 3946 training step(s),cross entropy on all data is 0.00586258\n",
      "After 3947 training step(s),cross entropy on all data is 0.00586073\n",
      "After 3948 training step(s),cross entropy on all data is 0.00585906\n",
      "After 3949 training step(s),cross entropy on all data is 0.00585756\n",
      "After 3950 training step(s),cross entropy on all data is 0.00585621\n",
      "After 3951 training step(s),cross entropy on all data is 0.00585499\n",
      "After 3952 training step(s),cross entropy on all data is 0.0058539\n",
      "After 3953 training step(s),cross entropy on all data is 0.00585291\n",
      "After 3954 training step(s),cross entropy on all data is 0.00585202\n",
      "After 3955 training step(s),cross entropy on all data is 0.00585122\n",
      "After 3956 training step(s),cross entropy on all data is 0.0058505\n",
      "After 3957 training step(s),cross entropy on all data is 0.00584985\n",
      "After 3958 training step(s),cross entropy on all data is 0.00584927\n",
      "After 3959 training step(s),cross entropy on all data is 0.00584645\n",
      "After 3960 training step(s),cross entropy on all data is 0.00584391\n",
      "After 3961 training step(s),cross entropy on all data is 0.00584162\n",
      "After 3962 training step(s),cross entropy on all data is 0.00583956\n",
      "After 3963 training step(s),cross entropy on all data is 0.00583771\n",
      "After 3964 training step(s),cross entropy on all data is 0.00583604\n",
      "After 3965 training step(s),cross entropy on all data is 0.00583453\n",
      "After 3966 training step(s),cross entropy on all data is 0.00583318\n",
      "After 3967 training step(s),cross entropy on all data is 0.00583196\n",
      "After 3968 training step(s),cross entropy on all data is 0.00583087\n",
      "After 3969 training step(s),cross entropy on all data is 0.00582988\n",
      "After 3970 training step(s),cross entropy on all data is 0.00582899\n",
      "After 3971 training step(s),cross entropy on all data is 0.00582819\n",
      "After 3972 training step(s),cross entropy on all data is 0.00582747\n",
      "After 3973 training step(s),cross entropy on all data is 0.00582682\n",
      "After 3974 training step(s),cross entropy on all data is 0.00582623\n",
      "After 3975 training step(s),cross entropy on all data is 0.00582341\n",
      "After 3976 training step(s),cross entropy on all data is 0.00582086\n",
      "After 3977 training step(s),cross entropy on all data is 0.00581857\n",
      "After 3978 training step(s),cross entropy on all data is 0.00581651\n",
      "After 3979 training step(s),cross entropy on all data is 0.00581465\n",
      "After 3980 training step(s),cross entropy on all data is 0.00581298\n",
      "After 3981 training step(s),cross entropy on all data is 0.00581148\n",
      "After 3982 training step(s),cross entropy on all data is 0.00581012\n",
      "After 3983 training step(s),cross entropy on all data is 0.0058089\n",
      "After 3984 training step(s),cross entropy on all data is 0.0058078\n",
      "After 3985 training step(s),cross entropy on all data is 0.00580681\n",
      "After 3986 training step(s),cross entropy on all data is 0.00580592\n",
      "After 3987 training step(s),cross entropy on all data is 0.00580512\n",
      "After 3988 training step(s),cross entropy on all data is 0.0058044\n",
      "After 3989 training step(s),cross entropy on all data is 0.00580375\n",
      "After 3990 training step(s),cross entropy on all data is 0.00580316\n",
      "After 3991 training step(s),cross entropy on all data is 0.00580033\n",
      "After 3992 training step(s),cross entropy on all data is 0.00579779\n",
      "After 3993 training step(s),cross entropy on all data is 0.00579549\n",
      "After 3994 training step(s),cross entropy on all data is 0.00579343\n",
      "After 3995 training step(s),cross entropy on all data is 0.00579157\n",
      "After 3996 training step(s),cross entropy on all data is 0.00578989\n",
      "After 3997 training step(s),cross entropy on all data is 0.00578839\n",
      "After 3998 training step(s),cross entropy on all data is 0.00578703\n",
      "After 3999 training step(s),cross entropy on all data is 0.00578581\n",
      "After 4000 training step(s),cross entropy on all data is 0.00578471\n",
      "After 4001 training step(s),cross entropy on all data is 0.00578372\n",
      "After 4002 training step(s),cross entropy on all data is 0.00578283\n",
      "After 4003 training step(s),cross entropy on all data is 0.00578202\n",
      "After 4004 training step(s),cross entropy on all data is 0.0057813\n",
      "After 4005 training step(s),cross entropy on all data is 0.00578065\n",
      "After 4006 training step(s),cross entropy on all data is 0.00578006\n",
      "After 4007 training step(s),cross entropy on all data is 0.00577723\n",
      "After 4008 training step(s),cross entropy on all data is 0.00577468\n",
      "After 4009 training step(s),cross entropy on all data is 0.00577238\n",
      "After 4010 training step(s),cross entropy on all data is 0.00577031\n",
      "After 4011 training step(s),cross entropy on all data is 0.00576845\n",
      "After 4012 training step(s),cross entropy on all data is 0.00576677\n",
      "After 4013 training step(s),cross entropy on all data is 0.00576526\n",
      "After 4014 training step(s),cross entropy on all data is 0.00576391\n",
      "After 4015 training step(s),cross entropy on all data is 0.00576268\n",
      "After 4016 training step(s),cross entropy on all data is 0.00576158\n",
      "After 4017 training step(s),cross entropy on all data is 0.00576059\n",
      "After 4018 training step(s),cross entropy on all data is 0.0057597\n",
      "After 4019 training step(s),cross entropy on all data is 0.00575889\n",
      "After 4020 training step(s),cross entropy on all data is 0.00575817\n",
      "After 4021 training step(s),cross entropy on all data is 0.00575752\n",
      "After 4022 training step(s),cross entropy on all data is 0.00575693\n",
      "After 4023 training step(s),cross entropy on all data is 0.00575409\n",
      "After 4024 training step(s),cross entropy on all data is 0.00575154\n",
      "After 4025 training step(s),cross entropy on all data is 0.00574924\n",
      "After 4026 training step(s),cross entropy on all data is 0.00574717\n",
      "After 4027 training step(s),cross entropy on all data is 0.0057453\n",
      "After 4028 training step(s),cross entropy on all data is 0.00574362\n",
      "After 4029 training step(s),cross entropy on all data is 0.00574211\n",
      "After 4030 training step(s),cross entropy on all data is 0.00574075\n",
      "After 4031 training step(s),cross entropy on all data is 0.00573953\n",
      "After 4032 training step(s),cross entropy on all data is 0.00573842\n",
      "After 4033 training step(s),cross entropy on all data is 0.00573743\n",
      "After 4034 training step(s),cross entropy on all data is 0.00573654\n",
      "After 4035 training step(s),cross entropy on all data is 0.00573573\n",
      "After 4036 training step(s),cross entropy on all data is 0.00573501\n",
      "After 4037 training step(s),cross entropy on all data is 0.00573435\n",
      "After 4038 training step(s),cross entropy on all data is 0.00573377\n",
      "After 4039 training step(s),cross entropy on all data is 0.00573093\n",
      "After 4040 training step(s),cross entropy on all data is 0.00572837\n",
      "After 4041 training step(s),cross entropy on all data is 0.00572606\n",
      "After 4042 training step(s),cross entropy on all data is 0.00572399\n",
      "After 4043 training step(s),cross entropy on all data is 0.00572212\n",
      "After 4044 training step(s),cross entropy on all data is 0.00572044\n",
      "After 4045 training step(s),cross entropy on all data is 0.00571893\n",
      "After 4046 training step(s),cross entropy on all data is 0.00571757\n",
      "After 4047 training step(s),cross entropy on all data is 0.00571634\n",
      "After 4048 training step(s),cross entropy on all data is 0.00571524\n",
      "After 4049 training step(s),cross entropy on all data is 0.00571424\n",
      "After 4050 training step(s),cross entropy on all data is 0.00571335\n",
      "After 4051 training step(s),cross entropy on all data is 0.00571254\n",
      "After 4052 training step(s),cross entropy on all data is 0.00571181\n",
      "After 4053 training step(s),cross entropy on all data is 0.00571116\n",
      "After 4054 training step(s),cross entropy on all data is 0.00571057\n",
      "After 4055 training step(s),cross entropy on all data is 0.00570773\n",
      "After 4056 training step(s),cross entropy on all data is 0.00570516\n",
      "After 4057 training step(s),cross entropy on all data is 0.00570286\n",
      "After 4058 training step(s),cross entropy on all data is 0.00570078\n",
      "After 4059 training step(s),cross entropy on all data is 0.00569891\n",
      "After 4060 training step(s),cross entropy on all data is 0.00569723\n",
      "After 4061 training step(s),cross entropy on all data is 0.00569572\n",
      "After 4062 training step(s),cross entropy on all data is 0.00569435\n",
      "After 4063 training step(s),cross entropy on all data is 0.00569312\n",
      "After 4064 training step(s),cross entropy on all data is 0.00569202\n",
      "After 4065 training step(s),cross entropy on all data is 0.00569102\n",
      "After 4066 training step(s),cross entropy on all data is 0.00569012\n",
      "After 4067 training step(s),cross entropy on all data is 0.00568932\n",
      "After 4068 training step(s),cross entropy on all data is 0.00568859\n",
      "After 4069 training step(s),cross entropy on all data is 0.00568794\n",
      "After 4070 training step(s),cross entropy on all data is 0.00568735\n",
      "After 4071 training step(s),cross entropy on all data is 0.0056845\n",
      "After 4072 training step(s),cross entropy on all data is 0.00568193\n",
      "After 4073 training step(s),cross entropy on all data is 0.00567963\n",
      "After 4074 training step(s),cross entropy on all data is 0.00567755\n",
      "After 4075 training step(s),cross entropy on all data is 0.00567567\n",
      "After 4076 training step(s),cross entropy on all data is 0.00567399\n",
      "After 4077 training step(s),cross entropy on all data is 0.00567247\n",
      "After 4078 training step(s),cross entropy on all data is 0.00567111\n",
      "After 4079 training step(s),cross entropy on all data is 0.00566988\n",
      "After 4080 training step(s),cross entropy on all data is 0.00566877\n",
      "After 4081 training step(s),cross entropy on all data is 0.00566777\n",
      "After 4082 training step(s),cross entropy on all data is 0.00566687\n",
      "After 4083 training step(s),cross entropy on all data is 0.00566607\n",
      "After 4084 training step(s),cross entropy on all data is 0.00566534\n",
      "After 4085 training step(s),cross entropy on all data is 0.00566468\n",
      "After 4086 training step(s),cross entropy on all data is 0.00566409\n",
      "After 4087 training step(s),cross entropy on all data is 0.00566124\n",
      "After 4088 training step(s),cross entropy on all data is 0.00565867\n",
      "After 4089 training step(s),cross entropy on all data is 0.00565636\n",
      "After 4090 training step(s),cross entropy on all data is 0.00565428\n",
      "After 4091 training step(s),cross entropy on all data is 0.00565241\n",
      "After 4092 training step(s),cross entropy on all data is 0.00565072\n",
      "After 4093 training step(s),cross entropy on all data is 0.0056492\n",
      "After 4094 training step(s),cross entropy on all data is 0.00564783\n",
      "After 4095 training step(s),cross entropy on all data is 0.0056466\n",
      "After 4096 training step(s),cross entropy on all data is 0.00564549\n",
      "After 4097 training step(s),cross entropy on all data is 0.0056445\n",
      "After 4098 training step(s),cross entropy on all data is 0.0056436\n",
      "After 4099 training step(s),cross entropy on all data is 0.00564279\n",
      "After 4100 training step(s),cross entropy on all data is 0.00564206\n",
      "After 4101 training step(s),cross entropy on all data is 0.0056414\n",
      "After 4102 training step(s),cross entropy on all data is 0.00564081\n",
      "After 4103 training step(s),cross entropy on all data is 0.00563796\n",
      "After 4104 training step(s),cross entropy on all data is 0.00563539\n",
      "After 4105 training step(s),cross entropy on all data is 0.00563307\n",
      "After 4106 training step(s),cross entropy on all data is 0.00563099\n",
      "After 4107 training step(s),cross entropy on all data is 0.00562911\n",
      "After 4108 training step(s),cross entropy on all data is 0.00562742\n",
      "After 4109 training step(s),cross entropy on all data is 0.0056259\n",
      "After 4110 training step(s),cross entropy on all data is 0.00562453\n",
      "After 4111 training step(s),cross entropy on all data is 0.0056233\n",
      "After 4112 training step(s),cross entropy on all data is 0.00562219\n",
      "After 4113 training step(s),cross entropy on all data is 0.00562119\n",
      "After 4114 training step(s),cross entropy on all data is 0.00562029\n",
      "After 4115 training step(s),cross entropy on all data is 0.00561948\n",
      "After 4116 training step(s),cross entropy on all data is 0.00561875\n",
      "After 4117 training step(s),cross entropy on all data is 0.00561809\n",
      "After 4118 training step(s),cross entropy on all data is 0.0056175\n",
      "After 4119 training step(s),cross entropy on all data is 0.00561464\n",
      "After 4120 training step(s),cross entropy on all data is 0.00561207\n",
      "After 4121 training step(s),cross entropy on all data is 0.00560975\n",
      "After 4122 training step(s),cross entropy on all data is 0.00560767\n",
      "After 4123 training step(s),cross entropy on all data is 0.00560579\n",
      "After 4124 training step(s),cross entropy on all data is 0.0056041\n",
      "After 4125 training step(s),cross entropy on all data is 0.00560257\n",
      "After 4126 training step(s),cross entropy on all data is 0.0056012\n",
      "After 4127 training step(s),cross entropy on all data is 0.00559997\n",
      "After 4128 training step(s),cross entropy on all data is 0.00559886\n",
      "After 4129 training step(s),cross entropy on all data is 0.00559786\n",
      "After 4130 training step(s),cross entropy on all data is 0.00559696\n",
      "After 4131 training step(s),cross entropy on all data is 0.00559615\n",
      "After 4132 training step(s),cross entropy on all data is 0.00559541\n",
      "After 4133 training step(s),cross entropy on all data is 0.00559476\n",
      "After 4134 training step(s),cross entropy on all data is 0.00559416\n",
      "After 4135 training step(s),cross entropy on all data is 0.0055913\n",
      "After 4136 training step(s),cross entropy on all data is 0.00558873\n",
      "After 4137 training step(s),cross entropy on all data is 0.00558641\n",
      "After 4138 training step(s),cross entropy on all data is 0.00558432\n",
      "After 4139 training step(s),cross entropy on all data is 0.00558244\n",
      "After 4140 training step(s),cross entropy on all data is 0.00558074\n",
      "After 4141 training step(s),cross entropy on all data is 0.00557922\n",
      "After 4142 training step(s),cross entropy on all data is 0.00557785\n",
      "After 4143 training step(s),cross entropy on all data is 0.00557661\n",
      "After 4144 training step(s),cross entropy on all data is 0.0055755\n",
      "After 4145 training step(s),cross entropy on all data is 0.0055745\n",
      "After 4146 training step(s),cross entropy on all data is 0.00557359\n",
      "After 4147 training step(s),cross entropy on all data is 0.00557278\n",
      "After 4148 training step(s),cross entropy on all data is 0.00557205\n",
      "After 4149 training step(s),cross entropy on all data is 0.00557139\n",
      "After 4150 training step(s),cross entropy on all data is 0.0055708\n",
      "After 4151 training step(s),cross entropy on all data is 0.00556793\n",
      "After 4152 training step(s),cross entropy on all data is 0.00556535\n",
      "After 4153 training step(s),cross entropy on all data is 0.00556303\n",
      "After 4154 training step(s),cross entropy on all data is 0.00556094\n",
      "After 4155 training step(s),cross entropy on all data is 0.00555906\n",
      "After 4156 training step(s),cross entropy on all data is 0.00555736\n",
      "After 4157 training step(s),cross entropy on all data is 0.00555584\n",
      "After 4158 training step(s),cross entropy on all data is 0.00555446\n",
      "After 4159 training step(s),cross entropy on all data is 0.00555323\n",
      "After 4160 training step(s),cross entropy on all data is 0.00555211\n",
      "After 4161 training step(s),cross entropy on all data is 0.00555111\n",
      "After 4162 training step(s),cross entropy on all data is 0.0055502\n",
      "After 4163 training step(s),cross entropy on all data is 0.00554939\n",
      "After 4164 training step(s),cross entropy on all data is 0.00554866\n",
      "After 4165 training step(s),cross entropy on all data is 0.005548\n",
      "After 4166 training step(s),cross entropy on all data is 0.00554741\n",
      "After 4167 training step(s),cross entropy on all data is 0.00554454\n",
      "After 4168 training step(s),cross entropy on all data is 0.00554196\n",
      "After 4169 training step(s),cross entropy on all data is 0.00553963\n",
      "After 4170 training step(s),cross entropy on all data is 0.00553754\n",
      "After 4171 training step(s),cross entropy on all data is 0.00553565\n",
      "After 4172 training step(s),cross entropy on all data is 0.00553396\n",
      "After 4173 training step(s),cross entropy on all data is 0.00553243\n",
      "After 4174 training step(s),cross entropy on all data is 0.00553105\n",
      "After 4175 training step(s),cross entropy on all data is 0.00552981\n",
      "After 4176 training step(s),cross entropy on all data is 0.0055287\n",
      "After 4177 training step(s),cross entropy on all data is 0.0055277\n",
      "After 4178 training step(s),cross entropy on all data is 0.00552679\n",
      "After 4179 training step(s),cross entropy on all data is 0.00552598\n",
      "After 4180 training step(s),cross entropy on all data is 0.00552524\n",
      "After 4181 training step(s),cross entropy on all data is 0.00552458\n",
      "After 4182 training step(s),cross entropy on all data is 0.00552399\n",
      "After 4183 training step(s),cross entropy on all data is 0.00552112\n",
      "After 4184 training step(s),cross entropy on all data is 0.00551853\n",
      "After 4185 training step(s),cross entropy on all data is 0.00551621\n",
      "After 4186 training step(s),cross entropy on all data is 0.00551411\n",
      "After 4187 training step(s),cross entropy on all data is 0.00551222\n",
      "After 4188 training step(s),cross entropy on all data is 0.00551052\n",
      "After 4189 training step(s),cross entropy on all data is 0.005509\n",
      "After 4190 training step(s),cross entropy on all data is 0.00550762\n",
      "After 4191 training step(s),cross entropy on all data is 0.00550638\n",
      "After 4192 training step(s),cross entropy on all data is 0.00550526\n",
      "After 4193 training step(s),cross entropy on all data is 0.00550426\n",
      "After 4194 training step(s),cross entropy on all data is 0.00550335\n",
      "After 4195 training step(s),cross entropy on all data is 0.00550254\n",
      "After 4196 training step(s),cross entropy on all data is 0.0055018\n",
      "After 4197 training step(s),cross entropy on all data is 0.00550114\n",
      "After 4198 training step(s),cross entropy on all data is 0.00550055\n",
      "After 4199 training step(s),cross entropy on all data is 0.00549767\n",
      "After 4200 training step(s),cross entropy on all data is 0.00549509\n",
      "After 4201 training step(s),cross entropy on all data is 0.00549276\n",
      "After 4202 training step(s),cross entropy on all data is 0.00549066\n",
      "After 4203 training step(s),cross entropy on all data is 0.00548877\n",
      "After 4204 training step(s),cross entropy on all data is 0.00548707\n",
      "After 4205 training step(s),cross entropy on all data is 0.00548554\n",
      "After 4206 training step(s),cross entropy on all data is 0.00548416\n",
      "After 4207 training step(s),cross entropy on all data is 0.00548292\n",
      "After 4208 training step(s),cross entropy on all data is 0.0054818\n",
      "After 4209 training step(s),cross entropy on all data is 0.00548079\n",
      "After 4210 training step(s),cross entropy on all data is 0.00547989\n",
      "After 4211 training step(s),cross entropy on all data is 0.00547907\n",
      "After 4212 training step(s),cross entropy on all data is 0.00547834\n",
      "After 4213 training step(s),cross entropy on all data is 0.00547768\n",
      "After 4214 training step(s),cross entropy on all data is 0.00547708\n",
      "After 4215 training step(s),cross entropy on all data is 0.0054742\n",
      "After 4216 training step(s),cross entropy on all data is 0.00547161\n",
      "After 4217 training step(s),cross entropy on all data is 0.00546928\n",
      "After 4218 training step(s),cross entropy on all data is 0.00546718\n",
      "After 4219 training step(s),cross entropy on all data is 0.00546529\n",
      "After 4220 training step(s),cross entropy on all data is 0.00546359\n",
      "After 4221 training step(s),cross entropy on all data is 0.00546206\n",
      "After 4222 training step(s),cross entropy on all data is 0.00546068\n",
      "After 4223 training step(s),cross entropy on all data is 0.00545943\n",
      "After 4224 training step(s),cross entropy on all data is 0.00545831\n",
      "After 4225 training step(s),cross entropy on all data is 0.00545731\n",
      "After 4226 training step(s),cross entropy on all data is 0.0054564\n",
      "After 4227 training step(s),cross entropy on all data is 0.00545558\n",
      "After 4228 training step(s),cross entropy on all data is 0.00545485\n",
      "After 4229 training step(s),cross entropy on all data is 0.00545419\n",
      "After 4230 training step(s),cross entropy on all data is 0.00545359\n",
      "After 4231 training step(s),cross entropy on all data is 0.00545071\n",
      "After 4232 training step(s),cross entropy on all data is 0.00544812\n",
      "After 4233 training step(s),cross entropy on all data is 0.00544578\n",
      "After 4234 training step(s),cross entropy on all data is 0.00544368\n",
      "After 4235 training step(s),cross entropy on all data is 0.00544179\n",
      "After 4236 training step(s),cross entropy on all data is 0.00544008\n",
      "After 4237 training step(s),cross entropy on all data is 0.00543855\n",
      "After 4238 training step(s),cross entropy on all data is 0.00543717\n",
      "After 4239 training step(s),cross entropy on all data is 0.00543593\n",
      "After 4240 training step(s),cross entropy on all data is 0.00543481\n",
      "After 4241 training step(s),cross entropy on all data is 0.0054338\n",
      "After 4242 training step(s),cross entropy on all data is 0.00543289\n",
      "After 4243 training step(s),cross entropy on all data is 0.00543207\n",
      "After 4244 training step(s),cross entropy on all data is 0.00543134\n",
      "After 4245 training step(s),cross entropy on all data is 0.00543067\n",
      "After 4246 training step(s),cross entropy on all data is 0.00543008\n",
      "After 4247 training step(s),cross entropy on all data is 0.00542719\n",
      "After 4248 training step(s),cross entropy on all data is 0.0054246\n",
      "After 4249 training step(s),cross entropy on all data is 0.00542226\n",
      "After 4250 training step(s),cross entropy on all data is 0.00542016\n",
      "After 4251 training step(s),cross entropy on all data is 0.00541826\n",
      "After 4252 training step(s),cross entropy on all data is 0.00541656\n",
      "After 4253 training step(s),cross entropy on all data is 0.00541502\n",
      "After 4254 training step(s),cross entropy on all data is 0.00541364\n",
      "After 4255 training step(s),cross entropy on all data is 0.00541239\n",
      "After 4256 training step(s),cross entropy on all data is 0.00541127\n",
      "After 4257 training step(s),cross entropy on all data is 0.00541026\n",
      "After 4258 training step(s),cross entropy on all data is 0.00540936\n",
      "After 4259 training step(s),cross entropy on all data is 0.00540854\n",
      "After 4260 training step(s),cross entropy on all data is 0.0054078\n",
      "After 4261 training step(s),cross entropy on all data is 0.00540714\n",
      "After 4262 training step(s),cross entropy on all data is 0.00540654\n",
      "After 4263 training step(s),cross entropy on all data is 0.00540365\n",
      "After 4264 training step(s),cross entropy on all data is 0.00540106\n",
      "After 4265 training step(s),cross entropy on all data is 0.00539872\n",
      "After 4266 training step(s),cross entropy on all data is 0.00539661\n",
      "After 4267 training step(s),cross entropy on all data is 0.00539471\n",
      "After 4268 training step(s),cross entropy on all data is 0.00539301\n",
      "After 4269 training step(s),cross entropy on all data is 0.00539147\n",
      "After 4270 training step(s),cross entropy on all data is 0.00539009\n",
      "After 4271 training step(s),cross entropy on all data is 0.00538884\n",
      "After 4272 training step(s),cross entropy on all data is 0.00538772\n",
      "After 4273 training step(s),cross entropy on all data is 0.00538671\n",
      "After 4274 training step(s),cross entropy on all data is 0.0053858\n",
      "After 4275 training step(s),cross entropy on all data is 0.00538498\n",
      "After 4276 training step(s),cross entropy on all data is 0.00538424\n",
      "After 4277 training step(s),cross entropy on all data is 0.00538358\n",
      "After 4278 training step(s),cross entropy on all data is 0.00538298\n",
      "After 4279 training step(s),cross entropy on all data is 0.00538009\n",
      "After 4280 training step(s),cross entropy on all data is 0.00537749\n",
      "After 4281 training step(s),cross entropy on all data is 0.00537515\n",
      "After 4282 training step(s),cross entropy on all data is 0.00537304\n",
      "After 4283 training step(s),cross entropy on all data is 0.00537114\n",
      "After 4284 training step(s),cross entropy on all data is 0.00536944\n",
      "After 4285 training step(s),cross entropy on all data is 0.0053679\n",
      "After 4286 training step(s),cross entropy on all data is 0.00536651\n",
      "After 4287 training step(s),cross entropy on all data is 0.00536527\n",
      "After 4288 training step(s),cross entropy on all data is 0.00536414\n",
      "After 4289 training step(s),cross entropy on all data is 0.00536313\n",
      "After 4290 training step(s),cross entropy on all data is 0.00536222\n",
      "After 4291 training step(s),cross entropy on all data is 0.0053614\n",
      "After 4292 training step(s),cross entropy on all data is 0.00536066\n",
      "After 4293 training step(s),cross entropy on all data is 0.00536\n",
      "After 4294 training step(s),cross entropy on all data is 0.0053594\n",
      "After 4295 training step(s),cross entropy on all data is 0.00535651\n",
      "After 4296 training step(s),cross entropy on all data is 0.00535391\n",
      "After 4297 training step(s),cross entropy on all data is 0.00535156\n",
      "After 4298 training step(s),cross entropy on all data is 0.00534945\n",
      "After 4299 training step(s),cross entropy on all data is 0.00534755\n",
      "After 4300 training step(s),cross entropy on all data is 0.00534584\n",
      "After 4301 training step(s),cross entropy on all data is 0.0053443\n",
      "After 4302 training step(s),cross entropy on all data is 0.00534292\n",
      "After 4303 training step(s),cross entropy on all data is 0.00534167\n",
      "After 4304 training step(s),cross entropy on all data is 0.00534054\n",
      "After 4305 training step(s),cross entropy on all data is 0.00533953\n",
      "After 4306 training step(s),cross entropy on all data is 0.00533862\n",
      "After 4307 training step(s),cross entropy on all data is 0.0053378\n",
      "After 4308 training step(s),cross entropy on all data is 0.00533706\n",
      "After 4309 training step(s),cross entropy on all data is 0.0053364\n",
      "After 4310 training step(s),cross entropy on all data is 0.0053358\n",
      "After 4311 training step(s),cross entropy on all data is 0.0053329\n",
      "After 4312 training step(s),cross entropy on all data is 0.0053303\n",
      "After 4313 training step(s),cross entropy on all data is 0.00532795\n",
      "After 4314 training step(s),cross entropy on all data is 0.00532584\n",
      "After 4315 training step(s),cross entropy on all data is 0.00532394\n",
      "After 4316 training step(s),cross entropy on all data is 0.00532223\n",
      "After 4317 training step(s),cross entropy on all data is 0.00532069\n",
      "After 4318 training step(s),cross entropy on all data is 0.0053193\n",
      "After 4319 training step(s),cross entropy on all data is 0.00531805\n",
      "After 4320 training step(s),cross entropy on all data is 0.00531692\n",
      "After 4321 training step(s),cross entropy on all data is 0.00531591\n",
      "After 4322 training step(s),cross entropy on all data is 0.005315\n",
      "After 4323 training step(s),cross entropy on all data is 0.00531418\n",
      "After 4324 training step(s),cross entropy on all data is 0.00531344\n",
      "After 4325 training step(s),cross entropy on all data is 0.00531277\n",
      "After 4326 training step(s),cross entropy on all data is 0.00531217\n",
      "After 4327 training step(s),cross entropy on all data is 0.00530928\n",
      "After 4328 training step(s),cross entropy on all data is 0.00530667\n",
      "After 4329 training step(s),cross entropy on all data is 0.00530432\n",
      "After 4330 training step(s),cross entropy on all data is 0.00530221\n",
      "After 4331 training step(s),cross entropy on all data is 0.0053003\n",
      "After 4332 training step(s),cross entropy on all data is 0.00529859\n",
      "After 4333 training step(s),cross entropy on all data is 0.00529705\n",
      "After 4334 training step(s),cross entropy on all data is 0.00529566\n",
      "After 4335 training step(s),cross entropy on all data is 0.00529441\n",
      "After 4336 training step(s),cross entropy on all data is 0.00529328\n",
      "After 4337 training step(s),cross entropy on all data is 0.00529227\n",
      "After 4338 training step(s),cross entropy on all data is 0.00529136\n",
      "After 4339 training step(s),cross entropy on all data is 0.00529054\n",
      "After 4340 training step(s),cross entropy on all data is 0.00528979\n",
      "After 4341 training step(s),cross entropy on all data is 0.00528913\n",
      "After 4342 training step(s),cross entropy on all data is 0.00528853\n",
      "After 4343 training step(s),cross entropy on all data is 0.00528563\n",
      "After 4344 training step(s),cross entropy on all data is 0.00528302\n",
      "After 4345 training step(s),cross entropy on all data is 0.00528067\n",
      "After 4346 training step(s),cross entropy on all data is 0.00527856\n",
      "After 4347 training step(s),cross entropy on all data is 0.00527665\n",
      "After 4348 training step(s),cross entropy on all data is 0.00527494\n",
      "After 4349 training step(s),cross entropy on all data is 0.00527339\n",
      "After 4350 training step(s),cross entropy on all data is 0.005272\n",
      "After 4351 training step(s),cross entropy on all data is 0.00527075\n",
      "After 4352 training step(s),cross entropy on all data is 0.00526962\n",
      "After 4353 training step(s),cross entropy on all data is 0.00526861\n",
      "After 4354 training step(s),cross entropy on all data is 0.0052677\n",
      "After 4355 training step(s),cross entropy on all data is 0.00526687\n",
      "After 4356 training step(s),cross entropy on all data is 0.00526613\n",
      "After 4357 training step(s),cross entropy on all data is 0.00526547\n",
      "After 4358 training step(s),cross entropy on all data is 0.00526486\n",
      "After 4359 training step(s),cross entropy on all data is 0.00526196\n",
      "After 4360 training step(s),cross entropy on all data is 0.00525935\n",
      "After 4361 training step(s),cross entropy on all data is 0.005257\n",
      "After 4362 training step(s),cross entropy on all data is 0.00525488\n",
      "After 4363 training step(s),cross entropy on all data is 0.00525298\n",
      "After 4364 training step(s),cross entropy on all data is 0.00525126\n",
      "After 4365 training step(s),cross entropy on all data is 0.00524972\n",
      "After 4366 training step(s),cross entropy on all data is 0.00524833\n",
      "After 4367 training step(s),cross entropy on all data is 0.00524707\n",
      "After 4368 training step(s),cross entropy on all data is 0.00524595\n",
      "After 4369 training step(s),cross entropy on all data is 0.00524493\n",
      "After 4370 training step(s),cross entropy on all data is 0.00524402\n",
      "After 4371 training step(s),cross entropy on all data is 0.00524319\n",
      "After 4372 training step(s),cross entropy on all data is 0.00524245\n",
      "After 4373 training step(s),cross entropy on all data is 0.00524178\n",
      "After 4374 training step(s),cross entropy on all data is 0.00524118\n",
      "After 4375 training step(s),cross entropy on all data is 0.00523828\n",
      "After 4376 training step(s),cross entropy on all data is 0.00523567\n",
      "After 4377 training step(s),cross entropy on all data is 0.00523331\n",
      "After 4378 training step(s),cross entropy on all data is 0.00523119\n",
      "After 4379 training step(s),cross entropy on all data is 0.00522929\n",
      "After 4380 training step(s),cross entropy on all data is 0.00522757\n",
      "After 4381 training step(s),cross entropy on all data is 0.00522602\n",
      "After 4382 training step(s),cross entropy on all data is 0.00522463\n",
      "After 4383 training step(s),cross entropy on all data is 0.00522338\n",
      "After 4384 training step(s),cross entropy on all data is 0.00522225\n",
      "After 4385 training step(s),cross entropy on all data is 0.00522123\n",
      "After 4386 training step(s),cross entropy on all data is 0.00522032\n",
      "After 4387 training step(s),cross entropy on all data is 0.00521949\n",
      "After 4388 training step(s),cross entropy on all data is 0.00521875\n",
      "After 4389 training step(s),cross entropy on all data is 0.00521808\n",
      "After 4390 training step(s),cross entropy on all data is 0.00521748\n",
      "After 4391 training step(s),cross entropy on all data is 0.00521458\n",
      "After 4392 training step(s),cross entropy on all data is 0.00521196\n",
      "After 4393 training step(s),cross entropy on all data is 0.00520961\n",
      "After 4394 training step(s),cross entropy on all data is 0.00520749\n",
      "After 4395 training step(s),cross entropy on all data is 0.00520558\n",
      "After 4396 training step(s),cross entropy on all data is 0.00520386\n",
      "After 4397 training step(s),cross entropy on all data is 0.00520231\n",
      "After 4398 training step(s),cross entropy on all data is 0.00520092\n",
      "After 4399 training step(s),cross entropy on all data is 0.00519966\n",
      "After 4400 training step(s),cross entropy on all data is 0.00519853\n",
      "After 4401 training step(s),cross entropy on all data is 0.00519752\n",
      "After 4402 training step(s),cross entropy on all data is 0.0051966\n",
      "After 4403 training step(s),cross entropy on all data is 0.00519578\n",
      "After 4404 training step(s),cross entropy on all data is 0.00519503\n",
      "After 4405 training step(s),cross entropy on all data is 0.00519437\n",
      "After 4406 training step(s),cross entropy on all data is 0.00519376\n",
      "After 4407 training step(s),cross entropy on all data is 0.00519086\n",
      "After 4408 training step(s),cross entropy on all data is 0.00518824\n",
      "After 4409 training step(s),cross entropy on all data is 0.00518588\n",
      "After 4410 training step(s),cross entropy on all data is 0.00518376\n",
      "After 4411 training step(s),cross entropy on all data is 0.00518185\n",
      "After 4412 training step(s),cross entropy on all data is 0.00518013\n",
      "After 4413 training step(s),cross entropy on all data is 0.00517858\n",
      "After 4414 training step(s),cross entropy on all data is 0.00517719\n",
      "After 4415 training step(s),cross entropy on all data is 0.00517593\n",
      "After 4416 training step(s),cross entropy on all data is 0.0051748\n",
      "After 4417 training step(s),cross entropy on all data is 0.00517378\n",
      "After 4418 training step(s),cross entropy on all data is 0.00517287\n",
      "After 4419 training step(s),cross entropy on all data is 0.00517204\n",
      "After 4420 training step(s),cross entropy on all data is 0.0051713\n",
      "After 4421 training step(s),cross entropy on all data is 0.00517063\n",
      "After 4422 training step(s),cross entropy on all data is 0.00517002\n",
      "After 4423 training step(s),cross entropy on all data is 0.00516712\n",
      "After 4424 training step(s),cross entropy on all data is 0.0051645\n",
      "After 4425 training step(s),cross entropy on all data is 0.00516214\n",
      "After 4426 training step(s),cross entropy on all data is 0.00516001\n",
      "After 4427 training step(s),cross entropy on all data is 0.0051581\n",
      "After 4428 training step(s),cross entropy on all data is 0.00515638\n",
      "After 4429 training step(s),cross entropy on all data is 0.00515483\n",
      "After 4430 training step(s),cross entropy on all data is 0.00515344\n",
      "After 4431 training step(s),cross entropy on all data is 0.00515218\n",
      "After 4432 training step(s),cross entropy on all data is 0.00515105\n",
      "After 4433 training step(s),cross entropy on all data is 0.00515003\n",
      "After 4434 training step(s),cross entropy on all data is 0.00514911\n",
      "After 4435 training step(s),cross entropy on all data is 0.00514829\n",
      "After 4436 training step(s),cross entropy on all data is 0.00514754\n",
      "After 4437 training step(s),cross entropy on all data is 0.00514687\n",
      "After 4438 training step(s),cross entropy on all data is 0.00514627\n",
      "After 4439 training step(s),cross entropy on all data is 0.00514336\n",
      "After 4440 training step(s),cross entropy on all data is 0.00514074\n",
      "After 4441 training step(s),cross entropy on all data is 0.00513838\n",
      "After 4442 training step(s),cross entropy on all data is 0.00513625\n",
      "After 4443 training step(s),cross entropy on all data is 0.00513434\n",
      "After 4444 training step(s),cross entropy on all data is 0.00513262\n",
      "After 4445 training step(s),cross entropy on all data is 0.00513107\n",
      "After 4446 training step(s),cross entropy on all data is 0.00512967\n",
      "After 4447 training step(s),cross entropy on all data is 0.00512841\n",
      "After 4448 training step(s),cross entropy on all data is 0.00512728\n",
      "After 4449 training step(s),cross entropy on all data is 0.00512626\n",
      "After 4450 training step(s),cross entropy on all data is 0.00512534\n",
      "After 4451 training step(s),cross entropy on all data is 0.00512452\n",
      "After 4452 training step(s),cross entropy on all data is 0.00512377\n",
      "After 4453 training step(s),cross entropy on all data is 0.0051231\n",
      "After 4454 training step(s),cross entropy on all data is 0.0051225\n",
      "After 4455 training step(s),cross entropy on all data is 0.00511959\n",
      "After 4456 training step(s),cross entropy on all data is 0.00511696\n",
      "After 4457 training step(s),cross entropy on all data is 0.0051146\n",
      "After 4458 training step(s),cross entropy on all data is 0.00511248\n",
      "After 4459 training step(s),cross entropy on all data is 0.00511056\n",
      "After 4460 training step(s),cross entropy on all data is 0.00510884\n",
      "After 4461 training step(s),cross entropy on all data is 0.00510729\n",
      "After 4462 training step(s),cross entropy on all data is 0.00510589\n",
      "After 4463 training step(s),cross entropy on all data is 0.00510463\n",
      "After 4464 training step(s),cross entropy on all data is 0.0051035\n",
      "After 4465 training step(s),cross entropy on all data is 0.00510248\n",
      "After 4466 training step(s),cross entropy on all data is 0.00510156\n",
      "After 4467 training step(s),cross entropy on all data is 0.00510073\n",
      "After 4468 training step(s),cross entropy on all data is 0.00509999\n",
      "After 4469 training step(s),cross entropy on all data is 0.00509932\n",
      "After 4470 training step(s),cross entropy on all data is 0.00509871\n",
      "After 4471 training step(s),cross entropy on all data is 0.0050958\n",
      "After 4472 training step(s),cross entropy on all data is 0.00509317\n",
      "After 4473 training step(s),cross entropy on all data is 0.00509081\n",
      "After 4474 training step(s),cross entropy on all data is 0.00508868\n",
      "After 4475 training step(s),cross entropy on all data is 0.00508677\n",
      "After 4476 training step(s),cross entropy on all data is 0.00508504\n",
      "After 4477 training step(s),cross entropy on all data is 0.00508349\n",
      "After 4478 training step(s),cross entropy on all data is 0.00508209\n",
      "After 4479 training step(s),cross entropy on all data is 0.00508083\n",
      "After 4480 training step(s),cross entropy on all data is 0.0050797\n",
      "After 4481 training step(s),cross entropy on all data is 0.00507868\n",
      "After 4482 training step(s),cross entropy on all data is 0.00507776\n",
      "After 4483 training step(s),cross entropy on all data is 0.00507693\n",
      "After 4484 training step(s),cross entropy on all data is 0.00507619\n",
      "After 4485 training step(s),cross entropy on all data is 0.00507551\n",
      "After 4486 training step(s),cross entropy on all data is 0.00507491\n",
      "After 4487 training step(s),cross entropy on all data is 0.00507199\n",
      "After 4488 training step(s),cross entropy on all data is 0.00506937\n",
      "After 4489 training step(s),cross entropy on all data is 0.005067\n",
      "After 4490 training step(s),cross entropy on all data is 0.00506487\n",
      "After 4491 training step(s),cross entropy on all data is 0.00506295\n",
      "After 4492 training step(s),cross entropy on all data is 0.00506123\n",
      "After 4493 training step(s),cross entropy on all data is 0.00505968\n",
      "After 4494 training step(s),cross entropy on all data is 0.00505828\n",
      "After 4495 training step(s),cross entropy on all data is 0.00505702\n",
      "After 4496 training step(s),cross entropy on all data is 0.00505588\n",
      "After 4497 training step(s),cross entropy on all data is 0.00505486\n",
      "After 4498 training step(s),cross entropy on all data is 0.00505394\n",
      "After 4499 training step(s),cross entropy on all data is 0.00505311\n",
      "After 4500 training step(s),cross entropy on all data is 0.00505237\n",
      "After 4501 training step(s),cross entropy on all data is 0.0050517\n",
      "After 4502 training step(s),cross entropy on all data is 0.00505109\n",
      "After 4503 training step(s),cross entropy on all data is 0.00504817\n",
      "After 4504 training step(s),cross entropy on all data is 0.00504554\n",
      "After 4505 training step(s),cross entropy on all data is 0.00504318\n",
      "After 4506 training step(s),cross entropy on all data is 0.00504105\n",
      "After 4507 training step(s),cross entropy on all data is 0.00503913\n",
      "After 4508 training step(s),cross entropy on all data is 0.0050374\n",
      "After 4509 training step(s),cross entropy on all data is 0.00503585\n",
      "After 4510 training step(s),cross entropy on all data is 0.00503445\n",
      "After 4511 training step(s),cross entropy on all data is 0.00503319\n",
      "After 4512 training step(s),cross entropy on all data is 0.00503205\n",
      "After 4513 training step(s),cross entropy on all data is 0.00503103\n",
      "After 4514 training step(s),cross entropy on all data is 0.00503011\n",
      "After 4515 training step(s),cross entropy on all data is 0.00502928\n",
      "After 4516 training step(s),cross entropy on all data is 0.00502854\n",
      "After 4517 training step(s),cross entropy on all data is 0.00502787\n",
      "After 4518 training step(s),cross entropy on all data is 0.00502726\n",
      "After 4519 training step(s),cross entropy on all data is 0.00502434\n",
      "After 4520 training step(s),cross entropy on all data is 0.00502171\n",
      "After 4521 training step(s),cross entropy on all data is 0.00501934\n",
      "After 4522 training step(s),cross entropy on all data is 0.00501721\n",
      "After 4523 training step(s),cross entropy on all data is 0.00501529\n",
      "After 4524 training step(s),cross entropy on all data is 0.00501356\n",
      "After 4525 training step(s),cross entropy on all data is 0.00501201\n",
      "After 4526 training step(s),cross entropy on all data is 0.00501061\n",
      "After 4527 training step(s),cross entropy on all data is 0.00500935\n",
      "After 4528 training step(s),cross entropy on all data is 0.00500821\n",
      "After 4529 training step(s),cross entropy on all data is 0.00500719\n",
      "After 4530 training step(s),cross entropy on all data is 0.00500627\n",
      "After 4531 training step(s),cross entropy on all data is 0.00500544\n",
      "After 4532 training step(s),cross entropy on all data is 0.00500469\n",
      "After 4533 training step(s),cross entropy on all data is 0.00500402\n",
      "After 4534 training step(s),cross entropy on all data is 0.00500341\n",
      "After 4535 training step(s),cross entropy on all data is 0.00500049\n",
      "After 4536 training step(s),cross entropy on all data is 0.00499786\n",
      "After 4537 training step(s),cross entropy on all data is 0.00499549\n",
      "After 4538 training step(s),cross entropy on all data is 0.00499336\n",
      "After 4539 training step(s),cross entropy on all data is 0.00499144\n",
      "After 4540 training step(s),cross entropy on all data is 0.00498971\n",
      "After 4541 training step(s),cross entropy on all data is 0.00498815\n",
      "After 4542 training step(s),cross entropy on all data is 0.00498675\n",
      "After 4543 training step(s),cross entropy on all data is 0.00498549\n",
      "After 4544 training step(s),cross entropy on all data is 0.00498435\n",
      "After 4545 training step(s),cross entropy on all data is 0.00498333\n",
      "After 4546 training step(s),cross entropy on all data is 0.00498241\n",
      "After 4547 training step(s),cross entropy on all data is 0.00498158\n",
      "After 4548 training step(s),cross entropy on all data is 0.00498083\n",
      "After 4549 training step(s),cross entropy on all data is 0.00498016\n",
      "After 4550 training step(s),cross entropy on all data is 0.00497956\n",
      "After 4551 training step(s),cross entropy on all data is 0.00497663\n",
      "After 4552 training step(s),cross entropy on all data is 0.004974\n",
      "After 4553 training step(s),cross entropy on all data is 0.00497163\n",
      "After 4554 training step(s),cross entropy on all data is 0.00496949\n",
      "After 4555 training step(s),cross entropy on all data is 0.00496757\n",
      "After 4556 training step(s),cross entropy on all data is 0.00496584\n",
      "After 4557 training step(s),cross entropy on all data is 0.00496428\n",
      "After 4558 training step(s),cross entropy on all data is 0.00496288\n",
      "After 4559 training step(s),cross entropy on all data is 0.00496162\n",
      "After 4560 training step(s),cross entropy on all data is 0.00496048\n",
      "After 4561 training step(s),cross entropy on all data is 0.00495946\n",
      "After 4562 training step(s),cross entropy on all data is 0.00495854\n",
      "After 4563 training step(s),cross entropy on all data is 0.00495771\n",
      "After 4564 training step(s),cross entropy on all data is 0.00495696\n",
      "After 4565 training step(s),cross entropy on all data is 0.00495629\n",
      "After 4566 training step(s),cross entropy on all data is 0.00495568\n",
      "After 4567 training step(s),cross entropy on all data is 0.00495276\n",
      "After 4568 training step(s),cross entropy on all data is 0.00495012\n",
      "After 4569 training step(s),cross entropy on all data is 0.00494775\n",
      "After 4570 training step(s),cross entropy on all data is 0.00494562\n",
      "After 4571 training step(s),cross entropy on all data is 0.00494369\n",
      "After 4572 training step(s),cross entropy on all data is 0.00494196\n",
      "After 4573 training step(s),cross entropy on all data is 0.0049404\n",
      "After 4574 training step(s),cross entropy on all data is 0.004939\n",
      "After 4575 training step(s),cross entropy on all data is 0.00493774\n",
      "After 4576 training step(s),cross entropy on all data is 0.0049366\n",
      "After 4577 training step(s),cross entropy on all data is 0.00493558\n",
      "After 4578 training step(s),cross entropy on all data is 0.00493465\n",
      "After 4579 training step(s),cross entropy on all data is 0.00493382\n",
      "After 4580 training step(s),cross entropy on all data is 0.00493308\n",
      "After 4581 training step(s),cross entropy on all data is 0.0049324\n",
      "After 4582 training step(s),cross entropy on all data is 0.0049318\n",
      "After 4583 training step(s),cross entropy on all data is 0.00492887\n",
      "After 4584 training step(s),cross entropy on all data is 0.00492623\n",
      "After 4585 training step(s),cross entropy on all data is 0.00492386\n",
      "After 4586 training step(s),cross entropy on all data is 0.00492172\n",
      "After 4587 training step(s),cross entropy on all data is 0.0049198\n",
      "After 4588 training step(s),cross entropy on all data is 0.00491807\n",
      "After 4589 training step(s),cross entropy on all data is 0.00491651\n",
      "After 4590 training step(s),cross entropy on all data is 0.00491511\n",
      "After 4591 training step(s),cross entropy on all data is 0.00491384\n",
      "After 4592 training step(s),cross entropy on all data is 0.0049127\n",
      "After 4593 training step(s),cross entropy on all data is 0.00491168\n",
      "After 4594 training step(s),cross entropy on all data is 0.00491076\n",
      "After 4595 training step(s),cross entropy on all data is 0.00490993\n",
      "After 4596 training step(s),cross entropy on all data is 0.00490918\n",
      "After 4597 training step(s),cross entropy on all data is 0.00490851\n",
      "After 4598 training step(s),cross entropy on all data is 0.0049079\n",
      "After 4599 training step(s),cross entropy on all data is 0.00490497\n",
      "After 4600 training step(s),cross entropy on all data is 0.00490233\n",
      "After 4601 training step(s),cross entropy on all data is 0.00489996\n",
      "After 4602 training step(s),cross entropy on all data is 0.00489782\n",
      "After 4603 training step(s),cross entropy on all data is 0.0048959\n",
      "After 4604 training step(s),cross entropy on all data is 0.00489416\n",
      "After 4605 training step(s),cross entropy on all data is 0.0048926\n",
      "After 4606 training step(s),cross entropy on all data is 0.0048912\n",
      "After 4607 training step(s),cross entropy on all data is 0.00488994\n",
      "After 4608 training step(s),cross entropy on all data is 0.0048888\n",
      "After 4609 training step(s),cross entropy on all data is 0.00488777\n",
      "After 4610 training step(s),cross entropy on all data is 0.00488685\n",
      "After 4611 training step(s),cross entropy on all data is 0.00488602\n",
      "After 4612 training step(s),cross entropy on all data is 0.00488527\n",
      "After 4613 training step(s),cross entropy on all data is 0.0048846\n",
      "After 4614 training step(s),cross entropy on all data is 0.00488399\n",
      "After 4615 training step(s),cross entropy on all data is 0.00488106\n",
      "After 4616 training step(s),cross entropy on all data is 0.00487842\n",
      "After 4617 training step(s),cross entropy on all data is 0.00487605\n",
      "After 4618 training step(s),cross entropy on all data is 0.00487391\n",
      "After 4619 training step(s),cross entropy on all data is 0.00487198\n",
      "After 4620 training step(s),cross entropy on all data is 0.00487025\n",
      "After 4621 training step(s),cross entropy on all data is 0.00486869\n",
      "After 4622 training step(s),cross entropy on all data is 0.00486728\n",
      "After 4623 training step(s),cross entropy on all data is 0.00486602\n",
      "After 4624 training step(s),cross entropy on all data is 0.00486488\n",
      "After 4625 training step(s),cross entropy on all data is 0.00486385\n",
      "After 4626 training step(s),cross entropy on all data is 0.00486293\n",
      "After 4627 training step(s),cross entropy on all data is 0.0048621\n",
      "After 4628 training step(s),cross entropy on all data is 0.00486135\n",
      "After 4629 training step(s),cross entropy on all data is 0.00486067\n",
      "After 4630 training step(s),cross entropy on all data is 0.00486007\n",
      "After 4631 training step(s),cross entropy on all data is 0.00485714\n",
      "After 4632 training step(s),cross entropy on all data is 0.0048545\n",
      "After 4633 training step(s),cross entropy on all data is 0.00485212\n",
      "After 4634 training step(s),cross entropy on all data is 0.00484998\n",
      "After 4635 training step(s),cross entropy on all data is 0.00484806\n",
      "After 4636 training step(s),cross entropy on all data is 0.00484632\n",
      "After 4637 training step(s),cross entropy on all data is 0.00484476\n",
      "After 4638 training step(s),cross entropy on all data is 0.00484335\n",
      "After 4639 training step(s),cross entropy on all data is 0.00484209\n",
      "After 4640 training step(s),cross entropy on all data is 0.00484095\n",
      "After 4641 training step(s),cross entropy on all data is 0.00483992\n",
      "After 4642 training step(s),cross entropy on all data is 0.004839\n",
      "After 4643 training step(s),cross entropy on all data is 0.00483817\n",
      "After 4644 training step(s),cross entropy on all data is 0.00483742\n",
      "After 4645 training step(s),cross entropy on all data is 0.00483674\n",
      "After 4646 training step(s),cross entropy on all data is 0.00483614\n",
      "After 4647 training step(s),cross entropy on all data is 0.0048332\n",
      "After 4648 training step(s),cross entropy on all data is 0.00483056\n",
      "After 4649 training step(s),cross entropy on all data is 0.00482819\n",
      "After 4650 training step(s),cross entropy on all data is 0.00482605\n",
      "After 4651 training step(s),cross entropy on all data is 0.00482412\n",
      "After 4652 training step(s),cross entropy on all data is 0.00482238\n",
      "After 4653 training step(s),cross entropy on all data is 0.00482082\n",
      "After 4654 training step(s),cross entropy on all data is 0.00481942\n",
      "After 4655 training step(s),cross entropy on all data is 0.00481815\n",
      "After 4656 training step(s),cross entropy on all data is 0.00481701\n",
      "After 4657 training step(s),cross entropy on all data is 0.00481598\n",
      "After 4658 training step(s),cross entropy on all data is 0.00481506\n",
      "After 4659 training step(s),cross entropy on all data is 0.00481423\n",
      "After 4660 training step(s),cross entropy on all data is 0.00481348\n",
      "After 4661 training step(s),cross entropy on all data is 0.0048128\n",
      "After 4662 training step(s),cross entropy on all data is 0.00481219\n",
      "After 4663 training step(s),cross entropy on all data is 0.00480926\n",
      "After 4664 training step(s),cross entropy on all data is 0.00480662\n",
      "After 4665 training step(s),cross entropy on all data is 0.00480424\n",
      "After 4666 training step(s),cross entropy on all data is 0.0048021\n",
      "After 4667 training step(s),cross entropy on all data is 0.00480017\n",
      "After 4668 training step(s),cross entropy on all data is 0.00479844\n",
      "After 4669 training step(s),cross entropy on all data is 0.00479687\n",
      "After 4670 training step(s),cross entropy on all data is 0.00479547\n",
      "After 4671 training step(s),cross entropy on all data is 0.0047942\n",
      "After 4672 training step(s),cross entropy on all data is 0.00479306\n",
      "After 4673 training step(s),cross entropy on all data is 0.00479203\n",
      "After 4674 training step(s),cross entropy on all data is 0.00479111\n",
      "After 4675 training step(s),cross entropy on all data is 0.00479027\n",
      "After 4676 training step(s),cross entropy on all data is 0.00478953\n",
      "After 4677 training step(s),cross entropy on all data is 0.00478885\n",
      "After 4678 training step(s),cross entropy on all data is 0.00478824\n",
      "After 4679 training step(s),cross entropy on all data is 0.00478531\n",
      "After 4680 training step(s),cross entropy on all data is 0.00478267\n",
      "After 4681 training step(s),cross entropy on all data is 0.00478029\n",
      "After 4682 training step(s),cross entropy on all data is 0.00477814\n",
      "After 4683 training step(s),cross entropy on all data is 0.00477622\n",
      "After 4684 training step(s),cross entropy on all data is 0.00477448\n",
      "After 4685 training step(s),cross entropy on all data is 0.00477292\n",
      "After 4686 training step(s),cross entropy on all data is 0.00477151\n",
      "After 4687 training step(s),cross entropy on all data is 0.00477024\n",
      "After 4688 training step(s),cross entropy on all data is 0.0047691\n",
      "After 4689 training step(s),cross entropy on all data is 0.00476807\n",
      "After 4690 training step(s),cross entropy on all data is 0.00476715\n",
      "After 4691 training step(s),cross entropy on all data is 0.00476631\n",
      "After 4692 training step(s),cross entropy on all data is 0.00476557\n",
      "After 4693 training step(s),cross entropy on all data is 0.00476489\n",
      "After 4694 training step(s),cross entropy on all data is 0.00476428\n",
      "After 4695 training step(s),cross entropy on all data is 0.00476135\n",
      "After 4696 training step(s),cross entropy on all data is 0.0047587\n",
      "After 4697 training step(s),cross entropy on all data is 0.00475632\n",
      "After 4698 training step(s),cross entropy on all data is 0.00475418\n",
      "After 4699 training step(s),cross entropy on all data is 0.00475225\n",
      "After 4700 training step(s),cross entropy on all data is 0.00475051\n",
      "After 4701 training step(s),cross entropy on all data is 0.00474895\n",
      "After 4702 training step(s),cross entropy on all data is 0.00474754\n",
      "After 4703 training step(s),cross entropy on all data is 0.00474627\n",
      "After 4704 training step(s),cross entropy on all data is 0.00474513\n",
      "After 4705 training step(s),cross entropy on all data is 0.00474411\n",
      "After 4706 training step(s),cross entropy on all data is 0.00474318\n",
      "After 4707 training step(s),cross entropy on all data is 0.00474235\n",
      "After 4708 training step(s),cross entropy on all data is 0.0047416\n",
      "After 4709 training step(s),cross entropy on all data is 0.00474092\n",
      "After 4710 training step(s),cross entropy on all data is 0.00474031\n",
      "After 4711 training step(s),cross entropy on all data is 0.00473737\n",
      "After 4712 training step(s),cross entropy on all data is 0.00473473\n",
      "After 4713 training step(s),cross entropy on all data is 0.00473235\n",
      "After 4714 training step(s),cross entropy on all data is 0.00473021\n",
      "After 4715 training step(s),cross entropy on all data is 0.00472828\n",
      "After 4716 training step(s),cross entropy on all data is 0.00472654\n",
      "After 4717 training step(s),cross entropy on all data is 0.00472497\n",
      "After 4718 training step(s),cross entropy on all data is 0.00472357\n",
      "After 4719 training step(s),cross entropy on all data is 0.0047223\n",
      "After 4720 training step(s),cross entropy on all data is 0.00472115\n",
      "After 4721 training step(s),cross entropy on all data is 0.00472013\n",
      "After 4722 training step(s),cross entropy on all data is 0.0047192\n",
      "After 4723 training step(s),cross entropy on all data is 0.00471837\n",
      "After 4724 training step(s),cross entropy on all data is 0.00471762\n",
      "After 4725 training step(s),cross entropy on all data is 0.00471694\n",
      "After 4726 training step(s),cross entropy on all data is 0.00471633\n",
      "After 4727 training step(s),cross entropy on all data is 0.0047134\n",
      "After 4728 training step(s),cross entropy on all data is 0.00471075\n",
      "After 4729 training step(s),cross entropy on all data is 0.00470837\n",
      "After 4730 training step(s),cross entropy on all data is 0.00470622\n",
      "After 4731 training step(s),cross entropy on all data is 0.00470429\n",
      "After 4732 training step(s),cross entropy on all data is 0.00470256\n",
      "After 4733 training step(s),cross entropy on all data is 0.00470099\n",
      "After 4734 training step(s),cross entropy on all data is 0.00469958\n",
      "After 4735 training step(s),cross entropy on all data is 0.00469831\n",
      "After 4736 training step(s),cross entropy on all data is 0.00469717\n",
      "After 4737 training step(s),cross entropy on all data is 0.00469614\n",
      "After 4738 training step(s),cross entropy on all data is 0.00469522\n",
      "After 4739 training step(s),cross entropy on all data is 0.00469438\n",
      "After 4740 training step(s),cross entropy on all data is 0.00469363\n",
      "After 4741 training step(s),cross entropy on all data is 0.00469296\n",
      "After 4742 training step(s),cross entropy on all data is 0.00469235\n",
      "After 4743 training step(s),cross entropy on all data is 0.00468941\n",
      "After 4744 training step(s),cross entropy on all data is 0.00468676\n",
      "After 4745 training step(s),cross entropy on all data is 0.00468438\n",
      "After 4746 training step(s),cross entropy on all data is 0.00468223\n",
      "After 4747 training step(s),cross entropy on all data is 0.0046803\n",
      "After 4748 training step(s),cross entropy on all data is 0.00467857\n",
      "After 4749 training step(s),cross entropy on all data is 0.004677\n",
      "After 4750 training step(s),cross entropy on all data is 0.00467559\n",
      "After 4751 training step(s),cross entropy on all data is 0.00467432\n",
      "After 4752 training step(s),cross entropy on all data is 0.00467318\n",
      "After 4753 training step(s),cross entropy on all data is 0.00467215\n",
      "After 4754 training step(s),cross entropy on all data is 0.00467122\n",
      "After 4755 training step(s),cross entropy on all data is 0.00467039\n",
      "After 4756 training step(s),cross entropy on all data is 0.00466964\n",
      "After 4757 training step(s),cross entropy on all data is 0.00466896\n",
      "After 4758 training step(s),cross entropy on all data is 0.00466835\n",
      "After 4759 training step(s),cross entropy on all data is 0.00466541\n",
      "After 4760 training step(s),cross entropy on all data is 0.00466277\n",
      "After 4761 training step(s),cross entropy on all data is 0.00466038\n",
      "After 4762 training step(s),cross entropy on all data is 0.00465824\n",
      "After 4763 training step(s),cross entropy on all data is 0.00465631\n",
      "After 4764 training step(s),cross entropy on all data is 0.00465457\n",
      "After 4765 training step(s),cross entropy on all data is 0.004653\n",
      "After 4766 training step(s),cross entropy on all data is 0.00465159\n",
      "After 4767 training step(s),cross entropy on all data is 0.00465032\n",
      "After 4768 training step(s),cross entropy on all data is 0.00464918\n",
      "After 4769 training step(s),cross entropy on all data is 0.00464815\n",
      "After 4770 training step(s),cross entropy on all data is 0.00464722\n",
      "After 4771 training step(s),cross entropy on all data is 0.00464639\n",
      "After 4772 training step(s),cross entropy on all data is 0.00464564\n",
      "After 4773 training step(s),cross entropy on all data is 0.00464496\n",
      "After 4774 training step(s),cross entropy on all data is 0.00464435\n",
      "After 4775 training step(s),cross entropy on all data is 0.00464141\n",
      "After 4776 training step(s),cross entropy on all data is 0.00463876\n",
      "After 4777 training step(s),cross entropy on all data is 0.00463638\n",
      "After 4778 training step(s),cross entropy on all data is 0.00463423\n",
      "After 4779 training step(s),cross entropy on all data is 0.0046323\n",
      "After 4780 training step(s),cross entropy on all data is 0.00463056\n",
      "After 4781 training step(s),cross entropy on all data is 0.004629\n",
      "After 4782 training step(s),cross entropy on all data is 0.00462759\n",
      "After 4783 training step(s),cross entropy on all data is 0.00462632\n",
      "After 4784 training step(s),cross entropy on all data is 0.00462517\n",
      "After 4785 training step(s),cross entropy on all data is 0.00462414\n",
      "After 4786 training step(s),cross entropy on all data is 0.00462322\n",
      "After 4787 training step(s),cross entropy on all data is 0.00462238\n",
      "After 4788 training step(s),cross entropy on all data is 0.00462163\n",
      "After 4789 training step(s),cross entropy on all data is 0.00462095\n",
      "After 4790 training step(s),cross entropy on all data is 0.00462034\n",
      "After 4791 training step(s),cross entropy on all data is 0.0046174\n",
      "After 4792 training step(s),cross entropy on all data is 0.00461475\n",
      "After 4793 training step(s),cross entropy on all data is 0.00461237\n",
      "After 4794 training step(s),cross entropy on all data is 0.00461022\n",
      "After 4795 training step(s),cross entropy on all data is 0.00460829\n",
      "After 4796 training step(s),cross entropy on all data is 0.00460655\n",
      "After 4797 training step(s),cross entropy on all data is 0.00460498\n",
      "After 4798 training step(s),cross entropy on all data is 0.00460357\n",
      "After 4799 training step(s),cross entropy on all data is 0.0046023\n",
      "After 4800 training step(s),cross entropy on all data is 0.00460116\n",
      "After 4801 training step(s),cross entropy on all data is 0.00460013\n",
      "After 4802 training step(s),cross entropy on all data is 0.0045992\n",
      "After 4803 training step(s),cross entropy on all data is 0.00459837\n",
      "After 4804 training step(s),cross entropy on all data is 0.00459762\n",
      "After 4805 training step(s),cross entropy on all data is 0.00459694\n",
      "After 4806 training step(s),cross entropy on all data is 0.00459633\n",
      "After 4807 training step(s),cross entropy on all data is 0.00459339\n",
      "After 4808 training step(s),cross entropy on all data is 0.00459074\n",
      "After 4809 training step(s),cross entropy on all data is 0.00458835\n",
      "After 4810 training step(s),cross entropy on all data is 0.00458621\n",
      "After 4811 training step(s),cross entropy on all data is 0.00458427\n",
      "After 4812 training step(s),cross entropy on all data is 0.00458253\n",
      "After 4813 training step(s),cross entropy on all data is 0.00458097\n",
      "After 4814 training step(s),cross entropy on all data is 0.00457956\n",
      "After 4815 training step(s),cross entropy on all data is 0.00457829\n",
      "After 4816 training step(s),cross entropy on all data is 0.00457714\n",
      "After 4817 training step(s),cross entropy on all data is 0.00457611\n",
      "After 4818 training step(s),cross entropy on all data is 0.00457518\n",
      "After 4819 training step(s),cross entropy on all data is 0.00457435\n",
      "After 4820 training step(s),cross entropy on all data is 0.0045736\n",
      "After 4821 training step(s),cross entropy on all data is 0.00457292\n",
      "After 4822 training step(s),cross entropy on all data is 0.00457231\n",
      "After 4823 training step(s),cross entropy on all data is 0.00456937\n",
      "After 4824 training step(s),cross entropy on all data is 0.00456672\n",
      "After 4825 training step(s),cross entropy on all data is 0.00456433\n",
      "After 4826 training step(s),cross entropy on all data is 0.00456218\n",
      "After 4827 training step(s),cross entropy on all data is 0.00456025\n",
      "After 4828 training step(s),cross entropy on all data is 0.00455851\n",
      "After 4829 training step(s),cross entropy on all data is 0.00455694\n",
      "After 4830 training step(s),cross entropy on all data is 0.00455553\n",
      "After 4831 training step(s),cross entropy on all data is 0.00455426\n",
      "After 4832 training step(s),cross entropy on all data is 0.00455312\n",
      "After 4833 training step(s),cross entropy on all data is 0.00455209\n",
      "After 4834 training step(s),cross entropy on all data is 0.00455116\n",
      "After 4835 training step(s),cross entropy on all data is 0.00455032\n",
      "After 4836 training step(s),cross entropy on all data is 0.00454957\n",
      "After 4837 training step(s),cross entropy on all data is 0.00454889\n",
      "After 4838 training step(s),cross entropy on all data is 0.00454828\n",
      "After 4839 training step(s),cross entropy on all data is 0.00454534\n",
      "After 4840 training step(s),cross entropy on all data is 0.00454269\n",
      "After 4841 training step(s),cross entropy on all data is 0.0045403\n",
      "After 4842 training step(s),cross entropy on all data is 0.00453816\n",
      "After 4843 training step(s),cross entropy on all data is 0.00453622\n",
      "After 4844 training step(s),cross entropy on all data is 0.00453448\n",
      "After 4845 training step(s),cross entropy on all data is 0.00453291\n",
      "After 4846 training step(s),cross entropy on all data is 0.0045315\n",
      "After 4847 training step(s),cross entropy on all data is 0.00453023\n",
      "After 4848 training step(s),cross entropy on all data is 0.00452909\n",
      "After 4849 training step(s),cross entropy on all data is 0.00452806\n",
      "After 4850 training step(s),cross entropy on all data is 0.00452713\n",
      "After 4851 training step(s),cross entropy on all data is 0.00452629\n",
      "After 4852 training step(s),cross entropy on all data is 0.00452554\n",
      "After 4853 training step(s),cross entropy on all data is 0.00452486\n",
      "After 4854 training step(s),cross entropy on all data is 0.00452425\n",
      "After 4855 training step(s),cross entropy on all data is 0.00452131\n",
      "After 4856 training step(s),cross entropy on all data is 0.00451866\n",
      "After 4857 training step(s),cross entropy on all data is 0.00451627\n",
      "After 4858 training step(s),cross entropy on all data is 0.00451412\n",
      "After 4859 training step(s),cross entropy on all data is 0.00451219\n",
      "After 4860 training step(s),cross entropy on all data is 0.00451045\n",
      "After 4861 training step(s),cross entropy on all data is 0.00450888\n",
      "After 4862 training step(s),cross entropy on all data is 0.00450747\n",
      "After 4863 training step(s),cross entropy on all data is 0.0045062\n",
      "After 4864 training step(s),cross entropy on all data is 0.00450505\n",
      "After 4865 training step(s),cross entropy on all data is 0.00450402\n",
      "After 4866 training step(s),cross entropy on all data is 0.00450309\n",
      "After 4867 training step(s),cross entropy on all data is 0.00450226\n",
      "After 4868 training step(s),cross entropy on all data is 0.00450151\n",
      "After 4869 training step(s),cross entropy on all data is 0.00450083\n",
      "After 4870 training step(s),cross entropy on all data is 0.00450022\n",
      "After 4871 training step(s),cross entropy on all data is 0.00449727\n",
      "After 4872 training step(s),cross entropy on all data is 0.00449462\n",
      "After 4873 training step(s),cross entropy on all data is 0.00449224\n",
      "After 4874 training step(s),cross entropy on all data is 0.00449009\n",
      "After 4875 training step(s),cross entropy on all data is 0.00448815\n",
      "After 4876 training step(s),cross entropy on all data is 0.00448641\n",
      "After 4877 training step(s),cross entropy on all data is 0.00448484\n",
      "After 4878 training step(s),cross entropy on all data is 0.00448343\n",
      "After 4879 training step(s),cross entropy on all data is 0.00448216\n",
      "After 4880 training step(s),cross entropy on all data is 0.00448101\n",
      "After 4881 training step(s),cross entropy on all data is 0.00447998\n",
      "After 4882 training step(s),cross entropy on all data is 0.00447905\n",
      "After 4883 training step(s),cross entropy on all data is 0.00447822\n",
      "After 4884 training step(s),cross entropy on all data is 0.00447747\n",
      "After 4885 training step(s),cross entropy on all data is 0.00447679\n",
      "After 4886 training step(s),cross entropy on all data is 0.00447618\n",
      "After 4887 training step(s),cross entropy on all data is 0.00447323\n",
      "After 4888 training step(s),cross entropy on all data is 0.00447058\n",
      "After 4889 training step(s),cross entropy on all data is 0.0044682\n",
      "After 4890 training step(s),cross entropy on all data is 0.00446605\n",
      "After 4891 training step(s),cross entropy on all data is 0.00446411\n",
      "After 4892 training step(s),cross entropy on all data is 0.00446237\n",
      "After 4893 training step(s),cross entropy on all data is 0.0044608\n",
      "After 4894 training step(s),cross entropy on all data is 0.00445939\n",
      "After 4895 training step(s),cross entropy on all data is 0.00445812\n",
      "After 4896 training step(s),cross entropy on all data is 0.00445697\n",
      "After 4897 training step(s),cross entropy on all data is 0.00445594\n",
      "After 4898 training step(s),cross entropy on all data is 0.00445501\n",
      "After 4899 training step(s),cross entropy on all data is 0.00445418\n",
      "After 4900 training step(s),cross entropy on all data is 0.00445342\n",
      "After 4901 training step(s),cross entropy on all data is 0.00445275\n",
      "After 4902 training step(s),cross entropy on all data is 0.00445214\n",
      "After 4903 training step(s),cross entropy on all data is 0.00444919\n",
      "After 4904 training step(s),cross entropy on all data is 0.00444654\n",
      "After 4905 training step(s),cross entropy on all data is 0.00444415\n",
      "After 4906 training step(s),cross entropy on all data is 0.004442\n",
      "After 4907 training step(s),cross entropy on all data is 0.00444007\n",
      "After 4908 training step(s),cross entropy on all data is 0.00443832\n",
      "After 4909 training step(s),cross entropy on all data is 0.00443675\n",
      "After 4910 training step(s),cross entropy on all data is 0.00443534\n",
      "After 4911 training step(s),cross entropy on all data is 0.00443407\n",
      "After 4912 training step(s),cross entropy on all data is 0.00443293\n",
      "After 4913 training step(s),cross entropy on all data is 0.00443189\n",
      "After 4914 training step(s),cross entropy on all data is 0.00443097\n",
      "After 4915 training step(s),cross entropy on all data is 0.00443013\n",
      "After 4916 training step(s),cross entropy on all data is 0.00442938\n",
      "After 4917 training step(s),cross entropy on all data is 0.0044287\n",
      "After 4918 training step(s),cross entropy on all data is 0.00442809\n",
      "After 4919 training step(s),cross entropy on all data is 0.00442514\n",
      "After 4920 training step(s),cross entropy on all data is 0.00442249\n",
      "After 4921 training step(s),cross entropy on all data is 0.0044201\n",
      "After 4922 training step(s),cross entropy on all data is 0.00441795\n",
      "After 4923 training step(s),cross entropy on all data is 0.00441602\n",
      "After 4924 training step(s),cross entropy on all data is 0.00441428\n",
      "After 4925 training step(s),cross entropy on all data is 0.00441271\n",
      "After 4926 training step(s),cross entropy on all data is 0.00441129\n",
      "After 4927 training step(s),cross entropy on all data is 0.00441002\n",
      "After 4928 training step(s),cross entropy on all data is 0.00440888\n",
      "After 4929 training step(s),cross entropy on all data is 0.00440785\n",
      "After 4930 training step(s),cross entropy on all data is 0.00440692\n",
      "After 4931 training step(s),cross entropy on all data is 0.00440608\n",
      "After 4932 training step(s),cross entropy on all data is 0.00440533\n",
      "After 4933 training step(s),cross entropy on all data is 0.00440465\n",
      "After 4934 training step(s),cross entropy on all data is 0.00440404\n",
      "After 4935 training step(s),cross entropy on all data is 0.00440109\n",
      "After 4936 training step(s),cross entropy on all data is 0.00439844\n",
      "After 4937 training step(s),cross entropy on all data is 0.00439605\n",
      "After 4938 training step(s),cross entropy on all data is 0.0043939\n",
      "After 4939 training step(s),cross entropy on all data is 0.00439197\n",
      "After 4940 training step(s),cross entropy on all data is 0.00439022\n",
      "After 4941 training step(s),cross entropy on all data is 0.00438866\n",
      "After 4942 training step(s),cross entropy on all data is 0.00438724\n",
      "After 4943 training step(s),cross entropy on all data is 0.00438597\n",
      "After 4944 training step(s),cross entropy on all data is 0.00438483\n",
      "After 4945 training step(s),cross entropy on all data is 0.00438379\n",
      "After 4946 training step(s),cross entropy on all data is 0.00438287\n",
      "After 4947 training step(s),cross entropy on all data is 0.00438203\n",
      "After 4948 training step(s),cross entropy on all data is 0.00438128\n",
      "After 4949 training step(s),cross entropy on all data is 0.0043806\n",
      "After 4950 training step(s),cross entropy on all data is 0.00437999\n",
      "After 4951 training step(s),cross entropy on all data is 0.00437704\n",
      "After 4952 training step(s),cross entropy on all data is 0.00437439\n",
      "After 4953 training step(s),cross entropy on all data is 0.004372\n",
      "After 4954 training step(s),cross entropy on all data is 0.00436985\n",
      "After 4955 training step(s),cross entropy on all data is 0.00436791\n",
      "After 4956 training step(s),cross entropy on all data is 0.00436617\n",
      "After 4957 training step(s),cross entropy on all data is 0.0043646\n",
      "After 4958 training step(s),cross entropy on all data is 0.00436319\n",
      "After 4959 training step(s),cross entropy on all data is 0.00436192\n",
      "After 4960 training step(s),cross entropy on all data is 0.00436077\n",
      "After 4961 training step(s),cross entropy on all data is 0.00435974\n",
      "After 4962 training step(s),cross entropy on all data is 0.00435881\n",
      "After 4963 training step(s),cross entropy on all data is 0.00435797\n",
      "After 4964 training step(s),cross entropy on all data is 0.00435722\n",
      "After 4965 training step(s),cross entropy on all data is 0.00435654\n",
      "After 4966 training step(s),cross entropy on all data is 0.00435593\n",
      "After 4967 training step(s),cross entropy on all data is 0.00435299\n",
      "After 4968 training step(s),cross entropy on all data is 0.00435033\n",
      "After 4969 training step(s),cross entropy on all data is 0.00434795\n",
      "After 4970 training step(s),cross entropy on all data is 0.0043458\n",
      "After 4971 training step(s),cross entropy on all data is 0.00434386\n",
      "After 4972 training step(s),cross entropy on all data is 0.00434212\n",
      "After 4973 training step(s),cross entropy on all data is 0.00434055\n",
      "After 4974 training step(s),cross entropy on all data is 0.00433913\n",
      "After 4975 training step(s),cross entropy on all data is 0.00433786\n",
      "After 4976 training step(s),cross entropy on all data is 0.00433671\n",
      "After 4977 training step(s),cross entropy on all data is 0.00433568\n",
      "After 4978 training step(s),cross entropy on all data is 0.00433475\n",
      "After 4979 training step(s),cross entropy on all data is 0.00433392\n",
      "After 4980 training step(s),cross entropy on all data is 0.00433317\n",
      "After 4981 training step(s),cross entropy on all data is 0.00433249\n",
      "After 4982 training step(s),cross entropy on all data is 0.00433188\n",
      "After 4983 training step(s),cross entropy on all data is 0.00432893\n",
      "After 4984 training step(s),cross entropy on all data is 0.00432628\n",
      "After 4985 training step(s),cross entropy on all data is 0.00432389\n",
      "After 4986 training step(s),cross entropy on all data is 0.00432174\n",
      "After 4987 training step(s),cross entropy on all data is 0.0043198\n",
      "After 4988 training step(s),cross entropy on all data is 0.00431806\n",
      "After 4989 training step(s),cross entropy on all data is 0.00431649\n",
      "After 4990 training step(s),cross entropy on all data is 0.00431508\n",
      "After 4991 training step(s),cross entropy on all data is 0.0043138\n",
      "After 4992 training step(s),cross entropy on all data is 0.00431266\n",
      "After 4993 training step(s),cross entropy on all data is 0.00431163\n",
      "After 4994 training step(s),cross entropy on all data is 0.0043107\n",
      "After 4995 training step(s),cross entropy on all data is 0.00430986\n",
      "After 4996 training step(s),cross entropy on all data is 0.00430911\n",
      "After 4997 training step(s),cross entropy on all data is 0.00430843\n",
      "After 4998 training step(s),cross entropy on all data is 0.00430782\n",
      "After 4999 training step(s),cross entropy on all data is 0.00430487\n",
      "[[-1.9618274   2.58235407  1.68203783]\n",
      " [-3.4681716   1.06982327  2.11788988]]\n",
      "[[-1.8247149 ]\n",
      " [ 2.68546653]\n",
      " [ 1.41819501]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init_op=tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    print(sess.run(w1))\n",
    "    print(sess.run(w2))\n",
    "    \n",
    "    STEPS=5000\n",
    "    for i in range(STEPS):\n",
    "        start=(i*batch_size) % dataset_size\n",
    "        end=min(start+batch_size,dataset_size)\n",
    "        sess.run(train_step,feed_dict={x:X[start:end],y_:Y[start:end]})\n",
    "        #print(sess.run(w1))\n",
    "        #print(sess.run(w2))\n",
    "        \n",
    "        total_cross_entropy=sess.run(cross_entropy,feed_dict={x:X,y_:Y})\n",
    "        print(\"After %d training step(s),cross entropy on all data is %g\" %(i,total_cross_entropy))\n",
    "        \n",
    "    print(sess.run(w1))\n",
    "    print(sess.run(w2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
